{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>11 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Chicago</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.32.1.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>11 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Vimalathithan_83ed67</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.525 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.8 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         11 secs\n",
       "H2O_cluster_timezone:       America/Chicago\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.32.1.3\n",
       "H2O_cluster_version_age:    11 days\n",
       "H2O_cluster_name:           H2O_from_python_Vimalathithan_83ed67\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.525 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.8.8 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NIJ_Train_Mod = pd.read_csv(\"NIJ_s_Recidivism_Challenge_Training_Dataset-sara.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "['ID', 'Gender', 'Race', 'Age_at_Release', 'Residence_PUMA', 'Gang_Affiliated', 'Supervision_Risk_Score_First', 'Supervision_Level_First', 'Education_Level', 'Dependents', 'Prison_Offense', 'Prison_Years', 'Prior_Arrest_Episodes_Felony', 'Prior_Arrest_Episodes_Misd', 'Prior_Arrest_Episodes_Violent', 'Prior_Arrest_Episodes_Property', 'Prior_Arrest_Episodes_Drug', 'Prior_Arrest_Episodes_PPViolationCharges', 'Prior_Arrest_Episodes_DVCharges', 'Prior_Arrest_Episodes_GunCharges', 'Prior_Conviction_Episodes_Felony', 'Prior_Conviction_Episodes_Misd', 'Prior_Conviction_Episodes_Viol', 'Prior_Conviction_Episodes_Prop', 'Prior_Conviction_Episodes_Drug', 'Prior_Conviction_Episodes_PPViolationCharges', 'Prior_Conviction_Episodes_DomesticViolenceCharges', 'Prior_Conviction_Episodes_GunCharges', 'Prior_Revocations_Parole', 'Prior_Revocations_Probation', 'Condition_MH_SA', 'Condition_Cog_Ed', 'Condition_Other', 'Violations_ElectronicMonitoring', 'Violations_Instruction', 'Violations_FailToReport', 'Violations_MoveWithoutPermission', 'Delinquency_Reports', 'Program_Attendances', 'Program_UnexcusedAbsences', 'Residence_Changes', 'Avg_Days_per_DrugTest', 'DrugTests_THC_Positive', 'DrugTests_Cocaine_Positive', 'DrugTests_Meth_Positive', 'DrugTests_Other_Positive', 'Percent_Days_Employed', 'Jobs_Per_Year', 'Employment_Exempt', 'Recidivism_Within_3years', 'Recidivism_Arrest_Year1', 'Recidivism_Arrest_Year2', 'Recidivism_Arrest_Year3']\n"
     ]
    }
   ],
   "source": [
    "NIJ_Train_Mod_Full = h2o.H2OFrame(NIJ_Train_Mod)\n",
    "print(NIJ_Train_Mod_Full.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NIJ_Train_Mod_Full[\"Recidivism_Arrest_Year1\"]=NIJ_Train_Mod_Full[\"Recidivism_Arrest_Year1\"].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:18028\n",
      "Cols:53\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>ID                </th><th>Gender  </th><th>Race  </th><th>Age_at_Release  </th><th>Residence_PUMA    </th><th>Gang_Affiliated  </th><th>Supervision_Risk_Score_First  </th><th>Supervision_Level_First  </th><th>Education_Level      </th><th>Dependents        </th><th>Prison_Offense  </th><th>Prison_Years     </th><th>Prior_Arrest_Episodes_Felony  </th><th>Prior_Arrest_Episodes_Misd  </th><th>Prior_Arrest_Episodes_Violent  </th><th>Prior_Arrest_Episodes_Property  </th><th>Prior_Arrest_Episodes_Drug  </th><th>Prior_Arrest_Episodes_PPViolationCharges  </th><th>Prior_Arrest_Episodes_DVCharges  </th><th>Prior_Arrest_Episodes_GunCharges  </th><th>Prior_Conviction_Episodes_Felony  </th><th>Prior_Conviction_Episodes_Misd  </th><th>Prior_Conviction_Episodes_Viol  </th><th>Prior_Conviction_Episodes_Prop  </th><th>Prior_Conviction_Episodes_Drug  </th><th>Prior_Conviction_Episodes_PPViolationCharges  </th><th>Prior_Conviction_Episodes_DomesticViolenceCharges  </th><th>Prior_Conviction_Episodes_GunCharges  </th><th>Prior_Revocations_Parole  </th><th>Prior_Revocations_Probation  </th><th>Condition_MH_SA  </th><th>Condition_Cog_Ed  </th><th>Condition_Other  </th><th>Violations_ElectronicMonitoring  </th><th>Violations_Instruction  </th><th>Violations_FailToReport  </th><th>Violations_MoveWithoutPermission  </th><th>Delinquency_Reports  </th><th>Program_Attendances  </th><th>Program_UnexcusedAbsences  </th><th>Residence_Changes  </th><th>Avg_Days_per_DrugTest  </th><th>DrugTests_THC_Positive  </th><th>DrugTests_Cocaine_Positive  </th><th>DrugTests_Meth_Positive  </th><th>DrugTests_Other_Positive  </th><th>Percent_Days_Employed  </th><th>Jobs_Per_Year     </th><th>Employment_Exempt  </th><th>Recidivism_Within_3years  </th><th>Recidivism_Arrest_Year1  </th><th>Recidivism_Arrest_Year2  </th><th>Recidivism_Arrest_Year3  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int               </td><td>enum    </td><td>enum  </td><td>enum            </td><td>int               </td><td>enum             </td><td>int                           </td><td>enum                     </td><td>enum                 </td><td>int               </td><td>enum            </td><td>enum             </td><td>int                           </td><td>int                         </td><td>int                            </td><td>int                             </td><td>int                         </td><td>int                                       </td><td>enum                             </td><td>enum                              </td><td>int                               </td><td>int                             </td><td>enum                            </td><td>int                             </td><td>int                             </td><td>enum                                          </td><td>enum                                               </td><td>enum                                  </td><td>enum                      </td><td>enum                         </td><td>enum             </td><td>enum              </td><td>enum             </td><td>enum                             </td><td>enum                    </td><td>enum                     </td><td>enum                              </td><td>int                  </td><td>int                  </td><td>int                        </td><td>int                </td><td>real                   </td><td>real                    </td><td>real                        </td><td>real                     </td><td>real                      </td><td>real                   </td><td>real              </td><td>enum               </td><td>enum                      </td><td>enum                     </td><td>enum                     </td><td>enum                     </td></tr>\n",
       "<tr><td>mins   </td><td>1.0               </td><td>        </td><td>      </td><td>                </td><td>1.0               </td><td>                 </td><td>1.0                           </td><td>                         </td><td>                     </td><td>0.0               </td><td>                </td><td>                 </td><td>0.0                           </td><td>0.0                         </td><td>0.0                            </td><td>0.0                             </td><td>0.0                         </td><td>0.0                                       </td><td>                                 </td><td>                                  </td><td>0.0                               </td><td>0.0                             </td><td>                                </td><td>0.0                             </td><td>0.0                             </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td><td>                                 </td><td>                        </td><td>                         </td><td>                                  </td><td>0.0                  </td><td>0.0                  </td><td>0.0                        </td><td>0.0                </td><td>0.5                    </td><td>0.0                     </td><td>0.0                         </td><td>0.0                      </td><td>0.0                       </td><td>0.0                    </td><td>0.0               </td><td>                   </td><td>                          </td><td>                         </td><td>                         </td><td>                         </td></tr>\n",
       "<tr><td>mean   </td><td>13386.065342800066</td><td>        </td><td>      </td><td>                </td><td>12.307577102285345</td><td>                 </td><td>6.064753079444013             </td><td>                         </td><td>                     </td><td>0.812723373838455 </td><td>                </td><td>                 </td><td>4.414911449602812             </td><td>2.0828792191948             </td><td>0.6597998822836924             </td><td>1.4095408895265436              </td><td>1.3619173262972737          </td><td>1.452849664528497                         </td><td>                                 </td><td>                                  </td><td>0.8324328437714035                </td><td>1.0695922948801495              </td><td>                                </td><td>0.6161360601588282              </td><td>0.3367316341829085              </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td><td>                                 </td><td>                        </td><td>                         </td><td>                                  </td><td>0.36162238136670893  </td><td>1.926088059890879    </td><td>0.1681324680050948         </td><td>0.5673466841350056 </td><td>93.5858598589524       </td><td>0.06312002135558516     </td><td>0.01417291604021951         </td><td>0.012768276397193669     </td><td>0.007681323101278122      </td><td>0.48003490711381924    </td><td>0.7664227222145314</td><td>                   </td><td>                          </td><td>                         </td><td>                         </td><td>                         </td></tr>\n",
       "<tr><td>maxs   </td><td>26761.0           </td><td>        </td><td>      </td><td>                </td><td>25.0              </td><td>                 </td><td>10.0                          </td><td>                         </td><td>                     </td><td>2.0               </td><td>                </td><td>                 </td><td>9.0                           </td><td>5.0                         </td><td>2.0                            </td><td>4.0                             </td><td>4.0                         </td><td>4.0                                       </td><td>                                 </td><td>                                  </td><td>2.0                               </td><td>3.0                             </td><td>                                </td><td>2.0                             </td><td>1.0                             </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td><td>                                 </td><td>                        </td><td>                         </td><td>                                  </td><td>3.0                  </td><td>9.0                  </td><td>2.0                        </td><td>2.0                </td><td>1087.0                 </td><td>1.0                     </td><td>1.0                         </td><td>1.0                      </td><td>1.0                       </td><td>1.0                    </td><td>8.0               </td><td>                   </td><td>                          </td><td>                         </td><td>                         </td><td>                         </td></tr>\n",
       "<tr><td>sigma  </td><td>7721.45199210053  </td><td>        </td><td>      </td><td>                </td><td>7.143255483700004 </td><td>                 </td><td>2.38281069293838              </td><td>                         </td><td>                     </td><td>0.8167430677526971</td><td>                </td><td>                 </td><td>2.411659438566055             </td><td>1.6725748398001308          </td><td>0.7428877504621911             </td><td>1.3091293195913836              </td><td>1.310739088997926           </td><td>1.3851498561202278                        </td><td>                                 </td><td>                                  </td><td>0.7772946645801878                </td><td>1.0662485610595156              </td><td>                                </td><td>0.7502850718927523              </td><td>0.4726099706580711              </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td><td>                                 </td><td>                        </td><td>                         </td><td>                                  </td><td>0.8430023110788698   </td><td>2.763995913238437    </td><td>0.4887386930153344         </td><td>0.7305650615200647 </td><td>117.56134050131506     </td><td>0.13835671043544032     </td><td>0.06347303019200744         </td><td>0.05957188007257393      </td><td>0.04222438425341263       </td><td>0.42439649611104063    </td><td>0.813473970173938 </td><td>                   </td><td>                          </td><td>                         </td><td>                         </td><td>                         </td></tr>\n",
       "<tr><td>zeros  </td><td>0                 </td><td>        </td><td>      </td><td>                </td><td>0                 </td><td>                 </td><td>0                             </td><td>                         </td><td>                     </td><td>5599              </td><td>                </td><td>                 </td><td>172                           </td><td>2853                        </td><td>7705                           </td><td>4561                            </td><td>5563                        </td><td>4718                                      </td><td>                                 </td><td>                                  </td><td>5255                              </td><td>5507                            </td><td>                                </td><td>7784                            </td><td>8848                            </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td><td>                                 </td><td>                        </td><td>                         </td><td>                                  </td><td>12248                </td><td>9534                 </td><td>14531                      </td><td>9245               </td><td>0                      </td><td>9893                    </td><td>13073                       </td><td>12975                    </td><td>13328                     </td><td>5713                   </td><td>5455              </td><td>                   </td><td>                          </td><td>                         </td><td>                         </td><td>                         </td></tr>\n",
       "<tr><td>missing</td><td>0                 </td><td>0       </td><td>0     </td><td>0               </td><td>0                 </td><td>0                </td><td>330                           </td><td>0                        </td><td>0                    </td><td>5437              </td><td>0               </td><td>0                </td><td>4307                          </td><td>5733                        </td><td>2737                           </td><td>4088                            </td><td>2110                        </td><td>4465                                      </td><td>0                                </td><td>0                                 </td><td>4887                              </td><td>4219                            </td><td>0                               </td><td>3799                            </td><td>4688                            </td><td>0                                             </td><td>0                                                  </td><td>0                                     </td><td>0                         </td><td>0                            </td><td>0                </td><td>0                 </td><td>0                </td><td>0                                </td><td>0                       </td><td>0                        </td><td>0                                 </td><td>3087                 </td><td>2266                 </td><td>1541                       </td><td>1999               </td><td>4260                   </td><td>3632                    </td><td>3632                        </td><td>3632                     </td><td>3632                      </td><td>307                    </td><td>534               </td><td>0                  </td><td>0                         </td><td>0                        </td><td>0                        </td><td>0                        </td></tr>\n",
       "<tr><td>0      </td><td>1.0               </td><td>M       </td><td>BLACK </td><td>43-47           </td><td>16.0              </td><td>False            </td><td>3.0                           </td><td>Standard                 </td><td>At least some college</td><td>nan               </td><td>Drug            </td><td>More than 3 years</td><td>6.0                           </td><td>nan                         </td><td>1.0                            </td><td>3.0                             </td><td>3.0                         </td><td>4.0                                       </td><td>False                            </td><td>False                             </td><td>nan                               </td><td>3.0                             </td><td>False                           </td><td>2.0                             </td><td>nan                             </td><td>False                                         </td><td>False                                              </td><td>False                                 </td><td>False                     </td><td>False                        </td><td>True             </td><td>True              </td><td>False            </td><td>False                            </td><td>False                   </td><td>False                    </td><td>False                             </td><td>0.0                  </td><td>6.0                  </td><td>0.0                        </td><td>2.0                </td><td>612.0                  </td><td>0.0                     </td><td>0.0                         </td><td>0.0                      </td><td>0.0                       </td><td>0.488562092            </td><td>0.447610294       </td><td>False              </td><td>False                     </td><td>False                    </td><td>False                    </td><td>False                    </td></tr>\n",
       "<tr><td>1      </td><td>2.0               </td><td>M       </td><td>BLACK </td><td>33-37           </td><td>16.0              </td><td>False            </td><td>6.0                           </td><td>Specialized              </td><td>Less than HS diploma </td><td>1.0               </td><td>Violent/Non-Sex </td><td>More than 3 years</td><td>7.0                           </td><td>nan                         </td><td>nan                            </td><td>0.0                             </td><td>3.0                         </td><td>nan                                       </td><td>True                             </td><td>False                             </td><td>nan                               </td><td>nan                             </td><td>True                            </td><td>0.0                             </td><td>nan                             </td><td>True                                          </td><td>True                                               </td><td>True                                  </td><td>False                     </td><td>False                        </td><td>False            </td><td>False             </td><td>False            </td><td>False                            </td><td>True                    </td><td>False                    </td><td>False                             </td><td>nan                  </td><td>0.0                  </td><td>0.0                        </td><td>2.0                </td><td>35.66666667            </td><td>0.0                     </td><td>0.0                         </td><td>0.0                      </td><td>0.0                       </td><td>0.425233645            </td><td>2.0               </td><td>False              </td><td>True                      </td><td>False                    </td><td>False                    </td><td>True                     </td></tr>\n",
       "<tr><td>2      </td><td>3.0               </td><td>M       </td><td>BLACK </td><td>48 or older     </td><td>24.0              </td><td>False            </td><td>7.0                           </td><td>High                     </td><td>At least some college</td><td>nan               </td><td>Drug            </td><td>1-2 years        </td><td>6.0                           </td><td>nan                         </td><td>nan                            </td><td>2.0                             </td><td>2.0                         </td><td>nan                                       </td><td>True                             </td><td>False                             </td><td>nan                               </td><td>2.0                             </td><td>True                            </td><td>1.0                             </td><td>nan                             </td><td>False                                         </td><td>True                                               </td><td>False                                 </td><td>False                     </td><td>False                        </td><td>True             </td><td>True              </td><td>False            </td><td>False                            </td><td>True                    </td><td>False                    </td><td>True                              </td><td>nan                  </td><td>6.0                  </td><td>0.0                        </td><td>0.0                </td><td>93.66666667            </td><td>0.333333343             </td><td>0.0                         </td><td>0.166666672              </td><td>0.0                       </td><td>0.0                    </td><td>0.0               </td><td>False              </td><td>True                      </td><td>False                    </td><td>True                     </td><td>False                    </td></tr>\n",
       "<tr><td>3      </td><td>4.0               </td><td>M       </td><td>WHITE </td><td>38-42           </td><td>16.0              </td><td>False            </td><td>7.0                           </td><td>High                     </td><td>Less than HS diploma </td><td>1.0               </td><td>Property        </td><td>1-2 years        </td><td>8.0                           </td><td>nan                         </td><td>0.0                            </td><td>3.0                             </td><td>3.0                         </td><td>3.0                                       </td><td>False                            </td><td>False                             </td><td>nan                               </td><td>nan                             </td><td>False                           </td><td>nan                             </td><td>nan                             </td><td>False                                         </td><td>False                                              </td><td>False                                 </td><td>False                     </td><td>True                         </td><td>True             </td><td>True              </td><td>False            </td><td>False                            </td><td>False                   </td><td>False                    </td><td>False                             </td><td>0.0                  </td><td>6.0                  </td><td>0.0                        </td><td>nan                </td><td>25.4                   </td><td>0.0                     </td><td>0.0                         </td><td>0.0                      </td><td>0.0                       </td><td>1.0                    </td><td>0.718996063       </td><td>False              </td><td>False                     </td><td>False                    </td><td>False                    </td><td>False                    </td></tr>\n",
       "<tr><td>4      </td><td>5.0               </td><td>M       </td><td>WHITE </td><td>33-37           </td><td>16.0              </td><td>False            </td><td>4.0                           </td><td>Specialized              </td><td>Less than HS diploma </td><td>nan               </td><td>Violent/Non-Sex </td><td>1-2 years        </td><td>4.0                           </td><td>4.0                         </td><td>nan                            </td><td>2.0                             </td><td>1.0                         </td><td>3.0                                       </td><td>True                             </td><td>False                             </td><td>1.0                               </td><td>0.0                             </td><td>True                            </td><td>0.0                             </td><td>1.0                             </td><td>False                                         </td><td>False                                              </td><td>False                                 </td><td>False                     </td><td>False                        </td><td>True             </td><td>True              </td><td>True             </td><td>False                            </td><td>False                   </td><td>False                    </td><td>False                             </td><td>0.0                  </td><td>7.0                  </td><td>0.0                        </td><td>0.0                </td><td>23.11764706            </td><td>0.0                     </td><td>0.0                         </td><td>0.05882353               </td><td>0.0                       </td><td>0.203562341            </td><td>0.929389313       </td><td>False              </td><td>True                      </td><td>True                     </td><td>False                    </td><td>False                    </td></tr>\n",
       "<tr><td>5      </td><td>7.0               </td><td>M       </td><td>BLACK </td><td>48 or older     </td><td>18.0              </td><td>False            </td><td>2.0                           </td><td>Standard                 </td><td>Less than HS diploma </td><td>2.0               </td><td>nan             </td><td>Less than 1 year </td><td>nan                           </td><td>nan                         </td><td>1.0                            </td><td>nan                             </td><td>1.0                         </td><td>nan                                       </td><td>False                            </td><td>True                              </td><td>nan                               </td><td>1.0                             </td><td>False                           </td><td>nan                             </td><td>0.0                             </td><td>True                                          </td><td>False                                              </td><td>True                                  </td><td>False                     </td><td>False                        </td><td>False            </td><td>False             </td><td>False            </td><td>False                            </td><td>False                   </td><td>False                    </td><td>False                             </td><td>0.0                  </td><td>0.0                  </td><td>0.0                        </td><td>1.0                </td><td>238.5                  </td><td>0.0                     </td><td>0.0                         </td><td>0.0                      </td><td>0.0                       </td><td>0.0                    </td><td>0.0               </td><td>False              </td><td>True                      </td><td>False                    </td><td>False                    </td><td>True                     </td></tr>\n",
       "<tr><td>6      </td><td>9.0               </td><td>F       </td><td>BLACK </td><td>43-47           </td><td>5.0               </td><td>nan              </td><td>7.0                           </td><td>High                     </td><td>High School Diploma  </td><td>0.0               </td><td>Drug            </td><td>Less than 1 year </td><td>nan                           </td><td>4.0                         </td><td>2.0                            </td><td>nan                             </td><td>3.0                         </td><td>3.0                                       </td><td>False                            </td><td>False                             </td><td>2.0                               </td><td>nan                             </td><td>False                           </td><td>nan                             </td><td>nan                             </td><td>True                                          </td><td>False                                              </td><td>False                                 </td><td>False                     </td><td>True                         </td><td>True             </td><td>False             </td><td>False            </td><td>False                            </td><td>False                   </td><td>False                    </td><td>False                             </td><td>0.0                  </td><td>0.0                  </td><td>0.0                        </td><td>0.0                </td><td>nan                    </td><td>nan                     </td><td>nan                         </td><td>nan                      </td><td>nan                       </td><td>0.0                    </td><td>0.0               </td><td>True               </td><td>True                      </td><td>True                     </td><td>False                    </td><td>False                    </td></tr>\n",
       "<tr><td>7      </td><td>10.0              </td><td>M       </td><td>BLACK </td><td>43-47           </td><td>16.0              </td><td>False            </td><td>5.0                           </td><td>Standard                 </td><td>High School Diploma  </td><td>nan               </td><td>Property        </td><td>More than 3 years</td><td>nan                           </td><td>nan                         </td><td>nan                            </td><td>nan                             </td><td>2.0                         </td><td>nan                                       </td><td>True                             </td><td>True                              </td><td>nan                               </td><td>nan                             </td><td>True                            </td><td>nan                             </td><td>nan                             </td><td>True                                          </td><td>True                                               </td><td>True                                  </td><td>False                     </td><td>False                        </td><td>False            </td><td>True              </td><td>True             </td><td>False                            </td><td>False                   </td><td>False                    </td><td>False                             </td><td>0.0                  </td><td>0.0                  </td><td>0.0                        </td><td>0.0                </td><td>27.8                   </td><td>0.0                     </td><td>0.0                         </td><td>0.0                      </td><td>0.0                       </td><td>0.35971223             </td><td>1.0               </td><td>False              </td><td>True                      </td><td>True                     </td><td>False                    </td><td>False                    </td></tr>\n",
       "<tr><td>8      </td><td>11.0              </td><td>M       </td><td>WHITE </td><td>43-47           </td><td>5.0               </td><td>False            </td><td>3.0                           </td><td>Specialized              </td><td>Less than HS diploma </td><td>1.0               </td><td>Violent/Non-Sex </td><td>1-2 years        </td><td>3.0                           </td><td>nan                         </td><td>2.0                            </td><td>1.0                             </td><td>1.0                         </td><td>3.0                                       </td><td>True                             </td><td>False                             </td><td>0.0                               </td><td>3.0                             </td><td>False                           </td><td>0.0                             </td><td>0.0                             </td><td>True                                          </td><td>False                                              </td><td>False                                 </td><td>True                      </td><td>False                        </td><td>True             </td><td>True              </td><td>False            </td><td>True                             </td><td>True                    </td><td>False                    </td><td>False                             </td><td>0.0                  </td><td>9.0                  </td><td>2.0                        </td><td>2.0                </td><td>42.8                   </td><td>0.300000012             </td><td>0.0                         </td><td>0.300000012              </td><td>0.0                       </td><td>1.0                    </td><td>3.413551402       </td><td>True               </td><td>True                      </td><td>False                    </td><td>True                     </td><td>False                    </td></tr>\n",
       "<tr><td>9      </td><td>13.0              </td><td>M       </td><td>WHITE </td><td>48 or older     </td><td>18.0              </td><td>False            </td><td>3.0                           </td><td>Standard                 </td><td>Less than HS diploma </td><td>1.0               </td><td>Property        </td><td>More than 3 years</td><td>8.0                           </td><td>4.0                         </td><td>0.0                            </td><td>nan                             </td><td>2.0                         </td><td>1.0                                       </td><td>False                            </td><td>False                             </td><td>1.0                               </td><td>0.0                             </td><td>False                           </td><td>2.0                             </td><td>1.0                             </td><td>False                                         </td><td>False                                              </td><td>False                                 </td><td>False                     </td><td>False                        </td><td>False            </td><td>False             </td><td>False            </td><td>False                            </td><td>False                   </td><td>False                    </td><td>False                             </td><td>0.0                  </td><td>0.0                  </td><td>0.0                        </td><td>1.0                </td><td>nan                    </td><td>0.0                     </td><td>0.0                         </td><td>0.016055046              </td><td>0.002293578               </td><td>0.0                    </td><td>nan               </td><td>False              </td><td>False                     </td><td>False                    </td><td>False                    </td><td>False                    </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NIJ_Train_Mod_Full.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender', 'Race', 'Age_at_Release', 'Residence_PUMA', 'Gang_Affiliated', 'Supervision_Risk_Score_First', 'Supervision_Level_First', 'Education_Level', 'Dependents', 'Prison_Offense', 'Prison_Years', 'Prior_Arrest_Episodes_Felony', 'Prior_Arrest_Episodes_Misd', 'Prior_Arrest_Episodes_Violent', 'Prior_Arrest_Episodes_Property', 'Prior_Arrest_Episodes_Drug', 'Prior_Arrest_Episodes_PPViolationCharges', 'Prior_Arrest_Episodes_DVCharges', 'Prior_Arrest_Episodes_GunCharges', 'Prior_Conviction_Episodes_Felony', 'Prior_Conviction_Episodes_Misd', 'Prior_Conviction_Episodes_Viol', 'Prior_Conviction_Episodes_Prop', 'Prior_Conviction_Episodes_Drug', 'Prior_Conviction_Episodes_PPViolationCharges', 'Prior_Conviction_Episodes_DomesticViolenceCharges', 'Prior_Conviction_Episodes_GunCharges', 'Prior_Revocations_Parole', 'Prior_Revocations_Probation', 'Condition_MH_SA', 'Condition_Cog_Ed', 'Condition_Other', 'Violations_ElectronicMonitoring', 'Violations_Instruction', 'Violations_FailToReport', 'Violations_MoveWithoutPermission', 'Delinquency_Reports', 'Program_Attendances', 'Program_UnexcusedAbsences', 'Residence_Changes', 'Avg_Days_per_DrugTest', 'DrugTests_THC_Positive', 'DrugTests_Cocaine_Positive', 'DrugTests_Meth_Positive', 'DrugTests_Other_Positive', 'Percent_Days_Employed', 'Jobs_Per_Year', 'Employment_Exempt', 'Recidivism_Arrest_Year1']\n"
     ]
    }
   ],
   "source": [
    "y= \"Recidivism_Arrest_Year1\"\n",
    "NIJ_Train_Mod_Full=NIJ_Train_Mod_Full.drop([\"ID\",\"Recidivism_Within_3years\",\"Recidivism_Arrest_Year2\",\"Recidivism_Arrest_Year3\"],axis=1)\n",
    "x= NIJ_Train_Mod_Full.columns\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |█\n",
      "07:51:19.827: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "███████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml = H2OAutoML(max_models = 10, seed = 1)\n",
    "aml.train(x = x, y = y, training_frame = NIJ_Train_Mod_Full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = aml.leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20210531_075119   </td><td style=\"text-align: right;\">0.867429</td><td style=\"text-align: right;\"> 0.405072</td><td style=\"text-align: right;\">0.722504</td><td style=\"text-align: right;\">              0.218688</td><td style=\"text-align: right;\">0.36581 </td><td style=\"text-align: right;\">0.133817</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20210531_075119                       </td><td style=\"text-align: right;\">0.863819</td><td style=\"text-align: right;\"> 0.410751</td><td style=\"text-align: right;\">0.712971</td><td style=\"text-align: right;\">              0.21805 </td><td style=\"text-align: right;\">0.36834 </td><td style=\"text-align: right;\">0.135675</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20210531_075119</td><td style=\"text-align: right;\">0.86369 </td><td style=\"text-align: right;\"> 0.410467</td><td style=\"text-align: right;\">0.71245 </td><td style=\"text-align: right;\">              0.217817</td><td style=\"text-align: right;\">0.368455</td><td style=\"text-align: right;\">0.135759</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20210531_075119                       </td><td style=\"text-align: right;\">0.863031</td><td style=\"text-align: right;\"> 0.410909</td><td style=\"text-align: right;\">0.714142</td><td style=\"text-align: right;\">              0.222919</td><td style=\"text-align: right;\">0.368593</td><td style=\"text-align: right;\">0.135861</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210531_075119_model_1         </td><td style=\"text-align: right;\">0.86279 </td><td style=\"text-align: right;\"> 0.413372</td><td style=\"text-align: right;\">0.709886</td><td style=\"text-align: right;\">              0.222226</td><td style=\"text-align: right;\">0.369349</td><td style=\"text-align: right;\">0.136419</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20210531_075119                       </td><td style=\"text-align: right;\">0.862121</td><td style=\"text-align: right;\"> 0.412545</td><td style=\"text-align: right;\">0.711536</td><td style=\"text-align: right;\">              0.225639</td><td style=\"text-align: right;\">0.369206</td><td style=\"text-align: right;\">0.136313</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20210531_075119                       </td><td style=\"text-align: right;\">0.86191 </td><td style=\"text-align: right;\"> 0.412633</td><td style=\"text-align: right;\">0.711859</td><td style=\"text-align: right;\">              0.223533</td><td style=\"text-align: right;\">0.369558</td><td style=\"text-align: right;\">0.136573</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20210531_075119                       </td><td style=\"text-align: right;\">0.856164</td><td style=\"text-align: right;\"> 0.421448</td><td style=\"text-align: right;\">0.699796</td><td style=\"text-align: right;\">              0.229361</td><td style=\"text-align: right;\">0.373604</td><td style=\"text-align: right;\">0.13958 </td></tr>\n",
       "<tr><td>DRF_1_AutoML_20210531_075119                       </td><td style=\"text-align: right;\">0.818156</td><td style=\"text-align: right;\"> 0.4755  </td><td style=\"text-align: right;\">0.637941</td><td style=\"text-align: right;\">              0.259268</td><td style=\"text-align: right;\">0.39537 </td><td style=\"text-align: right;\">0.156318</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20210531_075119                       </td><td style=\"text-align: right;\">0.816627</td><td style=\"text-align: right;\"> 0.474861</td><td style=\"text-align: right;\">0.631946</td><td style=\"text-align: right;\">              0.258569</td><td style=\"text-align: right;\">0.396611</td><td style=\"text-align: right;\">0.1573  </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20210531_075119   </td><td style=\"text-align: right;\">0.867429</td><td style=\"text-align: right;\"> 0.405072</td><td style=\"text-align: right;\">0.722504</td><td style=\"text-align: right;\">              0.218688</td><td style=\"text-align: right;\">0.36581 </td><td style=\"text-align: right;\">0.133817</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20210531_075119                       </td><td style=\"text-align: right;\">0.863819</td><td style=\"text-align: right;\"> 0.410751</td><td style=\"text-align: right;\">0.712971</td><td style=\"text-align: right;\">              0.21805 </td><td style=\"text-align: right;\">0.36834 </td><td style=\"text-align: right;\">0.135675</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20210531_075119</td><td style=\"text-align: right;\">0.86369 </td><td style=\"text-align: right;\"> 0.410467</td><td style=\"text-align: right;\">0.71245 </td><td style=\"text-align: right;\">              0.217817</td><td style=\"text-align: right;\">0.368455</td><td style=\"text-align: right;\">0.135759</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20210531_075119                       </td><td style=\"text-align: right;\">0.863031</td><td style=\"text-align: right;\"> 0.410909</td><td style=\"text-align: right;\">0.714142</td><td style=\"text-align: right;\">              0.222919</td><td style=\"text-align: right;\">0.368593</td><td style=\"text-align: right;\">0.135861</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210531_075119_model_1         </td><td style=\"text-align: right;\">0.86279 </td><td style=\"text-align: right;\"> 0.413372</td><td style=\"text-align: right;\">0.709886</td><td style=\"text-align: right;\">              0.222226</td><td style=\"text-align: right;\">0.369349</td><td style=\"text-align: right;\">0.136419</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20210531_075119                       </td><td style=\"text-align: right;\">0.862121</td><td style=\"text-align: right;\"> 0.412545</td><td style=\"text-align: right;\">0.711536</td><td style=\"text-align: right;\">              0.225639</td><td style=\"text-align: right;\">0.369206</td><td style=\"text-align: right;\">0.136313</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20210531_075119                       </td><td style=\"text-align: right;\">0.86191 </td><td style=\"text-align: right;\"> 0.412633</td><td style=\"text-align: right;\">0.711859</td><td style=\"text-align: right;\">              0.223533</td><td style=\"text-align: right;\">0.369558</td><td style=\"text-align: right;\">0.136573</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20210531_075119                       </td><td style=\"text-align: right;\">0.856164</td><td style=\"text-align: right;\"> 0.421448</td><td style=\"text-align: right;\">0.699796</td><td style=\"text-align: right;\">              0.229361</td><td style=\"text-align: right;\">0.373604</td><td style=\"text-align: right;\">0.13958 </td></tr>\n",
       "<tr><td>DRF_1_AutoML_20210531_075119                       </td><td style=\"text-align: right;\">0.818156</td><td style=\"text-align: right;\"> 0.4755  </td><td style=\"text-align: right;\">0.637941</td><td style=\"text-align: right;\">              0.259268</td><td style=\"text-align: right;\">0.39537 </td><td style=\"text-align: right;\">0.156318</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20210531_075119                       </td><td style=\"text-align: right;\">0.816627</td><td style=\"text-align: right;\"> 0.474861</td><td style=\"text-align: right;\">0.631946</td><td style=\"text-align: right;\">              0.258569</td><td style=\"text-align: right;\">0.396611</td><td style=\"text-align: right;\">0.1573  </td></tr>\n",
       "<tr><td>GLM_1_AutoML_20210531_075119                       </td><td style=\"text-align: right;\">0.77016 </td><td style=\"text-align: right;\"> 0.509323</td><td style=\"text-align: right;\">0.562375</td><td style=\"text-align: right;\">              0.29565 </td><td style=\"text-align: right;\">0.412534</td><td style=\"text-align: right;\">0.170184</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20210531_075119              </td><td style=\"text-align: right;\">0.761938</td><td style=\"text-align: right;\"> 0.518214</td><td style=\"text-align: right;\">0.551119</td><td style=\"text-align: right;\">              0.30429 </td><td style=\"text-align: right;\">0.416256</td><td style=\"text-align: right;\">0.173269</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model ids for all models in the AutoML Leaderboard\n",
    "model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n",
    "# Get the \"All Models\" Stacked Ensemble model\n",
    "se = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_AllModels\" in mid][0])\n",
    "# Get the Stacked Ensemble metalearner model\n",
    "metalearner = se.metalearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intercept': -1.5496564831222084,\n",
       " 'GBM_1_AutoML_20210531_075119': 0.4791762582895369,\n",
       " 'GBM_5_AutoML_20210531_075119': 0.5444018409686141,\n",
       " 'GBM_grid__1_AutoML_20210531_075119_model_1': 0.3101906619099289,\n",
       " 'GBM_2_AutoML_20210531_075119': 0.2417140689593273,\n",
       " 'GBM_3_AutoML_20210531_075119': 0.45583713046984486,\n",
       " 'GBM_4_AutoML_20210531_075119': 0.06034087401233019,\n",
       " 'DRF_1_AutoML_20210531_075119': 0.0,\n",
       " 'XRT_1_AutoML_20210531_075119': 0.0,\n",
       " 'GLM_1_AutoML_20210531_075119': 0.0,\n",
       " 'DeepLearning_1_AutoML_20210531_075119': 0.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metalearner.coef_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_AllModels_AutoML_20210531_075119\n",
      "\n",
      "No model summary for this model\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.08797613566372886\n",
      "RMSE: 0.2966077134258798\n",
      "LogLoss: 0.29105461624243056\n",
      "Null degrees of freedom: 10050\n",
      "Residual degrees of freedom: 10044\n",
      "Null deviance: 12311.73937063131\n",
      "Residual deviance: 5850.77989570534\n",
      "AIC: 5864.77989570534\n",
      "AUC: 0.9515930048026316\n",
      "AUCPR: 0.8982699033508889\n",
      "Gini: 0.9031860096052633\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4302824488110038: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>6338.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>(679.0/7017.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>475.0</td>\n",
       "      <td>2559.0</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>(475.0/3034.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>6813.0</td>\n",
       "      <td>3238.0</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>(1154.0/10051.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           False    True   Error               Rate\n",
       "0  False  6338.0   679.0  0.0968     (679.0/7017.0)\n",
       "1   True   475.0  2559.0  0.1566     (475.0/3034.0)\n",
       "2  Total  6813.0  3238.0  0.1148   (1154.0/10051.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.430282</td>\n",
       "      <td>0.816008</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.276527</td>\n",
       "      <td>0.869064</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.553743</td>\n",
       "      <td>0.837080</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.481559</td>\n",
       "      <td>0.886379</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.974181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.037981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.974181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.430282</td>\n",
       "      <td>0.733513</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.387988</td>\n",
       "      <td>0.877868</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.383362</td>\n",
       "      <td>0.879241</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.974181</td>\n",
       "      <td>7017.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.974181</td>\n",
       "      <td>3031.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>7017.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.037981</td>\n",
       "      <td>3034.000000</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.974181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.974181</td>\n",
       "      <td>0.999011</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.037981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.430282     0.816008  192.0\n",
       "1                        max f2   0.276527     0.869064  251.0\n",
       "2                  max f0point5   0.553743     0.837080  144.0\n",
       "3                  max accuracy   0.481559     0.886379  173.0\n",
       "4                 max precision   0.974181     1.000000    0.0\n",
       "5                    max recall   0.037981     1.000000  367.0\n",
       "6               max specificity   0.974181     1.000000    0.0\n",
       "7              max absolute_mcc   0.430282     0.733513  192.0\n",
       "8    max min_per_class_accuracy   0.387988     0.877868  207.0\n",
       "9   max mean_per_class_accuracy   0.383362     0.879241  209.0\n",
       "10                      max tns   0.974181  7017.000000    0.0\n",
       "11                      max fns   0.974181  3031.000000    0.0\n",
       "12                      max fps   0.003444  7017.000000  399.0\n",
       "13                      max tps   0.037981  3034.000000  367.0\n",
       "14                      max tnr   0.974181     1.000000    0.0\n",
       "15                      max fnr   0.974181     0.999011    0.0\n",
       "16                      max fpr   0.003444     1.000000  399.0\n",
       "17                      max tpr   0.037981     1.000000  367.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 30.19 %, avg score: 30.52 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>0.926142</td>\n",
       "      <td>3.312788</td>\n",
       "      <td>3.312788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943750</td>\n",
       "      <td>0.033289</td>\n",
       "      <td>0.033289</td>\n",
       "      <td>231.278840</td>\n",
       "      <td>231.278840</td>\n",
       "      <td>0.033289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020098</td>\n",
       "      <td>0.902219</td>\n",
       "      <td>3.279989</td>\n",
       "      <td>3.296388</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.913435</td>\n",
       "      <td>0.995050</td>\n",
       "      <td>0.928593</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.066249</td>\n",
       "      <td>227.998851</td>\n",
       "      <td>229.638846</td>\n",
       "      <td>0.066107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030047</td>\n",
       "      <td>0.882162</td>\n",
       "      <td>3.246533</td>\n",
       "      <td>3.279880</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.892320</td>\n",
       "      <td>0.990066</td>\n",
       "      <td>0.916582</td>\n",
       "      <td>0.032301</td>\n",
       "      <td>0.098550</td>\n",
       "      <td>224.653263</td>\n",
       "      <td>227.987990</td>\n",
       "      <td>0.098122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040096</td>\n",
       "      <td>0.864775</td>\n",
       "      <td>3.279989</td>\n",
       "      <td>3.279907</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.874587</td>\n",
       "      <td>0.990074</td>\n",
       "      <td>0.906057</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.131510</td>\n",
       "      <td>227.998851</td>\n",
       "      <td>227.990712</td>\n",
       "      <td>0.130940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050045</td>\n",
       "      <td>0.847571</td>\n",
       "      <td>3.246533</td>\n",
       "      <td>3.273272</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.855976</td>\n",
       "      <td>0.988072</td>\n",
       "      <td>0.896101</td>\n",
       "      <td>0.032301</td>\n",
       "      <td>0.163810</td>\n",
       "      <td>224.653263</td>\n",
       "      <td>227.327204</td>\n",
       "      <td>0.162955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100090</td>\n",
       "      <td>0.771225</td>\n",
       "      <td>3.181067</td>\n",
       "      <td>3.227170</td>\n",
       "      <td>0.960239</td>\n",
       "      <td>0.807654</td>\n",
       "      <td>0.974155</td>\n",
       "      <td>0.851877</td>\n",
       "      <td>0.159196</td>\n",
       "      <td>0.323006</td>\n",
       "      <td>218.106719</td>\n",
       "      <td>222.716961</td>\n",
       "      <td>0.319301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150035</td>\n",
       "      <td>0.699943</td>\n",
       "      <td>2.989429</td>\n",
       "      <td>3.148028</td>\n",
       "      <td>0.902390</td>\n",
       "      <td>0.736196</td>\n",
       "      <td>0.950265</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.149308</td>\n",
       "      <td>0.472314</td>\n",
       "      <td>198.942857</td>\n",
       "      <td>214.802770</td>\n",
       "      <td>0.461625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200080</td>\n",
       "      <td>0.622678</td>\n",
       "      <td>2.687113</td>\n",
       "      <td>3.032742</td>\n",
       "      <td>0.811133</td>\n",
       "      <td>0.661125</td>\n",
       "      <td>0.915465</td>\n",
       "      <td>0.775288</td>\n",
       "      <td>0.134476</td>\n",
       "      <td>0.606790</td>\n",
       "      <td>168.711266</td>\n",
       "      <td>203.274164</td>\n",
       "      <td>0.582563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300070</td>\n",
       "      <td>0.464692</td>\n",
       "      <td>2.004155</td>\n",
       "      <td>2.689993</td>\n",
       "      <td>0.604975</td>\n",
       "      <td>0.544198</td>\n",
       "      <td>0.812003</td>\n",
       "      <td>0.698284</td>\n",
       "      <td>0.200396</td>\n",
       "      <td>0.807185</td>\n",
       "      <td>100.415457</td>\n",
       "      <td>168.999297</td>\n",
       "      <td>0.726381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400060</td>\n",
       "      <td>0.317557</td>\n",
       "      <td>1.137226</td>\n",
       "      <td>2.301898</td>\n",
       "      <td>0.343284</td>\n",
       "      <td>0.388690</td>\n",
       "      <td>0.694852</td>\n",
       "      <td>0.620905</td>\n",
       "      <td>0.113711</td>\n",
       "      <td>0.920897</td>\n",
       "      <td>13.722587</td>\n",
       "      <td>130.189773</td>\n",
       "      <td>0.746035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500050</td>\n",
       "      <td>0.206286</td>\n",
       "      <td>0.507631</td>\n",
       "      <td>1.943116</td>\n",
       "      <td>0.153234</td>\n",
       "      <td>0.258364</td>\n",
       "      <td>0.586550</td>\n",
       "      <td>0.548411</td>\n",
       "      <td>0.050758</td>\n",
       "      <td>0.971655</td>\n",
       "      <td>-49.236874</td>\n",
       "      <td>94.311584</td>\n",
       "      <td>0.675517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600040</td>\n",
       "      <td>0.121078</td>\n",
       "      <td>0.224149</td>\n",
       "      <td>1.656669</td>\n",
       "      <td>0.067662</td>\n",
       "      <td>0.161446</td>\n",
       "      <td>0.500083</td>\n",
       "      <td>0.483927</td>\n",
       "      <td>0.022413</td>\n",
       "      <td>0.994067</td>\n",
       "      <td>-77.585113</td>\n",
       "      <td>65.666885</td>\n",
       "      <td>0.564396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.700030</td>\n",
       "      <td>0.058764</td>\n",
       "      <td>0.056037</td>\n",
       "      <td>1.428040</td>\n",
       "      <td>0.016915</td>\n",
       "      <td>0.088168</td>\n",
       "      <td>0.431069</td>\n",
       "      <td>0.427398</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>-94.396278</td>\n",
       "      <td>42.803968</td>\n",
       "      <td>0.429199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.800020</td>\n",
       "      <td>0.022792</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>1.249969</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.038795</td>\n",
       "      <td>0.377316</td>\n",
       "      <td>0.378829</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-99.670369</td>\n",
       "      <td>24.996891</td>\n",
       "      <td>0.286447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.900010</td>\n",
       "      <td>0.009815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.335397</td>\n",
       "      <td>0.338429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.109883</td>\n",
       "      <td>0.143224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.301861</td>\n",
       "      <td>0.305239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010049         0.926142  3.312788   \n",
       "1       2                  0.020098         0.902219  3.279989   \n",
       "2       3                  0.030047         0.882162  3.246533   \n",
       "3       4                  0.040096         0.864775  3.279989   \n",
       "4       5                  0.050045         0.847571  3.246533   \n",
       "5       6                  0.100090         0.771225  3.181067   \n",
       "6       7                  0.150035         0.699943  2.989429   \n",
       "7       8                  0.200080         0.622678  2.687113   \n",
       "8       9                  0.300070         0.464692  2.004155   \n",
       "9      10                  0.400060         0.317557  1.137226   \n",
       "10     11                  0.500050         0.206286  0.507631   \n",
       "11     12                  0.600040         0.121078  0.224149   \n",
       "12     13                  0.700030         0.058764  0.056037   \n",
       "13     14                  0.800020         0.022792  0.003296   \n",
       "14     15                  0.900010         0.009815  0.000000   \n",
       "15     16                  1.000000         0.002325  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          3.312788       1.000000  0.943750                  1.000000   \n",
       "1          3.296388       0.990099  0.913435                  0.995050   \n",
       "2          3.279880       0.980000  0.892320                  0.990066   \n",
       "3          3.279907       0.990099  0.874587                  0.990074   \n",
       "4          3.273272       0.980000  0.855976                  0.988072   \n",
       "5          3.227170       0.960239  0.807654                  0.974155   \n",
       "6          3.148028       0.902390  0.736196                  0.950265   \n",
       "7          3.032742       0.811133  0.661125                  0.915465   \n",
       "8          2.689993       0.604975  0.544198                  0.812003   \n",
       "9          2.301898       0.343284  0.388690                  0.694852   \n",
       "10         1.943116       0.153234  0.258364                  0.586550   \n",
       "11         1.656669       0.067662  0.161446                  0.500083   \n",
       "12         1.428040       0.016915  0.088168                  0.431069   \n",
       "13         1.249969       0.000995  0.038795                  0.377316   \n",
       "14         1.111099       0.000000  0.015190                  0.335397   \n",
       "15         1.000000       0.000000  0.006494                  0.301861   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.943750      0.033289                 0.033289  231.278840   \n",
       "1           0.928593      0.032960                 0.066249  227.998851   \n",
       "2           0.916582      0.032301                 0.098550  224.653263   \n",
       "3           0.906057      0.032960                 0.131510  227.998851   \n",
       "4           0.896101      0.032301                 0.163810  224.653263   \n",
       "5           0.851877      0.159196                 0.323006  218.106719   \n",
       "6           0.813368      0.149308                 0.472314  198.942857   \n",
       "7           0.775288      0.134476                 0.606790  168.711266   \n",
       "8           0.698284      0.200396                 0.807185  100.415457   \n",
       "9           0.620905      0.113711                 0.920897   13.722587   \n",
       "10          0.548411      0.050758                 0.971655  -49.236874   \n",
       "11          0.483927      0.022413                 0.994067  -77.585113   \n",
       "12          0.427398      0.005603                 0.999670  -94.396278   \n",
       "13          0.378829      0.000330                 1.000000  -99.670369   \n",
       "14          0.338429      0.000000                 1.000000 -100.000000   \n",
       "15          0.305239      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        231.278840            0.033289  \n",
       "1        229.638846            0.066107  \n",
       "2        227.987990            0.098122  \n",
       "3        227.990712            0.130940  \n",
       "4        227.327204            0.162955  \n",
       "5        222.716961            0.319301  \n",
       "6        214.802770            0.461625  \n",
       "7        203.274164            0.582563  \n",
       "8        168.999297            0.726381  \n",
       "9        130.189773            0.746035  \n",
       "10        94.311584            0.675517  \n",
       "11        65.666885            0.564396  \n",
       "12        42.803968            0.429199  \n",
       "13        24.996891            0.286447  \n",
       "14        11.109883            0.143224  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.13381720734600047\n",
      "RMSE: 0.3658103434103531\n",
      "LogLoss: 0.4050717126315097\n",
      "Null degrees of freedom: 18027\n",
      "Residual degrees of freedom: 18021\n",
      "Null deviance: 21973.61593555157\n",
      "Residual deviance: 14605.265670641711\n",
      "AIC: 14619.265670641711\n",
      "AUC: 0.8674286076676544\n",
      "AUCPR: 0.7225042941628982\n",
      "Gini: 0.7348572153353088\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3377251597766589: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>9807.0</td>\n",
       "      <td>2844.0</td>\n",
       "      <td>0.2248</td>\n",
       "      <td>(2844.0/12651.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>4234.0</td>\n",
       "      <td>0.2126</td>\n",
       "      <td>(1143.0/5377.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>10950.0</td>\n",
       "      <td>7078.0</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>(3987.0/18028.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            False    True   Error               Rate\n",
       "0  False   9807.0  2844.0  0.2248   (2844.0/12651.0)\n",
       "1   True   1143.0  4234.0  0.2126    (1143.0/5377.0)\n",
       "2  Total  10950.0  7078.0  0.2212   (3987.0/18028.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.337725</td>\n",
       "      <td>0.679888</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.132925</td>\n",
       "      <td>0.791813</td>\n",
       "      <td>316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.525035</td>\n",
       "      <td>0.670761</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.441898</td>\n",
       "      <td>0.799756</td>\n",
       "      <td>187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.973791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.973791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.386202</td>\n",
       "      <td>0.529971</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.343187</td>\n",
       "      <td>0.779148</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.300887</td>\n",
       "      <td>0.783031</td>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.973791</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.973791</td>\n",
       "      <td>5373.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>5377.000000</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.973791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.973791</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.337725      0.679888  228.0\n",
       "1                        max f2   0.132925      0.791813  316.0\n",
       "2                  max f0point5   0.525035      0.670761  157.0\n",
       "3                  max accuracy   0.441898      0.799756  187.0\n",
       "4                 max precision   0.973791      1.000000    0.0\n",
       "5                    max recall   0.012138      1.000000  389.0\n",
       "6               max specificity   0.973791      1.000000    0.0\n",
       "7              max absolute_mcc   0.386202      0.529971  209.0\n",
       "8    max min_per_class_accuracy   0.343187      0.779148  226.0\n",
       "9   max mean_per_class_accuracy   0.300887      0.783031  244.0\n",
       "10                      max tns   0.973791  12651.000000    0.0\n",
       "11                      max fns   0.973791   5373.000000    0.0\n",
       "12                      max fps   0.003564  12651.000000  399.0\n",
       "13                      max tps   0.012138   5377.000000  389.0\n",
       "14                      max tnr   0.973791      1.000000    0.0\n",
       "15                      max fnr   0.973791      0.999256    0.0\n",
       "16                      max fpr   0.003564      1.000000  399.0\n",
       "17                      max tpr   0.012138      1.000000  389.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 29.83 %, avg score: 29.83 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.914219</td>\n",
       "      <td>3.130514</td>\n",
       "      <td>3.130514</td>\n",
       "      <td>0.933702</td>\n",
       "      <td>0.935570</td>\n",
       "      <td>0.933702</td>\n",
       "      <td>0.935570</td>\n",
       "      <td>0.031430</td>\n",
       "      <td>0.031430</td>\n",
       "      <td>213.051394</td>\n",
       "      <td>213.051394</td>\n",
       "      <td>0.030482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020024</td>\n",
       "      <td>0.886245</td>\n",
       "      <td>3.073399</td>\n",
       "      <td>3.102036</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.898408</td>\n",
       "      <td>0.925208</td>\n",
       "      <td>0.917041</td>\n",
       "      <td>0.030686</td>\n",
       "      <td>0.062116</td>\n",
       "      <td>207.339905</td>\n",
       "      <td>210.203560</td>\n",
       "      <td>0.059982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030009</td>\n",
       "      <td>0.863920</td>\n",
       "      <td>2.998892</td>\n",
       "      <td>3.067718</td>\n",
       "      <td>0.894444</td>\n",
       "      <td>0.875417</td>\n",
       "      <td>0.914972</td>\n",
       "      <td>0.903192</td>\n",
       "      <td>0.029942</td>\n",
       "      <td>0.092059</td>\n",
       "      <td>199.889240</td>\n",
       "      <td>206.771809</td>\n",
       "      <td>0.088423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040049</td>\n",
       "      <td>0.842150</td>\n",
       "      <td>2.889705</td>\n",
       "      <td>3.023092</td>\n",
       "      <td>0.861878</td>\n",
       "      <td>0.852007</td>\n",
       "      <td>0.901662</td>\n",
       "      <td>0.890360</td>\n",
       "      <td>0.029012</td>\n",
       "      <td>0.121071</td>\n",
       "      <td>188.970518</td>\n",
       "      <td>202.309158</td>\n",
       "      <td>0.115459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050033</td>\n",
       "      <td>0.822079</td>\n",
       "      <td>2.775372</td>\n",
       "      <td>2.973658</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.830701</td>\n",
       "      <td>0.886918</td>\n",
       "      <td>0.878455</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>0.148782</td>\n",
       "      <td>177.537247</td>\n",
       "      <td>197.365761</td>\n",
       "      <td>0.140719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>0.734881</td>\n",
       "      <td>2.571347</td>\n",
       "      <td>2.772614</td>\n",
       "      <td>0.766926</td>\n",
       "      <td>0.777097</td>\n",
       "      <td>0.826955</td>\n",
       "      <td>0.827804</td>\n",
       "      <td>0.128510</td>\n",
       "      <td>0.277292</td>\n",
       "      <td>157.134748</td>\n",
       "      <td>177.261411</td>\n",
       "      <td>0.252630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150044</td>\n",
       "      <td>0.661094</td>\n",
       "      <td>2.312019</td>\n",
       "      <td>2.619026</td>\n",
       "      <td>0.689579</td>\n",
       "      <td>0.696277</td>\n",
       "      <td>0.781146</td>\n",
       "      <td>0.783946</td>\n",
       "      <td>0.115678</td>\n",
       "      <td>0.392970</td>\n",
       "      <td>131.201879</td>\n",
       "      <td>161.902558</td>\n",
       "      <td>0.346175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.586512</td>\n",
       "      <td>1.946186</td>\n",
       "      <td>2.450909</td>\n",
       "      <td>0.580466</td>\n",
       "      <td>0.624078</td>\n",
       "      <td>0.731004</td>\n",
       "      <td>0.744001</td>\n",
       "      <td>0.097266</td>\n",
       "      <td>0.490236</td>\n",
       "      <td>94.618630</td>\n",
       "      <td>145.090906</td>\n",
       "      <td>0.413562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300033</td>\n",
       "      <td>0.449108</td>\n",
       "      <td>1.746133</td>\n",
       "      <td>2.215984</td>\n",
       "      <td>0.520799</td>\n",
       "      <td>0.517122</td>\n",
       "      <td>0.660935</td>\n",
       "      <td>0.668375</td>\n",
       "      <td>0.174633</td>\n",
       "      <td>0.664869</td>\n",
       "      <td>74.613323</td>\n",
       "      <td>121.598378</td>\n",
       "      <td>0.519900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399989</td>\n",
       "      <td>0.327418</td>\n",
       "      <td>1.298698</td>\n",
       "      <td>1.986758</td>\n",
       "      <td>0.387347</td>\n",
       "      <td>0.386475</td>\n",
       "      <td>0.592567</td>\n",
       "      <td>0.597929</td>\n",
       "      <td>0.129812</td>\n",
       "      <td>0.794681</td>\n",
       "      <td>29.869793</td>\n",
       "      <td>98.675772</td>\n",
       "      <td>0.562446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.216124</td>\n",
       "      <td>0.940941</td>\n",
       "      <td>1.777571</td>\n",
       "      <td>0.280643</td>\n",
       "      <td>0.269911</td>\n",
       "      <td>0.530175</td>\n",
       "      <td>0.532318</td>\n",
       "      <td>0.094105</td>\n",
       "      <td>0.888786</td>\n",
       "      <td>-5.905919</td>\n",
       "      <td>77.757114</td>\n",
       "      <td>0.554029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600011</td>\n",
       "      <td>0.126088</td>\n",
       "      <td>0.617376</td>\n",
       "      <td>1.584187</td>\n",
       "      <td>0.184138</td>\n",
       "      <td>0.167997</td>\n",
       "      <td>0.472497</td>\n",
       "      <td>0.471592</td>\n",
       "      <td>0.061744</td>\n",
       "      <td>0.950530</td>\n",
       "      <td>-38.262382</td>\n",
       "      <td>58.418743</td>\n",
       "      <td>0.499498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699967</td>\n",
       "      <td>0.060706</td>\n",
       "      <td>0.347932</td>\n",
       "      <td>1.407649</td>\n",
       "      <td>0.103774</td>\n",
       "      <td>0.091942</td>\n",
       "      <td>0.419843</td>\n",
       "      <td>0.417378</td>\n",
       "      <td>0.034778</td>\n",
       "      <td>0.985308</td>\n",
       "      <td>-65.206803</td>\n",
       "      <td>40.764949</td>\n",
       "      <td>0.406618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799978</td>\n",
       "      <td>0.023375</td>\n",
       "      <td>0.137608</td>\n",
       "      <td>1.248872</td>\n",
       "      <td>0.041043</td>\n",
       "      <td>0.039681</td>\n",
       "      <td>0.372486</td>\n",
       "      <td>0.370159</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>0.999070</td>\n",
       "      <td>-86.239206</td>\n",
       "      <td>24.887228</td>\n",
       "      <td>0.283712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899989</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>1.111125</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.015291</td>\n",
       "      <td>0.331402</td>\n",
       "      <td>0.330725</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-99.070217</td>\n",
       "      <td>11.112481</td>\n",
       "      <td>0.142518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006586</td>\n",
       "      <td>0.298258</td>\n",
       "      <td>0.298307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010040         0.914219  3.130514   \n",
       "1       2                  0.020024         0.886245  3.073399   \n",
       "2       3                  0.030009         0.863920  2.998892   \n",
       "3       4                  0.040049         0.842150  2.889705   \n",
       "4       5                  0.050033         0.822079  2.775372   \n",
       "5       6                  0.100011         0.734881  2.571347   \n",
       "6       7                  0.150044         0.661094  2.312019   \n",
       "7       8                  0.200022         0.586512  1.946186   \n",
       "8       9                  0.300033         0.449108  1.746133   \n",
       "9      10                  0.399989         0.327418  1.298698   \n",
       "10     11                  0.500000         0.216124  0.940941   \n",
       "11     12                  0.600011         0.126088  0.617376   \n",
       "12     13                  0.699967         0.060706  0.347932   \n",
       "13     14                  0.799978         0.023375  0.137608   \n",
       "14     15                  0.899989         0.009756  0.009298   \n",
       "15     16                  1.000000         0.002274  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          3.130514       0.933702  0.935570                  0.933702   \n",
       "1          3.102036       0.916667  0.898408                  0.925208   \n",
       "2          3.067718       0.894444  0.875417                  0.914972   \n",
       "3          3.023092       0.861878  0.852007                  0.901662   \n",
       "4          2.973658       0.827778  0.830701                  0.886918   \n",
       "5          2.772614       0.766926  0.777097                  0.826955   \n",
       "6          2.619026       0.689579  0.696277                  0.781146   \n",
       "7          2.450909       0.580466  0.624078                  0.731004   \n",
       "8          2.215984       0.520799  0.517122                  0.660935   \n",
       "9          1.986758       0.387347  0.386475                  0.592567   \n",
       "10         1.777571       0.280643  0.269911                  0.530175   \n",
       "11         1.584187       0.184138  0.167997                  0.472497   \n",
       "12         1.407649       0.103774  0.091942                  0.419843   \n",
       "13         1.248872       0.041043  0.039681                  0.372486   \n",
       "14         1.111125       0.002773  0.015291                  0.331402   \n",
       "15         1.000000       0.000000  0.006586                  0.298258   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.935570      0.031430                 0.031430  213.051394   \n",
       "1           0.917041      0.030686                 0.062116  207.339905   \n",
       "2           0.903192      0.029942                 0.092059  199.889240   \n",
       "3           0.890360      0.029012                 0.121071  188.970518   \n",
       "4           0.878455      0.027711                 0.148782  177.537247   \n",
       "5           0.827804      0.128510                 0.277292  157.134748   \n",
       "6           0.783946      0.115678                 0.392970  131.201879   \n",
       "7           0.744001      0.097266                 0.490236   94.618630   \n",
       "8           0.668375      0.174633                 0.664869   74.613323   \n",
       "9           0.597929      0.129812                 0.794681   29.869793   \n",
       "10          0.532318      0.094105                 0.888786   -5.905919   \n",
       "11          0.471592      0.061744                 0.950530  -38.262382   \n",
       "12          0.417378      0.034778                 0.985308  -65.206803   \n",
       "13          0.370159      0.013762                 0.999070  -86.239206   \n",
       "14          0.330725      0.000930                 1.000000  -99.070217   \n",
       "15          0.298307      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        213.051394            0.030482  \n",
       "1        210.203560            0.059982  \n",
       "2        206.771809            0.088423  \n",
       "3        202.309158            0.115459  \n",
       "4        197.365761            0.140719  \n",
       "5        177.261411            0.252630  \n",
       "6        161.902558            0.346175  \n",
       "7        145.090906            0.413562  \n",
       "8        121.598378            0.519900  \n",
       "9         98.675772            0.562446  \n",
       "10        77.757114            0.554029  \n",
       "11        58.418743            0.499498  \n",
       "12        40.764949            0.406618  \n",
       "13        24.887228            0.283712  \n",
       "14        11.112481            0.142518  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OBinomialModel.confusion_matrix of >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_AllModels_AutoML_20210531_075119\n",
      "\n",
      "No model summary for this model\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.08797613566372886\n",
      "RMSE: 0.2966077134258798\n",
      "LogLoss: 0.29105461624243056\n",
      "Null degrees of freedom: 10050\n",
      "Residual degrees of freedom: 10044\n",
      "Null deviance: 12311.73937063131\n",
      "Residual deviance: 5850.77989570534\n",
      "AIC: 5864.77989570534\n",
      "AUC: 0.9515930048026316\n",
      "AUCPR: 0.8982699033508889\n",
      "Gini: 0.9031860096052633\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4302824488110038: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>6338.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>(679.0/7017.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>475.0</td>\n",
       "      <td>2559.0</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>(475.0/3034.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>6813.0</td>\n",
       "      <td>3238.0</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>(1154.0/10051.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           False    True   Error               Rate\n",
       "0  False  6338.0   679.0  0.0968     (679.0/7017.0)\n",
       "1   True   475.0  2559.0  0.1566     (475.0/3034.0)\n",
       "2  Total  6813.0  3238.0  0.1148   (1154.0/10051.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.430282</td>\n",
       "      <td>0.816008</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.276527</td>\n",
       "      <td>0.869064</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.553743</td>\n",
       "      <td>0.837080</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.481559</td>\n",
       "      <td>0.886379</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.974181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.037981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.974181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.430282</td>\n",
       "      <td>0.733513</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.387988</td>\n",
       "      <td>0.877868</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.383362</td>\n",
       "      <td>0.879241</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.974181</td>\n",
       "      <td>7017.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.974181</td>\n",
       "      <td>3031.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>7017.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.037981</td>\n",
       "      <td>3034.000000</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.974181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.974181</td>\n",
       "      <td>0.999011</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.037981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.430282     0.816008  192.0\n",
       "1                        max f2   0.276527     0.869064  251.0\n",
       "2                  max f0point5   0.553743     0.837080  144.0\n",
       "3                  max accuracy   0.481559     0.886379  173.0\n",
       "4                 max precision   0.974181     1.000000    0.0\n",
       "5                    max recall   0.037981     1.000000  367.0\n",
       "6               max specificity   0.974181     1.000000    0.0\n",
       "7              max absolute_mcc   0.430282     0.733513  192.0\n",
       "8    max min_per_class_accuracy   0.387988     0.877868  207.0\n",
       "9   max mean_per_class_accuracy   0.383362     0.879241  209.0\n",
       "10                      max tns   0.974181  7017.000000    0.0\n",
       "11                      max fns   0.974181  3031.000000    0.0\n",
       "12                      max fps   0.003444  7017.000000  399.0\n",
       "13                      max tps   0.037981  3034.000000  367.0\n",
       "14                      max tnr   0.974181     1.000000    0.0\n",
       "15                      max fnr   0.974181     0.999011    0.0\n",
       "16                      max fpr   0.003444     1.000000  399.0\n",
       "17                      max tpr   0.037981     1.000000  367.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 30.19 %, avg score: 30.52 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>0.926142</td>\n",
       "      <td>3.312788</td>\n",
       "      <td>3.312788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943750</td>\n",
       "      <td>0.033289</td>\n",
       "      <td>0.033289</td>\n",
       "      <td>231.278840</td>\n",
       "      <td>231.278840</td>\n",
       "      <td>0.033289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020098</td>\n",
       "      <td>0.902219</td>\n",
       "      <td>3.279989</td>\n",
       "      <td>3.296388</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.913435</td>\n",
       "      <td>0.995050</td>\n",
       "      <td>0.928593</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.066249</td>\n",
       "      <td>227.998851</td>\n",
       "      <td>229.638846</td>\n",
       "      <td>0.066107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030047</td>\n",
       "      <td>0.882162</td>\n",
       "      <td>3.246533</td>\n",
       "      <td>3.279880</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.892320</td>\n",
       "      <td>0.990066</td>\n",
       "      <td>0.916582</td>\n",
       "      <td>0.032301</td>\n",
       "      <td>0.098550</td>\n",
       "      <td>224.653263</td>\n",
       "      <td>227.987990</td>\n",
       "      <td>0.098122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040096</td>\n",
       "      <td>0.864775</td>\n",
       "      <td>3.279989</td>\n",
       "      <td>3.279907</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.874587</td>\n",
       "      <td>0.990074</td>\n",
       "      <td>0.906057</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.131510</td>\n",
       "      <td>227.998851</td>\n",
       "      <td>227.990712</td>\n",
       "      <td>0.130940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050045</td>\n",
       "      <td>0.847571</td>\n",
       "      <td>3.246533</td>\n",
       "      <td>3.273272</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.855976</td>\n",
       "      <td>0.988072</td>\n",
       "      <td>0.896101</td>\n",
       "      <td>0.032301</td>\n",
       "      <td>0.163810</td>\n",
       "      <td>224.653263</td>\n",
       "      <td>227.327204</td>\n",
       "      <td>0.162955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100090</td>\n",
       "      <td>0.771225</td>\n",
       "      <td>3.181067</td>\n",
       "      <td>3.227170</td>\n",
       "      <td>0.960239</td>\n",
       "      <td>0.807654</td>\n",
       "      <td>0.974155</td>\n",
       "      <td>0.851877</td>\n",
       "      <td>0.159196</td>\n",
       "      <td>0.323006</td>\n",
       "      <td>218.106719</td>\n",
       "      <td>222.716961</td>\n",
       "      <td>0.319301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150035</td>\n",
       "      <td>0.699943</td>\n",
       "      <td>2.989429</td>\n",
       "      <td>3.148028</td>\n",
       "      <td>0.902390</td>\n",
       "      <td>0.736196</td>\n",
       "      <td>0.950265</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.149308</td>\n",
       "      <td>0.472314</td>\n",
       "      <td>198.942857</td>\n",
       "      <td>214.802770</td>\n",
       "      <td>0.461625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200080</td>\n",
       "      <td>0.622678</td>\n",
       "      <td>2.687113</td>\n",
       "      <td>3.032742</td>\n",
       "      <td>0.811133</td>\n",
       "      <td>0.661125</td>\n",
       "      <td>0.915465</td>\n",
       "      <td>0.775288</td>\n",
       "      <td>0.134476</td>\n",
       "      <td>0.606790</td>\n",
       "      <td>168.711266</td>\n",
       "      <td>203.274164</td>\n",
       "      <td>0.582563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300070</td>\n",
       "      <td>0.464692</td>\n",
       "      <td>2.004155</td>\n",
       "      <td>2.689993</td>\n",
       "      <td>0.604975</td>\n",
       "      <td>0.544198</td>\n",
       "      <td>0.812003</td>\n",
       "      <td>0.698284</td>\n",
       "      <td>0.200396</td>\n",
       "      <td>0.807185</td>\n",
       "      <td>100.415457</td>\n",
       "      <td>168.999297</td>\n",
       "      <td>0.726381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400060</td>\n",
       "      <td>0.317557</td>\n",
       "      <td>1.137226</td>\n",
       "      <td>2.301898</td>\n",
       "      <td>0.343284</td>\n",
       "      <td>0.388690</td>\n",
       "      <td>0.694852</td>\n",
       "      <td>0.620905</td>\n",
       "      <td>0.113711</td>\n",
       "      <td>0.920897</td>\n",
       "      <td>13.722587</td>\n",
       "      <td>130.189773</td>\n",
       "      <td>0.746035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500050</td>\n",
       "      <td>0.206286</td>\n",
       "      <td>0.507631</td>\n",
       "      <td>1.943116</td>\n",
       "      <td>0.153234</td>\n",
       "      <td>0.258364</td>\n",
       "      <td>0.586550</td>\n",
       "      <td>0.548411</td>\n",
       "      <td>0.050758</td>\n",
       "      <td>0.971655</td>\n",
       "      <td>-49.236874</td>\n",
       "      <td>94.311584</td>\n",
       "      <td>0.675517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600040</td>\n",
       "      <td>0.121078</td>\n",
       "      <td>0.224149</td>\n",
       "      <td>1.656669</td>\n",
       "      <td>0.067662</td>\n",
       "      <td>0.161446</td>\n",
       "      <td>0.500083</td>\n",
       "      <td>0.483927</td>\n",
       "      <td>0.022413</td>\n",
       "      <td>0.994067</td>\n",
       "      <td>-77.585113</td>\n",
       "      <td>65.666885</td>\n",
       "      <td>0.564396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.700030</td>\n",
       "      <td>0.058764</td>\n",
       "      <td>0.056037</td>\n",
       "      <td>1.428040</td>\n",
       "      <td>0.016915</td>\n",
       "      <td>0.088168</td>\n",
       "      <td>0.431069</td>\n",
       "      <td>0.427398</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>-94.396278</td>\n",
       "      <td>42.803968</td>\n",
       "      <td>0.429199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.800020</td>\n",
       "      <td>0.022792</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>1.249969</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.038795</td>\n",
       "      <td>0.377316</td>\n",
       "      <td>0.378829</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-99.670369</td>\n",
       "      <td>24.996891</td>\n",
       "      <td>0.286447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.900010</td>\n",
       "      <td>0.009815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.335397</td>\n",
       "      <td>0.338429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.109883</td>\n",
       "      <td>0.143224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.301861</td>\n",
       "      <td>0.305239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010049         0.926142  3.312788   \n",
       "1       2                  0.020098         0.902219  3.279989   \n",
       "2       3                  0.030047         0.882162  3.246533   \n",
       "3       4                  0.040096         0.864775  3.279989   \n",
       "4       5                  0.050045         0.847571  3.246533   \n",
       "5       6                  0.100090         0.771225  3.181067   \n",
       "6       7                  0.150035         0.699943  2.989429   \n",
       "7       8                  0.200080         0.622678  2.687113   \n",
       "8       9                  0.300070         0.464692  2.004155   \n",
       "9      10                  0.400060         0.317557  1.137226   \n",
       "10     11                  0.500050         0.206286  0.507631   \n",
       "11     12                  0.600040         0.121078  0.224149   \n",
       "12     13                  0.700030         0.058764  0.056037   \n",
       "13     14                  0.800020         0.022792  0.003296   \n",
       "14     15                  0.900010         0.009815  0.000000   \n",
       "15     16                  1.000000         0.002325  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          3.312788       1.000000  0.943750                  1.000000   \n",
       "1          3.296388       0.990099  0.913435                  0.995050   \n",
       "2          3.279880       0.980000  0.892320                  0.990066   \n",
       "3          3.279907       0.990099  0.874587                  0.990074   \n",
       "4          3.273272       0.980000  0.855976                  0.988072   \n",
       "5          3.227170       0.960239  0.807654                  0.974155   \n",
       "6          3.148028       0.902390  0.736196                  0.950265   \n",
       "7          3.032742       0.811133  0.661125                  0.915465   \n",
       "8          2.689993       0.604975  0.544198                  0.812003   \n",
       "9          2.301898       0.343284  0.388690                  0.694852   \n",
       "10         1.943116       0.153234  0.258364                  0.586550   \n",
       "11         1.656669       0.067662  0.161446                  0.500083   \n",
       "12         1.428040       0.016915  0.088168                  0.431069   \n",
       "13         1.249969       0.000995  0.038795                  0.377316   \n",
       "14         1.111099       0.000000  0.015190                  0.335397   \n",
       "15         1.000000       0.000000  0.006494                  0.301861   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.943750      0.033289                 0.033289  231.278840   \n",
       "1           0.928593      0.032960                 0.066249  227.998851   \n",
       "2           0.916582      0.032301                 0.098550  224.653263   \n",
       "3           0.906057      0.032960                 0.131510  227.998851   \n",
       "4           0.896101      0.032301                 0.163810  224.653263   \n",
       "5           0.851877      0.159196                 0.323006  218.106719   \n",
       "6           0.813368      0.149308                 0.472314  198.942857   \n",
       "7           0.775288      0.134476                 0.606790  168.711266   \n",
       "8           0.698284      0.200396                 0.807185  100.415457   \n",
       "9           0.620905      0.113711                 0.920897   13.722587   \n",
       "10          0.548411      0.050758                 0.971655  -49.236874   \n",
       "11          0.483927      0.022413                 0.994067  -77.585113   \n",
       "12          0.427398      0.005603                 0.999670  -94.396278   \n",
       "13          0.378829      0.000330                 1.000000  -99.670369   \n",
       "14          0.338429      0.000000                 1.000000 -100.000000   \n",
       "15          0.305239      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        231.278840            0.033289  \n",
       "1        229.638846            0.066107  \n",
       "2        227.987990            0.098122  \n",
       "3        227.990712            0.130940  \n",
       "4        227.327204            0.162955  \n",
       "5        222.716961            0.319301  \n",
       "6        214.802770            0.461625  \n",
       "7        203.274164            0.582563  \n",
       "8        168.999297            0.726381  \n",
       "9        130.189773            0.746035  \n",
       "10        94.311584            0.675517  \n",
       "11        65.666885            0.564396  \n",
       "12        42.803968            0.429199  \n",
       "13        24.996891            0.286447  \n",
       "14        11.109883            0.143224  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.13381720734600047\n",
      "RMSE: 0.3658103434103531\n",
      "LogLoss: 0.4050717126315097\n",
      "Null degrees of freedom: 18027\n",
      "Residual degrees of freedom: 18021\n",
      "Null deviance: 21973.61593555157\n",
      "Residual deviance: 14605.265670641711\n",
      "AIC: 14619.265670641711\n",
      "AUC: 0.8674286076676544\n",
      "AUCPR: 0.7225042941628982\n",
      "Gini: 0.7348572153353088\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3377251597766589: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>9807.0</td>\n",
       "      <td>2844.0</td>\n",
       "      <td>0.2248</td>\n",
       "      <td>(2844.0/12651.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>4234.0</td>\n",
       "      <td>0.2126</td>\n",
       "      <td>(1143.0/5377.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>10950.0</td>\n",
       "      <td>7078.0</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>(3987.0/18028.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            False    True   Error               Rate\n",
       "0  False   9807.0  2844.0  0.2248   (2844.0/12651.0)\n",
       "1   True   1143.0  4234.0  0.2126    (1143.0/5377.0)\n",
       "2  Total  10950.0  7078.0  0.2212   (3987.0/18028.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.337725</td>\n",
       "      <td>0.679888</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.132925</td>\n",
       "      <td>0.791813</td>\n",
       "      <td>316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.525035</td>\n",
       "      <td>0.670761</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.441898</td>\n",
       "      <td>0.799756</td>\n",
       "      <td>187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.973791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.973791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.386202</td>\n",
       "      <td>0.529971</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.343187</td>\n",
       "      <td>0.779148</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.300887</td>\n",
       "      <td>0.783031</td>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.973791</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.973791</td>\n",
       "      <td>5373.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>5377.000000</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.973791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.973791</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.337725      0.679888  228.0\n",
       "1                        max f2   0.132925      0.791813  316.0\n",
       "2                  max f0point5   0.525035      0.670761  157.0\n",
       "3                  max accuracy   0.441898      0.799756  187.0\n",
       "4                 max precision   0.973791      1.000000    0.0\n",
       "5                    max recall   0.012138      1.000000  389.0\n",
       "6               max specificity   0.973791      1.000000    0.0\n",
       "7              max absolute_mcc   0.386202      0.529971  209.0\n",
       "8    max min_per_class_accuracy   0.343187      0.779148  226.0\n",
       "9   max mean_per_class_accuracy   0.300887      0.783031  244.0\n",
       "10                      max tns   0.973791  12651.000000    0.0\n",
       "11                      max fns   0.973791   5373.000000    0.0\n",
       "12                      max fps   0.003564  12651.000000  399.0\n",
       "13                      max tps   0.012138   5377.000000  389.0\n",
       "14                      max tnr   0.973791      1.000000    0.0\n",
       "15                      max fnr   0.973791      0.999256    0.0\n",
       "16                      max fpr   0.003564      1.000000  399.0\n",
       "17                      max tpr   0.012138      1.000000  389.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 29.83 %, avg score: 29.83 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.914219</td>\n",
       "      <td>3.130514</td>\n",
       "      <td>3.130514</td>\n",
       "      <td>0.933702</td>\n",
       "      <td>0.935570</td>\n",
       "      <td>0.933702</td>\n",
       "      <td>0.935570</td>\n",
       "      <td>0.031430</td>\n",
       "      <td>0.031430</td>\n",
       "      <td>213.051394</td>\n",
       "      <td>213.051394</td>\n",
       "      <td>0.030482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020024</td>\n",
       "      <td>0.886245</td>\n",
       "      <td>3.073399</td>\n",
       "      <td>3.102036</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.898408</td>\n",
       "      <td>0.925208</td>\n",
       "      <td>0.917041</td>\n",
       "      <td>0.030686</td>\n",
       "      <td>0.062116</td>\n",
       "      <td>207.339905</td>\n",
       "      <td>210.203560</td>\n",
       "      <td>0.059982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030009</td>\n",
       "      <td>0.863920</td>\n",
       "      <td>2.998892</td>\n",
       "      <td>3.067718</td>\n",
       "      <td>0.894444</td>\n",
       "      <td>0.875417</td>\n",
       "      <td>0.914972</td>\n",
       "      <td>0.903192</td>\n",
       "      <td>0.029942</td>\n",
       "      <td>0.092059</td>\n",
       "      <td>199.889240</td>\n",
       "      <td>206.771809</td>\n",
       "      <td>0.088423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040049</td>\n",
       "      <td>0.842150</td>\n",
       "      <td>2.889705</td>\n",
       "      <td>3.023092</td>\n",
       "      <td>0.861878</td>\n",
       "      <td>0.852007</td>\n",
       "      <td>0.901662</td>\n",
       "      <td>0.890360</td>\n",
       "      <td>0.029012</td>\n",
       "      <td>0.121071</td>\n",
       "      <td>188.970518</td>\n",
       "      <td>202.309158</td>\n",
       "      <td>0.115459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050033</td>\n",
       "      <td>0.822079</td>\n",
       "      <td>2.775372</td>\n",
       "      <td>2.973658</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.830701</td>\n",
       "      <td>0.886918</td>\n",
       "      <td>0.878455</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>0.148782</td>\n",
       "      <td>177.537247</td>\n",
       "      <td>197.365761</td>\n",
       "      <td>0.140719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>0.734881</td>\n",
       "      <td>2.571347</td>\n",
       "      <td>2.772614</td>\n",
       "      <td>0.766926</td>\n",
       "      <td>0.777097</td>\n",
       "      <td>0.826955</td>\n",
       "      <td>0.827804</td>\n",
       "      <td>0.128510</td>\n",
       "      <td>0.277292</td>\n",
       "      <td>157.134748</td>\n",
       "      <td>177.261411</td>\n",
       "      <td>0.252630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150044</td>\n",
       "      <td>0.661094</td>\n",
       "      <td>2.312019</td>\n",
       "      <td>2.619026</td>\n",
       "      <td>0.689579</td>\n",
       "      <td>0.696277</td>\n",
       "      <td>0.781146</td>\n",
       "      <td>0.783946</td>\n",
       "      <td>0.115678</td>\n",
       "      <td>0.392970</td>\n",
       "      <td>131.201879</td>\n",
       "      <td>161.902558</td>\n",
       "      <td>0.346175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.586512</td>\n",
       "      <td>1.946186</td>\n",
       "      <td>2.450909</td>\n",
       "      <td>0.580466</td>\n",
       "      <td>0.624078</td>\n",
       "      <td>0.731004</td>\n",
       "      <td>0.744001</td>\n",
       "      <td>0.097266</td>\n",
       "      <td>0.490236</td>\n",
       "      <td>94.618630</td>\n",
       "      <td>145.090906</td>\n",
       "      <td>0.413562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300033</td>\n",
       "      <td>0.449108</td>\n",
       "      <td>1.746133</td>\n",
       "      <td>2.215984</td>\n",
       "      <td>0.520799</td>\n",
       "      <td>0.517122</td>\n",
       "      <td>0.660935</td>\n",
       "      <td>0.668375</td>\n",
       "      <td>0.174633</td>\n",
       "      <td>0.664869</td>\n",
       "      <td>74.613323</td>\n",
       "      <td>121.598378</td>\n",
       "      <td>0.519900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399989</td>\n",
       "      <td>0.327418</td>\n",
       "      <td>1.298698</td>\n",
       "      <td>1.986758</td>\n",
       "      <td>0.387347</td>\n",
       "      <td>0.386475</td>\n",
       "      <td>0.592567</td>\n",
       "      <td>0.597929</td>\n",
       "      <td>0.129812</td>\n",
       "      <td>0.794681</td>\n",
       "      <td>29.869793</td>\n",
       "      <td>98.675772</td>\n",
       "      <td>0.562446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.216124</td>\n",
       "      <td>0.940941</td>\n",
       "      <td>1.777571</td>\n",
       "      <td>0.280643</td>\n",
       "      <td>0.269911</td>\n",
       "      <td>0.530175</td>\n",
       "      <td>0.532318</td>\n",
       "      <td>0.094105</td>\n",
       "      <td>0.888786</td>\n",
       "      <td>-5.905919</td>\n",
       "      <td>77.757114</td>\n",
       "      <td>0.554029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600011</td>\n",
       "      <td>0.126088</td>\n",
       "      <td>0.617376</td>\n",
       "      <td>1.584187</td>\n",
       "      <td>0.184138</td>\n",
       "      <td>0.167997</td>\n",
       "      <td>0.472497</td>\n",
       "      <td>0.471592</td>\n",
       "      <td>0.061744</td>\n",
       "      <td>0.950530</td>\n",
       "      <td>-38.262382</td>\n",
       "      <td>58.418743</td>\n",
       "      <td>0.499498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699967</td>\n",
       "      <td>0.060706</td>\n",
       "      <td>0.347932</td>\n",
       "      <td>1.407649</td>\n",
       "      <td>0.103774</td>\n",
       "      <td>0.091942</td>\n",
       "      <td>0.419843</td>\n",
       "      <td>0.417378</td>\n",
       "      <td>0.034778</td>\n",
       "      <td>0.985308</td>\n",
       "      <td>-65.206803</td>\n",
       "      <td>40.764949</td>\n",
       "      <td>0.406618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799978</td>\n",
       "      <td>0.023375</td>\n",
       "      <td>0.137608</td>\n",
       "      <td>1.248872</td>\n",
       "      <td>0.041043</td>\n",
       "      <td>0.039681</td>\n",
       "      <td>0.372486</td>\n",
       "      <td>0.370159</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>0.999070</td>\n",
       "      <td>-86.239206</td>\n",
       "      <td>24.887228</td>\n",
       "      <td>0.283712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899989</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>1.111125</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.015291</td>\n",
       "      <td>0.331402</td>\n",
       "      <td>0.330725</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-99.070217</td>\n",
       "      <td>11.112481</td>\n",
       "      <td>0.142518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006586</td>\n",
       "      <td>0.298258</td>\n",
       "      <td>0.298307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010040         0.914219  3.130514   \n",
       "1       2                  0.020024         0.886245  3.073399   \n",
       "2       3                  0.030009         0.863920  2.998892   \n",
       "3       4                  0.040049         0.842150  2.889705   \n",
       "4       5                  0.050033         0.822079  2.775372   \n",
       "5       6                  0.100011         0.734881  2.571347   \n",
       "6       7                  0.150044         0.661094  2.312019   \n",
       "7       8                  0.200022         0.586512  1.946186   \n",
       "8       9                  0.300033         0.449108  1.746133   \n",
       "9      10                  0.399989         0.327418  1.298698   \n",
       "10     11                  0.500000         0.216124  0.940941   \n",
       "11     12                  0.600011         0.126088  0.617376   \n",
       "12     13                  0.699967         0.060706  0.347932   \n",
       "13     14                  0.799978         0.023375  0.137608   \n",
       "14     15                  0.899989         0.009756  0.009298   \n",
       "15     16                  1.000000         0.002274  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          3.130514       0.933702  0.935570                  0.933702   \n",
       "1          3.102036       0.916667  0.898408                  0.925208   \n",
       "2          3.067718       0.894444  0.875417                  0.914972   \n",
       "3          3.023092       0.861878  0.852007                  0.901662   \n",
       "4          2.973658       0.827778  0.830701                  0.886918   \n",
       "5          2.772614       0.766926  0.777097                  0.826955   \n",
       "6          2.619026       0.689579  0.696277                  0.781146   \n",
       "7          2.450909       0.580466  0.624078                  0.731004   \n",
       "8          2.215984       0.520799  0.517122                  0.660935   \n",
       "9          1.986758       0.387347  0.386475                  0.592567   \n",
       "10         1.777571       0.280643  0.269911                  0.530175   \n",
       "11         1.584187       0.184138  0.167997                  0.472497   \n",
       "12         1.407649       0.103774  0.091942                  0.419843   \n",
       "13         1.248872       0.041043  0.039681                  0.372486   \n",
       "14         1.111125       0.002773  0.015291                  0.331402   \n",
       "15         1.000000       0.000000  0.006586                  0.298258   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.935570      0.031430                 0.031430  213.051394   \n",
       "1           0.917041      0.030686                 0.062116  207.339905   \n",
       "2           0.903192      0.029942                 0.092059  199.889240   \n",
       "3           0.890360      0.029012                 0.121071  188.970518   \n",
       "4           0.878455      0.027711                 0.148782  177.537247   \n",
       "5           0.827804      0.128510                 0.277292  157.134748   \n",
       "6           0.783946      0.115678                 0.392970  131.201879   \n",
       "7           0.744001      0.097266                 0.490236   94.618630   \n",
       "8           0.668375      0.174633                 0.664869   74.613323   \n",
       "9           0.597929      0.129812                 0.794681   29.869793   \n",
       "10          0.532318      0.094105                 0.888786   -5.905919   \n",
       "11          0.471592      0.061744                 0.950530  -38.262382   \n",
       "12          0.417378      0.034778                 0.985308  -65.206803   \n",
       "13          0.370159      0.013762                 0.999070  -86.239206   \n",
       "14          0.330725      0.000930                 1.000000  -99.070217   \n",
       "15          0.298307      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        213.051394            0.030482  \n",
       "1        210.203560            0.059982  \n",
       "2        206.771809            0.088423  \n",
       "3        202.309158            0.115459  \n",
       "4        197.365761            0.140719  \n",
       "5        177.261411            0.252630  \n",
       "6        161.902558            0.346175  \n",
       "7        145.090906            0.413562  \n",
       "8        121.598378            0.519900  \n",
       "9         98.675772            0.562446  \n",
       "10        77.757114            0.554029  \n",
       "11        58.418743            0.499498  \n",
       "12        40.764949            0.406618  \n",
       "13        24.887228            0.283712  \n",
       "14        11.112481            0.142518  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OBinomialModel.accuracy of >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "metalearner.std_coef_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_1_AutoML_20210531_075119\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>59912.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>55.444443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0               81.0                      81.0              59912.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0        6.0        6.0         6.0        25.0        64.0    55.444443  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.10019259574566626\n",
      "RMSE: 0.31653214014640957\n",
      "LogLoss: 0.3228059692415566\n",
      "Mean Per-Class Error: 0.14564385819817338\n",
      "AUC: 0.9337223009610945\n",
      "AUCPR: 0.859842657542678\n",
      "Gini: 0.8674446019221891\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.42566191297500694: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>11245.0</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>(1406.0/12651.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>4316.0</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>(1061.0/5377.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>12306.0</td>\n",
       "      <td>5722.0</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>(2467.0/18028.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            False    True   Error               Rate\n",
       "0  False  11245.0  1406.0  0.1111   (1406.0/12651.0)\n",
       "1   True   1061.0  4316.0  0.1973    (1061.0/5377.0)\n",
       "2  Total  12306.0  5722.0  0.1368   (2467.0/18028.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.425662</td>\n",
       "      <td>0.777728</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.250152</td>\n",
       "      <td>0.844969</td>\n",
       "      <td>262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.563751</td>\n",
       "      <td>0.797077</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.476581</td>\n",
       "      <td>0.865432</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.966792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.027485</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.966792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.425662</td>\n",
       "      <td>0.679701</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.371936</td>\n",
       "      <td>0.851404</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.348051</td>\n",
       "      <td>0.854356</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.966792</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.966792</td>\n",
       "      <td>5370.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.027485</td>\n",
       "      <td>5377.000000</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.966792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.966792</td>\n",
       "      <td>0.998698</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.027485</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.425662      0.777728  190.0\n",
       "1                        max f2   0.250152      0.844969  262.0\n",
       "2                  max f0point5   0.563751      0.797077  135.0\n",
       "3                  max accuracy   0.476581      0.865432  170.0\n",
       "4                 max precision   0.966792      1.000000    0.0\n",
       "5                    max recall   0.027485      1.000000  378.0\n",
       "6               max specificity   0.966792      1.000000    0.0\n",
       "7              max absolute_mcc   0.425662      0.679701  190.0\n",
       "8    max min_per_class_accuracy   0.371936      0.851404  210.0\n",
       "9   max mean_per_class_accuracy   0.348051      0.854356  220.0\n",
       "10                      max tns   0.966792  12651.000000    0.0\n",
       "11                      max fns   0.966792   5370.000000    0.0\n",
       "12                      max fps   0.004845  12651.000000  399.0\n",
       "13                      max tps   0.027485   5377.000000  378.0\n",
       "14                      max tnr   0.966792      1.000000    0.0\n",
       "15                      max fnr   0.966792      0.998698    0.0\n",
       "16                      max fpr   0.004845      1.000000  399.0\n",
       "17                      max tpr   0.027485      1.000000  378.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 29.83 %, avg score: 29.81 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.902901</td>\n",
       "      <td>3.315751</td>\n",
       "      <td>3.315751</td>\n",
       "      <td>0.988950</td>\n",
       "      <td>0.927211</td>\n",
       "      <td>0.988950</td>\n",
       "      <td>0.927211</td>\n",
       "      <td>0.033290</td>\n",
       "      <td>0.033290</td>\n",
       "      <td>231.575146</td>\n",
       "      <td>231.575146</td>\n",
       "      <td>0.033132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020024</td>\n",
       "      <td>0.873064</td>\n",
       "      <td>3.334172</td>\n",
       "      <td>3.324936</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.886822</td>\n",
       "      <td>0.991690</td>\n",
       "      <td>0.907072</td>\n",
       "      <td>0.033290</td>\n",
       "      <td>0.066580</td>\n",
       "      <td>233.417230</td>\n",
       "      <td>232.493636</td>\n",
       "      <td>0.066343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030009</td>\n",
       "      <td>0.849924</td>\n",
       "      <td>3.278292</td>\n",
       "      <td>3.309417</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.860250</td>\n",
       "      <td>0.987061</td>\n",
       "      <td>0.891494</td>\n",
       "      <td>0.032732</td>\n",
       "      <td>0.099312</td>\n",
       "      <td>227.829232</td>\n",
       "      <td>230.941709</td>\n",
       "      <td>0.098759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040049</td>\n",
       "      <td>0.830813</td>\n",
       "      <td>3.241656</td>\n",
       "      <td>3.292430</td>\n",
       "      <td>0.966851</td>\n",
       "      <td>0.840142</td>\n",
       "      <td>0.981994</td>\n",
       "      <td>0.878620</td>\n",
       "      <td>0.032546</td>\n",
       "      <td>0.131858</td>\n",
       "      <td>224.165645</td>\n",
       "      <td>229.243000</td>\n",
       "      <td>0.130830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050033</td>\n",
       "      <td>0.812451</td>\n",
       "      <td>3.203786</td>\n",
       "      <td>3.274740</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.821252</td>\n",
       "      <td>0.976718</td>\n",
       "      <td>0.867172</td>\n",
       "      <td>0.031988</td>\n",
       "      <td>0.163846</td>\n",
       "      <td>220.378567</td>\n",
       "      <td>227.474045</td>\n",
       "      <td>0.162186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>0.727436</td>\n",
       "      <td>3.110921</td>\n",
       "      <td>3.192876</td>\n",
       "      <td>0.927858</td>\n",
       "      <td>0.768991</td>\n",
       "      <td>0.952302</td>\n",
       "      <td>0.818109</td>\n",
       "      <td>0.155477</td>\n",
       "      <td>0.319323</td>\n",
       "      <td>211.092112</td>\n",
       "      <td>219.287621</td>\n",
       "      <td>0.312525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150044</td>\n",
       "      <td>0.656777</td>\n",
       "      <td>2.847277</td>\n",
       "      <td>3.077634</td>\n",
       "      <td>0.849224</td>\n",
       "      <td>0.692725</td>\n",
       "      <td>0.917930</td>\n",
       "      <td>0.776299</td>\n",
       "      <td>0.142459</td>\n",
       "      <td>0.461782</td>\n",
       "      <td>184.727716</td>\n",
       "      <td>207.763394</td>\n",
       "      <td>0.444234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.584848</td>\n",
       "      <td>2.448548</td>\n",
       "      <td>2.920450</td>\n",
       "      <td>0.730300</td>\n",
       "      <td>0.621733</td>\n",
       "      <td>0.871048</td>\n",
       "      <td>0.737679</td>\n",
       "      <td>0.122373</td>\n",
       "      <td>0.584155</td>\n",
       "      <td>144.854796</td>\n",
       "      <td>192.044968</td>\n",
       "      <td>0.547399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300033</td>\n",
       "      <td>0.450214</td>\n",
       "      <td>1.915354</td>\n",
       "      <td>2.585418</td>\n",
       "      <td>0.571270</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.771122</td>\n",
       "      <td>0.664335</td>\n",
       "      <td>0.191557</td>\n",
       "      <td>0.775711</td>\n",
       "      <td>91.535381</td>\n",
       "      <td>158.541772</td>\n",
       "      <td>0.677853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399989</td>\n",
       "      <td>0.319781</td>\n",
       "      <td>1.177759</td>\n",
       "      <td>2.233649</td>\n",
       "      <td>0.351276</td>\n",
       "      <td>0.381667</td>\n",
       "      <td>0.666204</td>\n",
       "      <td>0.593697</td>\n",
       "      <td>0.117724</td>\n",
       "      <td>0.893435</td>\n",
       "      <td>17.775901</td>\n",
       "      <td>123.364945</td>\n",
       "      <td>0.703173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.211830</td>\n",
       "      <td>0.639691</td>\n",
       "      <td>1.914822</td>\n",
       "      <td>0.190793</td>\n",
       "      <td>0.264443</td>\n",
       "      <td>0.571112</td>\n",
       "      <td>0.527839</td>\n",
       "      <td>0.063976</td>\n",
       "      <td>0.957411</td>\n",
       "      <td>-36.030902</td>\n",
       "      <td>91.482239</td>\n",
       "      <td>0.651823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600011</td>\n",
       "      <td>0.129959</td>\n",
       "      <td>0.290092</td>\n",
       "      <td>1.644009</td>\n",
       "      <td>0.086522</td>\n",
       "      <td>0.168908</td>\n",
       "      <td>0.490339</td>\n",
       "      <td>0.468012</td>\n",
       "      <td>0.029012</td>\n",
       "      <td>0.986424</td>\n",
       "      <td>-70.990758</td>\n",
       "      <td>64.400903</td>\n",
       "      <td>0.550648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699967</td>\n",
       "      <td>0.067109</td>\n",
       "      <td>0.119078</td>\n",
       "      <td>1.426248</td>\n",
       "      <td>0.035516</td>\n",
       "      <td>0.096534</td>\n",
       "      <td>0.425390</td>\n",
       "      <td>0.414964</td>\n",
       "      <td>0.011903</td>\n",
       "      <td>0.998326</td>\n",
       "      <td>-88.092168</td>\n",
       "      <td>42.624810</td>\n",
       "      <td>0.425170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799978</td>\n",
       "      <td>0.029713</td>\n",
       "      <td>0.013017</td>\n",
       "      <td>1.249570</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>0.046275</td>\n",
       "      <td>0.372694</td>\n",
       "      <td>0.368872</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.999628</td>\n",
       "      <td>-98.698303</td>\n",
       "      <td>24.956971</td>\n",
       "      <td>0.284507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899989</td>\n",
       "      <td>0.014061</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>1.111125</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.020616</td>\n",
       "      <td>0.331402</td>\n",
       "      <td>0.330172</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-99.628087</td>\n",
       "      <td>11.112481</td>\n",
       "      <td>0.142518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009597</td>\n",
       "      <td>0.298258</td>\n",
       "      <td>0.298111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010040         0.902901  3.315751   \n",
       "1       2                  0.020024         0.873064  3.334172   \n",
       "2       3                  0.030009         0.849924  3.278292   \n",
       "3       4                  0.040049         0.830813  3.241656   \n",
       "4       5                  0.050033         0.812451  3.203786   \n",
       "5       6                  0.100011         0.727436  3.110921   \n",
       "6       7                  0.150044         0.656777  2.847277   \n",
       "7       8                  0.200022         0.584848  2.448548   \n",
       "8       9                  0.300033         0.450214  1.915354   \n",
       "9      10                  0.399989         0.319781  1.177759   \n",
       "10     11                  0.500000         0.211830  0.639691   \n",
       "11     12                  0.600011         0.129959  0.290092   \n",
       "12     13                  0.699967         0.067109  0.119078   \n",
       "13     14                  0.799978         0.029713  0.013017   \n",
       "14     15                  0.899989         0.014061  0.003719   \n",
       "15     16                  1.000000         0.003692  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          3.315751       0.988950  0.927211                  0.988950   \n",
       "1          3.324936       0.994444  0.886822                  0.991690   \n",
       "2          3.309417       0.977778  0.860250                  0.987061   \n",
       "3          3.292430       0.966851  0.840142                  0.981994   \n",
       "4          3.274740       0.955556  0.821252                  0.976718   \n",
       "5          3.192876       0.927858  0.768991                  0.952302   \n",
       "6          3.077634       0.849224  0.692725                  0.917930   \n",
       "7          2.920450       0.730300  0.621733                  0.871048   \n",
       "8          2.585418       0.571270  0.517647                  0.771122   \n",
       "9          2.233649       0.351276  0.381667                  0.666204   \n",
       "10         1.914822       0.190793  0.264443                  0.571112   \n",
       "11         1.644009       0.086522  0.168908                  0.490339   \n",
       "12         1.426248       0.035516  0.096534                  0.425390   \n",
       "13         1.249570       0.003882  0.046275                  0.372694   \n",
       "14         1.111125       0.001109  0.020616                  0.331402   \n",
       "15         1.000000       0.000000  0.009597                  0.298258   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.927211      0.033290                 0.033290  231.575146   \n",
       "1           0.907072      0.033290                 0.066580  233.417230   \n",
       "2           0.891494      0.032732                 0.099312  227.829232   \n",
       "3           0.878620      0.032546                 0.131858  224.165645   \n",
       "4           0.867172      0.031988                 0.163846  220.378567   \n",
       "5           0.818109      0.155477                 0.319323  211.092112   \n",
       "6           0.776299      0.142459                 0.461782  184.727716   \n",
       "7           0.737679      0.122373                 0.584155  144.854796   \n",
       "8           0.664335      0.191557                 0.775711   91.535381   \n",
       "9           0.593697      0.117724                 0.893435   17.775901   \n",
       "10          0.527839      0.063976                 0.957411  -36.030902   \n",
       "11          0.468012      0.029012                 0.986424  -70.990758   \n",
       "12          0.414964      0.011903                 0.998326  -88.092168   \n",
       "13          0.368872      0.001302                 0.999628  -98.698303   \n",
       "14          0.330172      0.000372                 1.000000  -99.628087   \n",
       "15          0.298111      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        231.575146            0.033132  \n",
       "1        232.493636            0.066343  \n",
       "2        230.941709            0.098759  \n",
       "3        229.243000            0.130830  \n",
       "4        227.474045            0.162186  \n",
       "5        219.287621            0.312525  \n",
       "6        207.763394            0.444234  \n",
       "7        192.044968            0.547399  \n",
       "8        158.541772            0.677853  \n",
       "9        123.364945            0.703173  \n",
       "10        91.482239            0.651823  \n",
       "11        64.400903            0.550648  \n",
       "12        42.624810            0.425170  \n",
       "13        24.956971            0.284507  \n",
       "14        11.112481            0.142518  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.13567459317160033\n",
      "RMSE: 0.36834032248940696\n",
      "LogLoss: 0.41075078167522805\n",
      "Mean Per-Class Error: 0.21804959856552708\n",
      "AUC: 0.8638187499910877\n",
      "AUCPR: 0.7129709674022839\n",
      "Gini: 0.7276374999821753\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3088357379595852: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>9522.0</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>0.2473</td>\n",
       "      <td>(3129.0/12651.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>4362.0</td>\n",
       "      <td>0.1888</td>\n",
       "      <td>(1015.0/5377.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>10537.0</td>\n",
       "      <td>7491.0</td>\n",
       "      <td>0.2299</td>\n",
       "      <td>(4144.0/18028.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            False    True   Error               Rate\n",
       "0  False   9522.0  3129.0  0.2473   (3129.0/12651.0)\n",
       "1   True   1015.0  4362.0  0.1888    (1015.0/5377.0)\n",
       "2  Total  10537.0  7491.0  0.2299   (4144.0/18028.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.308836</td>\n",
       "      <td>0.677961</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.142659</td>\n",
       "      <td>0.790806</td>\n",
       "      <td>313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.508395</td>\n",
       "      <td>0.664902</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.481924</td>\n",
       "      <td>0.797260</td>\n",
       "      <td>167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.970857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.014768</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.970857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.380993</td>\n",
       "      <td>0.523499</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.338251</td>\n",
       "      <td>0.777409</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.308836</td>\n",
       "      <td>0.781950</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.970857</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.970857</td>\n",
       "      <td>5372.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.004803</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.014768</td>\n",
       "      <td>5377.000000</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.970857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.970857</td>\n",
       "      <td>0.999070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.004803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.014768</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.308836      0.677961  239.0\n",
       "1                        max f2   0.142659      0.790806  313.0\n",
       "2                  max f0point5   0.508395      0.664902  156.0\n",
       "3                  max accuracy   0.481924      0.797260  167.0\n",
       "4                 max precision   0.970857      1.000000    0.0\n",
       "5                    max recall   0.014768      1.000000  389.0\n",
       "6               max specificity   0.970857      1.000000    0.0\n",
       "7              max absolute_mcc   0.380993      0.523499  208.0\n",
       "8    max min_per_class_accuracy   0.338251      0.777409  226.0\n",
       "9   max mean_per_class_accuracy   0.308836      0.781950  239.0\n",
       "10                      max tns   0.970857  12651.000000    0.0\n",
       "11                      max fns   0.970857   5372.000000    0.0\n",
       "12                      max fps   0.004803  12651.000000  399.0\n",
       "13                      max tps   0.014768   5377.000000  389.0\n",
       "14                      max tnr   0.970857      1.000000    0.0\n",
       "15                      max fnr   0.970857      0.999070    0.0\n",
       "16                      max fpr   0.004803      1.000000  399.0\n",
       "17                      max tpr   0.014768      1.000000  389.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 29.83 %, avg score: 29.53 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.898144</td>\n",
       "      <td>3.130514</td>\n",
       "      <td>3.130514</td>\n",
       "      <td>0.933702</td>\n",
       "      <td>0.923453</td>\n",
       "      <td>0.933702</td>\n",
       "      <td>0.923453</td>\n",
       "      <td>0.031430</td>\n",
       "      <td>0.031430</td>\n",
       "      <td>213.051394</td>\n",
       "      <td>213.051394</td>\n",
       "      <td>0.030482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020024</td>\n",
       "      <td>0.860632</td>\n",
       "      <td>3.054772</td>\n",
       "      <td>3.092748</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.878824</td>\n",
       "      <td>0.922438</td>\n",
       "      <td>0.901200</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.061930</td>\n",
       "      <td>205.477238</td>\n",
       "      <td>209.274807</td>\n",
       "      <td>0.059717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030009</td>\n",
       "      <td>0.835631</td>\n",
       "      <td>2.849879</td>\n",
       "      <td>3.011941</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.847070</td>\n",
       "      <td>0.898336</td>\n",
       "      <td>0.883190</td>\n",
       "      <td>0.028455</td>\n",
       "      <td>0.090385</td>\n",
       "      <td>184.987911</td>\n",
       "      <td>201.194139</td>\n",
       "      <td>0.086037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040049</td>\n",
       "      <td>0.812612</td>\n",
       "      <td>2.760039</td>\n",
       "      <td>2.948791</td>\n",
       "      <td>0.823204</td>\n",
       "      <td>0.824023</td>\n",
       "      <td>0.879501</td>\n",
       "      <td>0.868357</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>0.118096</td>\n",
       "      <td>176.003892</td>\n",
       "      <td>194.879133</td>\n",
       "      <td>0.111219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050033</td>\n",
       "      <td>0.794569</td>\n",
       "      <td>2.849879</td>\n",
       "      <td>2.929053</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.803656</td>\n",
       "      <td>0.873614</td>\n",
       "      <td>0.855446</td>\n",
       "      <td>0.028455</td>\n",
       "      <td>0.146550</td>\n",
       "      <td>184.987911</td>\n",
       "      <td>192.905275</td>\n",
       "      <td>0.137539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>0.705960</td>\n",
       "      <td>2.508087</td>\n",
       "      <td>2.718687</td>\n",
       "      <td>0.748058</td>\n",
       "      <td>0.747603</td>\n",
       "      <td>0.810871</td>\n",
       "      <td>0.801554</td>\n",
       "      <td>0.125349</td>\n",
       "      <td>0.271899</td>\n",
       "      <td>150.808712</td>\n",
       "      <td>171.868668</td>\n",
       "      <td>0.244944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150044</td>\n",
       "      <td>0.631937</td>\n",
       "      <td>2.312019</td>\n",
       "      <td>2.583081</td>\n",
       "      <td>0.689579</td>\n",
       "      <td>0.668295</td>\n",
       "      <td>0.770425</td>\n",
       "      <td>0.757118</td>\n",
       "      <td>0.115678</td>\n",
       "      <td>0.387577</td>\n",
       "      <td>131.201879</td>\n",
       "      <td>158.308060</td>\n",
       "      <td>0.338490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.564049</td>\n",
       "      <td>1.935023</td>\n",
       "      <td>2.421156</td>\n",
       "      <td>0.577137</td>\n",
       "      <td>0.598543</td>\n",
       "      <td>0.722130</td>\n",
       "      <td>0.717496</td>\n",
       "      <td>0.096708</td>\n",
       "      <td>0.484285</td>\n",
       "      <td>93.502271</td>\n",
       "      <td>142.115599</td>\n",
       "      <td>0.405082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300033</td>\n",
       "      <td>0.440487</td>\n",
       "      <td>1.740555</td>\n",
       "      <td>2.194289</td>\n",
       "      <td>0.519135</td>\n",
       "      <td>0.500483</td>\n",
       "      <td>0.654465</td>\n",
       "      <td>0.645159</td>\n",
       "      <td>0.174075</td>\n",
       "      <td>0.658360</td>\n",
       "      <td>74.055453</td>\n",
       "      <td>119.428884</td>\n",
       "      <td>0.510624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399989</td>\n",
       "      <td>0.324544</td>\n",
       "      <td>1.337771</td>\n",
       "      <td>1.980248</td>\n",
       "      <td>0.399001</td>\n",
       "      <td>0.380981</td>\n",
       "      <td>0.590625</td>\n",
       "      <td>0.579142</td>\n",
       "      <td>0.133718</td>\n",
       "      <td>0.792077</td>\n",
       "      <td>33.777051</td>\n",
       "      <td>98.024834</td>\n",
       "      <td>0.558736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.221775</td>\n",
       "      <td>0.940941</td>\n",
       "      <td>1.772364</td>\n",
       "      <td>0.280643</td>\n",
       "      <td>0.272609</td>\n",
       "      <td>0.528622</td>\n",
       "      <td>0.517828</td>\n",
       "      <td>0.094105</td>\n",
       "      <td>0.886182</td>\n",
       "      <td>-5.905919</td>\n",
       "      <td>77.236377</td>\n",
       "      <td>0.550319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600011</td>\n",
       "      <td>0.136411</td>\n",
       "      <td>0.635972</td>\n",
       "      <td>1.582948</td>\n",
       "      <td>0.189684</td>\n",
       "      <td>0.177745</td>\n",
       "      <td>0.472127</td>\n",
       "      <td>0.461142</td>\n",
       "      <td>0.063604</td>\n",
       "      <td>0.949786</td>\n",
       "      <td>-36.402815</td>\n",
       "      <td>58.294761</td>\n",
       "      <td>0.498438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699967</td>\n",
       "      <td>0.072696</td>\n",
       "      <td>0.360956</td>\n",
       "      <td>1.408447</td>\n",
       "      <td>0.107658</td>\n",
       "      <td>0.103229</td>\n",
       "      <td>0.420081</td>\n",
       "      <td>0.410032</td>\n",
       "      <td>0.036080</td>\n",
       "      <td>0.985866</td>\n",
       "      <td>-63.904384</td>\n",
       "      <td>40.844657</td>\n",
       "      <td>0.407413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799978</td>\n",
       "      <td>0.032579</td>\n",
       "      <td>0.122731</td>\n",
       "      <td>1.247710</td>\n",
       "      <td>0.036606</td>\n",
       "      <td>0.050261</td>\n",
       "      <td>0.372140</td>\n",
       "      <td>0.365055</td>\n",
       "      <td>0.012275</td>\n",
       "      <td>0.998140</td>\n",
       "      <td>-87.726859</td>\n",
       "      <td>24.770989</td>\n",
       "      <td>0.282387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899989</td>\n",
       "      <td>0.015144</td>\n",
       "      <td>0.016736</td>\n",
       "      <td>1.110918</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>0.022516</td>\n",
       "      <td>0.331341</td>\n",
       "      <td>0.326990</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>-98.326390</td>\n",
       "      <td>11.091816</td>\n",
       "      <td>0.142253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002959</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.010276</td>\n",
       "      <td>0.298258</td>\n",
       "      <td>0.295315</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-99.814043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010040         0.898144  3.130514   \n",
       "1       2                  0.020024         0.860632  3.054772   \n",
       "2       3                  0.030009         0.835631  2.849879   \n",
       "3       4                  0.040049         0.812612  2.760039   \n",
       "4       5                  0.050033         0.794569  2.849879   \n",
       "5       6                  0.100011         0.705960  2.508087   \n",
       "6       7                  0.150044         0.631937  2.312019   \n",
       "7       8                  0.200022         0.564049  1.935023   \n",
       "8       9                  0.300033         0.440487  1.740555   \n",
       "9      10                  0.399989         0.324544  1.337771   \n",
       "10     11                  0.500000         0.221775  0.940941   \n",
       "11     12                  0.600011         0.136411  0.635972   \n",
       "12     13                  0.699967         0.072696  0.360956   \n",
       "13     14                  0.799978         0.032579  0.122731   \n",
       "14     15                  0.899989         0.015144  0.016736   \n",
       "15     16                  1.000000         0.002959  0.001860   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          3.130514       0.933702  0.923453                  0.933702   \n",
       "1          3.092748       0.911111  0.878824                  0.922438   \n",
       "2          3.011941       0.850000  0.847070                  0.898336   \n",
       "3          2.948791       0.823204  0.824023                  0.879501   \n",
       "4          2.929053       0.850000  0.803656                  0.873614   \n",
       "5          2.718687       0.748058  0.747603                  0.810871   \n",
       "6          2.583081       0.689579  0.668295                  0.770425   \n",
       "7          2.421156       0.577137  0.598543                  0.722130   \n",
       "8          2.194289       0.519135  0.500483                  0.654465   \n",
       "9          1.980248       0.399001  0.380981                  0.590625   \n",
       "10         1.772364       0.280643  0.272609                  0.528622   \n",
       "11         1.582948       0.189684  0.177745                  0.472127   \n",
       "12         1.408447       0.107658  0.103229                  0.420081   \n",
       "13         1.247710       0.036606  0.050261                  0.372140   \n",
       "14         1.110918       0.004992  0.022516                  0.331341   \n",
       "15         1.000000       0.000555  0.010276                  0.298258   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.923453      0.031430                 0.031430  213.051394   \n",
       "1           0.901200      0.030500                 0.061930  205.477238   \n",
       "2           0.883190      0.028455                 0.090385  184.987911   \n",
       "3           0.868357      0.027711                 0.118096  176.003892   \n",
       "4           0.855446      0.028455                 0.146550  184.987911   \n",
       "5           0.801554      0.125349                 0.271899  150.808712   \n",
       "6           0.757118      0.115678                 0.387577  131.201879   \n",
       "7           0.717496      0.096708                 0.484285   93.502271   \n",
       "8           0.645159      0.174075                 0.658360   74.055453   \n",
       "9           0.579142      0.133718                 0.792077   33.777051   \n",
       "10          0.517828      0.094105                 0.886182   -5.905919   \n",
       "11          0.461142      0.063604                 0.949786  -36.402815   \n",
       "12          0.410032      0.036080                 0.985866  -63.904384   \n",
       "13          0.365055      0.012275                 0.998140  -87.726859   \n",
       "14          0.326990      0.001674                 0.999814  -98.326390   \n",
       "15          0.295315      0.000186                 1.000000  -99.814043   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        213.051394            0.030482  \n",
       "1        209.274807            0.059717  \n",
       "2        201.194139            0.086037  \n",
       "3        194.879133            0.111219  \n",
       "4        192.905275            0.137539  \n",
       "5        171.868668            0.244944  \n",
       "6        158.308060            0.338490  \n",
       "7        142.115599            0.405082  \n",
       "8        119.428884            0.510624  \n",
       "9         98.024834            0.558736  \n",
       "10        77.236377            0.550319  \n",
       "11        58.294761            0.498438  \n",
       "12        40.844657            0.407413  \n",
       "13        24.770989            0.282387  \n",
       "14        11.091816            0.142253  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>cv_1_valid</th>\n",
       "      <th>cv_2_valid</th>\n",
       "      <th>cv_3_valid</th>\n",
       "      <th>cv_4_valid</th>\n",
       "      <th>cv_5_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.7837257</td>\n",
       "      <td>0.0117617445</td>\n",
       "      <td>0.7933999</td>\n",
       "      <td>0.7684415</td>\n",
       "      <td>0.78230727</td>\n",
       "      <td>0.7972261</td>\n",
       "      <td>0.7772538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.86389035</td>\n",
       "      <td>0.0048539233</td>\n",
       "      <td>0.8649034</td>\n",
       "      <td>0.8556991</td>\n",
       "      <td>0.8675965</td>\n",
       "      <td>0.86740917</td>\n",
       "      <td>0.8638437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>err</td>\n",
       "      <td>0.21627429</td>\n",
       "      <td>0.0117617445</td>\n",
       "      <td>0.20660011</td>\n",
       "      <td>0.23155852</td>\n",
       "      <td>0.21769273</td>\n",
       "      <td>0.20277393</td>\n",
       "      <td>0.22274618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>err_count</td>\n",
       "      <td>779.8</td>\n",
       "      <td>42.440548</td>\n",
       "      <td>745.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>803.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f0point5</td>\n",
       "      <td>0.63599044</td>\n",
       "      <td>0.015952792</td>\n",
       "      <td>0.647857</td>\n",
       "      <td>0.6194172</td>\n",
       "      <td>0.6362189</td>\n",
       "      <td>0.65544</td>\n",
       "      <td>0.6210191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.6809015</td>\n",
       "      <td>0.00810247</td>\n",
       "      <td>0.67762876</td>\n",
       "      <td>0.66956866</td>\n",
       "      <td>0.69130945</td>\n",
       "      <td>0.6847779</td>\n",
       "      <td>0.68122274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f2</td>\n",
       "      <td>0.7333775</td>\n",
       "      <td>0.021334141</td>\n",
       "      <td>0.7102685</td>\n",
       "      <td>0.7285567</td>\n",
       "      <td>0.7568452</td>\n",
       "      <td>0.7168653</td>\n",
       "      <td>0.75435203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lift_top_group</td>\n",
       "      <td>3.1358035</td>\n",
       "      <td>0.1109866</td>\n",
       "      <td>3.1055498</td>\n",
       "      <td>3.2100096</td>\n",
       "      <td>2.9560313</td>\n",
       "      <td>3.1781316</td>\n",
       "      <td>3.2292945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logloss</td>\n",
       "      <td>0.41075045</td>\n",
       "      <td>0.005978554</td>\n",
       "      <td>0.408412</td>\n",
       "      <td>0.42134482</td>\n",
       "      <td>0.40869018</td>\n",
       "      <td>0.40669727</td>\n",
       "      <td>0.40860793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_per_class_error</td>\n",
       "      <td>0.24525394</td>\n",
       "      <td>0.016711961</td>\n",
       "      <td>0.26616684</td>\n",
       "      <td>0.2339833</td>\n",
       "      <td>0.22875299</td>\n",
       "      <td>0.26001865</td>\n",
       "      <td>0.23734798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mcc</td>\n",
       "      <td>0.53042495</td>\n",
       "      <td>0.013855669</td>\n",
       "      <td>0.53028756</td>\n",
       "      <td>0.5071335</td>\n",
       "      <td>0.54185456</td>\n",
       "      <td>0.53979945</td>\n",
       "      <td>0.5330496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mean_per_class_accuracy</td>\n",
       "      <td>0.78080684</td>\n",
       "      <td>0.008077689</td>\n",
       "      <td>0.7761328</td>\n",
       "      <td>0.7700166</td>\n",
       "      <td>0.7895757</td>\n",
       "      <td>0.78073317</td>\n",
       "      <td>0.787576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mean_per_class_error</td>\n",
       "      <td>0.21919313</td>\n",
       "      <td>0.008077689</td>\n",
       "      <td>0.22386718</td>\n",
       "      <td>0.2299834</td>\n",
       "      <td>0.21042429</td>\n",
       "      <td>0.21926682</td>\n",
       "      <td>0.212424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.13567443</td>\n",
       "      <td>0.002604064</td>\n",
       "      <td>0.13485736</td>\n",
       "      <td>0.14024611</td>\n",
       "      <td>0.13491313</td>\n",
       "      <td>0.13367918</td>\n",
       "      <td>0.13467635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pr_auc</td>\n",
       "      <td>0.7130097</td>\n",
       "      <td>0.0039490312</td>\n",
       "      <td>0.7114958</td>\n",
       "      <td>0.7138216</td>\n",
       "      <td>0.71247876</td>\n",
       "      <td>0.71902925</td>\n",
       "      <td>0.7082231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.6094417</td>\n",
       "      <td>0.022954548</td>\n",
       "      <td>0.62942123</td>\n",
       "      <td>0.58995813</td>\n",
       "      <td>0.6041237</td>\n",
       "      <td>0.63723916</td>\n",
       "      <td>0.5864662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.35174507</td>\n",
       "      <td>0.009883261</td>\n",
       "      <td>0.3527099</td>\n",
       "      <td>0.3360588</td>\n",
       "      <td>0.35964462</td>\n",
       "      <td>0.36054367</td>\n",
       "      <td>0.3497683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.77364707</td>\n",
       "      <td>0.036748394</td>\n",
       "      <td>0.7338332</td>\n",
       "      <td>0.77401644</td>\n",
       "      <td>0.8079044</td>\n",
       "      <td>0.73998135</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3683267</td>\n",
       "      <td>0.0035147048</td>\n",
       "      <td>0.3672293</td>\n",
       "      <td>0.37449446</td>\n",
       "      <td>0.36730525</td>\n",
       "      <td>0.36562163</td>\n",
       "      <td>0.36698276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>specificity</td>\n",
       "      <td>0.78796667</td>\n",
       "      <td>0.029384607</td>\n",
       "      <td>0.81843245</td>\n",
       "      <td>0.7660167</td>\n",
       "      <td>0.771247</td>\n",
       "      <td>0.821485</td>\n",
       "      <td>0.76265204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean            sd  cv_1_valid  cv_2_valid  \\\n",
       "0                  accuracy   0.7837257  0.0117617445   0.7933999   0.7684415   \n",
       "1                       auc  0.86389035  0.0048539233   0.8649034   0.8556991   \n",
       "2                       err  0.21627429  0.0117617445  0.20660011  0.23155852   \n",
       "3                 err_count       779.8     42.440548       745.0       835.0   \n",
       "4                  f0point5  0.63599044   0.015952792    0.647857   0.6194172   \n",
       "5                        f1   0.6809015    0.00810247  0.67762876  0.66956866   \n",
       "6                        f2   0.7333775   0.021334141   0.7102685   0.7285567   \n",
       "7            lift_top_group   3.1358035     0.1109866   3.1055498   3.2100096   \n",
       "8                   logloss  0.41075045   0.005978554    0.408412  0.42134482   \n",
       "9       max_per_class_error  0.24525394   0.016711961  0.26616684   0.2339833   \n",
       "10                      mcc  0.53042495   0.013855669  0.53028756   0.5071335   \n",
       "11  mean_per_class_accuracy  0.78080684   0.008077689   0.7761328   0.7700166   \n",
       "12     mean_per_class_error  0.21919313   0.008077689  0.22386718   0.2299834   \n",
       "13                      mse  0.13567443   0.002604064  0.13485736  0.14024611   \n",
       "14                   pr_auc   0.7130097  0.0039490312   0.7114958   0.7138216   \n",
       "15                precision   0.6094417   0.022954548  0.62942123  0.58995813   \n",
       "16                       r2  0.35174507   0.009883261   0.3527099   0.3360588   \n",
       "17                   recall  0.77364707   0.036748394   0.7338332  0.77401644   \n",
       "18                     rmse   0.3683267  0.0035147048   0.3672293  0.37449446   \n",
       "19              specificity  0.78796667   0.029384607  0.81843245   0.7660167   \n",
       "\n",
       "    cv_3_valid  cv_4_valid  cv_5_valid  \n",
       "0   0.78230727   0.7972261   0.7772538  \n",
       "1    0.8675965  0.86740917   0.8638437  \n",
       "2   0.21769273  0.20277393  0.22274618  \n",
       "3        785.0       731.0       803.0  \n",
       "4    0.6362189     0.65544   0.6210191  \n",
       "5   0.69130945   0.6847779  0.68122274  \n",
       "6    0.7568452   0.7168653  0.75435203  \n",
       "7    2.9560313   3.1781316   3.2292945  \n",
       "8   0.40869018  0.40669727  0.40860793  \n",
       "9   0.22875299  0.26001865  0.23734798  \n",
       "10  0.54185456  0.53979945   0.5330496  \n",
       "11   0.7895757  0.78073317    0.787576  \n",
       "12  0.21042429  0.21926682    0.212424  \n",
       "13  0.13491313  0.13367918  0.13467635  \n",
       "14  0.71247876  0.71902925   0.7082231  \n",
       "15   0.6041237  0.63723916   0.5864662  \n",
       "16  0.35964462  0.36054367   0.3497683  \n",
       "17   0.8079044  0.73998135      0.8125  \n",
       "18  0.36730525  0.36562163  0.36698276  \n",
       "19    0.771247    0.821485  0.76265204  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:12</td>\n",
       "      <td>9.724 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.457493</td>\n",
       "      <td>0.609381</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.298258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.701742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:13</td>\n",
       "      <td>9.924 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.416518</td>\n",
       "      <td>0.523993</td>\n",
       "      <td>0.855942</td>\n",
       "      <td>0.699389</td>\n",
       "      <td>3.204609</td>\n",
       "      <td>0.237630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:13</td>\n",
       "      <td>10.062 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.393193</td>\n",
       "      <td>0.476615</td>\n",
       "      <td>0.871913</td>\n",
       "      <td>0.725902</td>\n",
       "      <td>3.204609</td>\n",
       "      <td>0.218826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:13</td>\n",
       "      <td>10.178 sec</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.376313</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>0.883008</td>\n",
       "      <td>0.752102</td>\n",
       "      <td>3.278704</td>\n",
       "      <td>0.199634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:13</td>\n",
       "      <td>10.278 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.366365</td>\n",
       "      <td>0.420279</td>\n",
       "      <td>0.889602</td>\n",
       "      <td>0.765890</td>\n",
       "      <td>3.315751</td>\n",
       "      <td>0.206457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:13</td>\n",
       "      <td>10.379 sec</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.358712</td>\n",
       "      <td>0.403668</td>\n",
       "      <td>0.894937</td>\n",
       "      <td>0.776549</td>\n",
       "      <td>3.315751</td>\n",
       "      <td>0.191147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:13</td>\n",
       "      <td>10.495 sec</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.352717</td>\n",
       "      <td>0.391131</td>\n",
       "      <td>0.900205</td>\n",
       "      <td>0.787701</td>\n",
       "      <td>3.260180</td>\n",
       "      <td>0.184879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:13</td>\n",
       "      <td>10.595 sec</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.347433</td>\n",
       "      <td>0.380658</td>\n",
       "      <td>0.905053</td>\n",
       "      <td>0.797776</td>\n",
       "      <td>3.297228</td>\n",
       "      <td>0.173009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:13</td>\n",
       "      <td>10.695 sec</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.342755</td>\n",
       "      <td>0.371323</td>\n",
       "      <td>0.909845</td>\n",
       "      <td>0.808765</td>\n",
       "      <td>3.334275</td>\n",
       "      <td>0.170291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:13</td>\n",
       "      <td>10.811 sec</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.338409</td>\n",
       "      <td>0.362472</td>\n",
       "      <td>0.913734</td>\n",
       "      <td>0.816763</td>\n",
       "      <td>3.315751</td>\n",
       "      <td>0.168793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:14</td>\n",
       "      <td>10.911 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.334768</td>\n",
       "      <td>0.355820</td>\n",
       "      <td>0.917473</td>\n",
       "      <td>0.823733</td>\n",
       "      <td>3.315751</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:14</td>\n",
       "      <td>11.027 sec</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.331072</td>\n",
       "      <td>0.348719</td>\n",
       "      <td>0.920772</td>\n",
       "      <td>0.830678</td>\n",
       "      <td>3.315751</td>\n",
       "      <td>0.160417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:14</td>\n",
       "      <td>11.127 sec</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.328083</td>\n",
       "      <td>0.343498</td>\n",
       "      <td>0.923494</td>\n",
       "      <td>0.836805</td>\n",
       "      <td>3.315751</td>\n",
       "      <td>0.154426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:14</td>\n",
       "      <td>11.228 sec</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.325921</td>\n",
       "      <td>0.339616</td>\n",
       "      <td>0.925154</td>\n",
       "      <td>0.841129</td>\n",
       "      <td>3.334275</td>\n",
       "      <td>0.152540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:14</td>\n",
       "      <td>11.331 sec</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.322487</td>\n",
       "      <td>0.333411</td>\n",
       "      <td>0.928417</td>\n",
       "      <td>0.848910</td>\n",
       "      <td>3.334275</td>\n",
       "      <td>0.144941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:14</td>\n",
       "      <td>11.450 sec</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.319668</td>\n",
       "      <td>0.328187</td>\n",
       "      <td>0.930799</td>\n",
       "      <td>0.854127</td>\n",
       "      <td>3.334275</td>\n",
       "      <td>0.147604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:14</td>\n",
       "      <td>11.551 sec</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.317078</td>\n",
       "      <td>0.323730</td>\n",
       "      <td>0.933239</td>\n",
       "      <td>0.858668</td>\n",
       "      <td>3.315751</td>\n",
       "      <td>0.138895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:52:14</td>\n",
       "      <td>11.582 sec</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.316532</td>\n",
       "      <td>0.322806</td>\n",
       "      <td>0.933722</td>\n",
       "      <td>0.859843</td>\n",
       "      <td>3.315751</td>\n",
       "      <td>0.136843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0     2021-05-31 07:52:12   9.724 sec              0.0       0.457493   \n",
       "1     2021-05-31 07:52:13   9.924 sec              5.0       0.416518   \n",
       "2     2021-05-31 07:52:13  10.062 sec             10.0       0.393193   \n",
       "3     2021-05-31 07:52:13  10.178 sec             15.0       0.376313   \n",
       "4     2021-05-31 07:52:13  10.278 sec             20.0       0.366365   \n",
       "5     2021-05-31 07:52:13  10.379 sec             25.0       0.358712   \n",
       "6     2021-05-31 07:52:13  10.495 sec             30.0       0.352717   \n",
       "7     2021-05-31 07:52:13  10.595 sec             35.0       0.347433   \n",
       "8     2021-05-31 07:52:13  10.695 sec             40.0       0.342755   \n",
       "9     2021-05-31 07:52:13  10.811 sec             45.0       0.338409   \n",
       "10    2021-05-31 07:52:14  10.911 sec             50.0       0.334768   \n",
       "11    2021-05-31 07:52:14  11.027 sec             55.0       0.331072   \n",
       "12    2021-05-31 07:52:14  11.127 sec             60.0       0.328083   \n",
       "13    2021-05-31 07:52:14  11.228 sec             65.0       0.325921   \n",
       "14    2021-05-31 07:52:14  11.331 sec             70.0       0.322487   \n",
       "15    2021-05-31 07:52:14  11.450 sec             75.0       0.319668   \n",
       "16    2021-05-31 07:52:14  11.551 sec             80.0       0.317078   \n",
       "17    2021-05-31 07:52:14  11.582 sec             81.0       0.316532   \n",
       "\n",
       "    training_logloss  training_auc  training_pr_auc  training_lift  \\\n",
       "0           0.609381      0.500000         0.298258       1.000000   \n",
       "1           0.523993      0.855942         0.699389       3.204609   \n",
       "2           0.476615      0.871913         0.725902       3.204609   \n",
       "3           0.441558      0.883008         0.752102       3.278704   \n",
       "4           0.420279      0.889602         0.765890       3.315751   \n",
       "5           0.403668      0.894937         0.776549       3.315751   \n",
       "6           0.391131      0.900205         0.787701       3.260180   \n",
       "7           0.380658      0.905053         0.797776       3.297228   \n",
       "8           0.371323      0.909845         0.808765       3.334275   \n",
       "9           0.362472      0.913734         0.816763       3.315751   \n",
       "10          0.355820      0.917473         0.823733       3.315751   \n",
       "11          0.348719      0.920772         0.830678       3.315751   \n",
       "12          0.343498      0.923494         0.836805       3.315751   \n",
       "13          0.339616      0.925154         0.841129       3.334275   \n",
       "14          0.333411      0.928417         0.848910       3.334275   \n",
       "15          0.328187      0.930799         0.854127       3.334275   \n",
       "16          0.323730      0.933239         0.858668       3.315751   \n",
       "17          0.322806      0.933722         0.859843       3.315751   \n",
       "\n",
       "    training_classification_error  \n",
       "0                        0.701742  \n",
       "1                        0.237630  \n",
       "2                        0.218826  \n",
       "3                        0.199634  \n",
       "4                        0.206457  \n",
       "5                        0.191147  \n",
       "6                        0.184879  \n",
       "7                        0.173009  \n",
       "8                        0.170291  \n",
       "9                        0.168793  \n",
       "10                       0.162913  \n",
       "11                       0.160417  \n",
       "12                       0.154426  \n",
       "13                       0.152540  \n",
       "14                       0.144941  \n",
       "15                       0.147604  \n",
       "16                       0.138895  \n",
       "17                       0.136843  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Percent_Days_Employed</td>\n",
       "      <td>2197.381348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jobs_Per_Year</td>\n",
       "      <td>1639.730469</td>\n",
       "      <td>0.746220</td>\n",
       "      <td>0.177625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delinquency_Reports</td>\n",
       "      <td>564.791931</td>\n",
       "      <td>0.257030</td>\n",
       "      <td>0.061181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avg_Days_per_DrugTest</td>\n",
       "      <td>433.241211</td>\n",
       "      <td>0.197163</td>\n",
       "      <td>0.046931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Age_at_Release</td>\n",
       "      <td>414.811951</td>\n",
       "      <td>0.188776</td>\n",
       "      <td>0.044935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DrugTests_THC_Positive</td>\n",
       "      <td>368.832581</td>\n",
       "      <td>0.167851</td>\n",
       "      <td>0.039954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Residence_Changes</td>\n",
       "      <td>333.255005</td>\n",
       "      <td>0.151660</td>\n",
       "      <td>0.036100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Prior_Arrest_Episodes_Felony</td>\n",
       "      <td>287.215363</td>\n",
       "      <td>0.130708</td>\n",
       "      <td>0.031113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Program_Attendances</td>\n",
       "      <td>268.366150</td>\n",
       "      <td>0.122130</td>\n",
       "      <td>0.029071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gang_Affiliated</td>\n",
       "      <td>235.279907</td>\n",
       "      <td>0.107073</td>\n",
       "      <td>0.025487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Supervision_Risk_Score_First</td>\n",
       "      <td>217.878128</td>\n",
       "      <td>0.099154</td>\n",
       "      <td>0.023602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Prior_Arrest_Episodes_PPViolationCharges</td>\n",
       "      <td>214.448868</td>\n",
       "      <td>0.097593</td>\n",
       "      <td>0.023230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DrugTests_Meth_Positive</td>\n",
       "      <td>205.373596</td>\n",
       "      <td>0.093463</td>\n",
       "      <td>0.022247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Prior_Arrest_Episodes_Property</td>\n",
       "      <td>174.659424</td>\n",
       "      <td>0.079485</td>\n",
       "      <td>0.018920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Prison_Offense</td>\n",
       "      <td>122.612854</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.013282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Residence_PUMA</td>\n",
       "      <td>122.424393</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>0.013262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Prior_Arrest_Episodes_Misd</td>\n",
       "      <td>120.198456</td>\n",
       "      <td>0.054701</td>\n",
       "      <td>0.013021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Supervision_Level_First</td>\n",
       "      <td>112.713821</td>\n",
       "      <td>0.051295</td>\n",
       "      <td>0.012210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Prior_Conviction_Episodes_Misd</td>\n",
       "      <td>104.228294</td>\n",
       "      <td>0.047433</td>\n",
       "      <td>0.011291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Prison_Years</td>\n",
       "      <td>101.280975</td>\n",
       "      <td>0.046092</td>\n",
       "      <td>0.010971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    variable  relative_importance  \\\n",
       "0                      Percent_Days_Employed          2197.381348   \n",
       "1                              Jobs_Per_Year          1639.730469   \n",
       "2                        Delinquency_Reports           564.791931   \n",
       "3                      Avg_Days_per_DrugTest           433.241211   \n",
       "4                             Age_at_Release           414.811951   \n",
       "5                     DrugTests_THC_Positive           368.832581   \n",
       "6                          Residence_Changes           333.255005   \n",
       "7               Prior_Arrest_Episodes_Felony           287.215363   \n",
       "8                        Program_Attendances           268.366150   \n",
       "9                            Gang_Affiliated           235.279907   \n",
       "10              Supervision_Risk_Score_First           217.878128   \n",
       "11  Prior_Arrest_Episodes_PPViolationCharges           214.448868   \n",
       "12                   DrugTests_Meth_Positive           205.373596   \n",
       "13            Prior_Arrest_Episodes_Property           174.659424   \n",
       "14                            Prison_Offense           122.612854   \n",
       "15                            Residence_PUMA           122.424393   \n",
       "16                Prior_Arrest_Episodes_Misd           120.198456   \n",
       "17                   Supervision_Level_First           112.713821   \n",
       "18            Prior_Conviction_Episodes_Misd           104.228294   \n",
       "19                              Prison_Years           101.280975   \n",
       "\n",
       "    scaled_importance  percentage  \n",
       "0            1.000000    0.238033  \n",
       "1            0.746220    0.177625  \n",
       "2            0.257030    0.061181  \n",
       "3            0.197163    0.046931  \n",
       "4            0.188776    0.044935  \n",
       "5            0.167851    0.039954  \n",
       "6            0.151660    0.036100  \n",
       "7            0.130708    0.031113  \n",
       "8            0.122130    0.029071  \n",
       "9            0.107073    0.025487  \n",
       "10           0.099154    0.023602  \n",
       "11           0.097593    0.023230  \n",
       "12           0.093463    0.022247  \n",
       "13           0.079485    0.018920  \n",
       "14           0.055800    0.013282  \n",
       "15           0.055714    0.013262  \n",
       "16           0.054701    0.013021  \n",
       "17           0.051295    0.012210  \n",
       "18           0.047433    0.011291  \n",
       "19           0.046092    0.010971  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbm = h2o.get_model([mid for mid in model_ids if \"GBM\" in mid][0])\n",
    "print(gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "NIJ_Test_Mod = h2o.import_file(\"NIJ_s_Recidivism_Challenge_Test_Dataset1-sara.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:7807\n",
      "Cols:33\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>ID                </th><th>Gender  </th><th>Race  </th><th>Age_at_Release  </th><th>Residence_PUMA   </th><th>Gang_Affiliated  </th><th>Supervision_Risk_Score_First  </th><th>Supervision_Level_First  </th><th>Education_Level      </th><th>Dependents        </th><th>Prison_Offense  </th><th>Prison_Years             </th><th>Prior_Arrest_Episodes_Felony  </th><th>Prior_Arrest_Episodes_Misd  </th><th>Prior_Arrest_Episodes_Violent  </th><th>Prior_Arrest_Episodes_Property  </th><th>Prior_Arrest_Episodes_Drug  </th><th>Prior_Arrest_Episodes_PPViolationCharges  </th><th>Prior_Arrest_Episodes_DVCharges  </th><th>Prior_Arrest_Episodes_GunCharges  </th><th>Prior_Conviction_Episodes_Felony  </th><th>Prior_Conviction_Episodes_Misd  </th><th>Prior_Conviction_Episodes_Viol  </th><th>Prior_Conviction_Episodes_Prop  </th><th>Prior_Conviction_Episodes_Drug  </th><th>Prior_Conviction_Episodes_PPViolationCharges  </th><th>Prior_Conviction_Episodes_DomesticViolenceCharges  </th><th>Prior_Conviction_Episodes_GunCharges  </th><th>Prior_Revocations_Parole  </th><th>Prior_Revocations_Probation  </th><th>Condition_MH_SA  </th><th>Condition_Cog_Ed  </th><th>Condition_Other  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int               </td><td>enum    </td><td>enum  </td><td>enum            </td><td>int              </td><td>enum             </td><td>int                           </td><td>enum                     </td><td>enum                 </td><td>int               </td><td>enum            </td><td>enum                     </td><td>int                           </td><td>int                         </td><td>int                            </td><td>int                             </td><td>int                         </td><td>int                                       </td><td>enum                             </td><td>enum                              </td><td>int                               </td><td>int                             </td><td>enum                            </td><td>int                             </td><td>int                             </td><td>enum                                          </td><td>enum                                               </td><td>enum                                  </td><td>enum                      </td><td>enum                         </td><td>enum             </td><td>enum              </td><td>enum             </td></tr>\n",
       "<tr><td>mins   </td><td>6.0               </td><td>        </td><td>      </td><td>                </td><td>1.0              </td><td>                 </td><td>1.0                           </td><td>                         </td><td>                     </td><td>0.0               </td><td>                </td><td>                         </td><td>0.0                           </td><td>0.0                         </td><td>0.0                            </td><td>0.0                             </td><td>0.0                         </td><td>0.0                                       </td><td>                                 </td><td>                                  </td><td>0.0                               </td><td>0.0                             </td><td>                                </td><td>0.0                             </td><td>0.0                             </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td></tr>\n",
       "<tr><td>mean   </td><td>13147.602023824773</td><td>        </td><td>      </td><td>                </td><td>12.48699884718842</td><td>                 </td><td>6.1225528582615505            </td><td>                         </td><td>                     </td><td>0.8110582204320762</td><td>                </td><td>                         </td><td>4.460160696350853             </td><td>2.083614548181478           </td><td>0.664463802943827              </td><td>1.4269331585845346              </td><td>1.3597837205903849          </td><td>1.487825356842989                         </td><td>                                 </td><td>                                  </td><td>0.8320836965998256                </td><td>1.1035737921906021              </td><td>                                </td><td>0.6062226543509966              </td><td>0.3482127288578902              </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td></tr>\n",
       "<tr><td>maxs   </td><td>26755.0           </td><td>        </td><td>      </td><td>                </td><td>25.0             </td><td>                 </td><td>10.0                          </td><td>                         </td><td>                     </td><td>2.0               </td><td>                </td><td>                         </td><td>9.0                           </td><td>5.0                         </td><td>2.0                            </td><td>4.0                             </td><td>4.0                         </td><td>4.0                                       </td><td>                                 </td><td>                                  </td><td>2.0                               </td><td>3.0                             </td><td>                                </td><td>2.0                             </td><td>1.0                             </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td></tr>\n",
       "<tr><td>sigma  </td><td>7721.873304986551 </td><td>        </td><td>      </td><td>                </td><td>7.110601208719824</td><td>                 </td><td>2.377941170789086             </td><td>                         </td><td>                     </td><td>0.817431863459127 </td><td>                </td><td>                         </td><td>2.413548531783437             </td><td>1.6658124644167591          </td><td>0.7459682969010476             </td><td>1.3176110953709808              </td><td>1.3216991712175232          </td><td>1.3757989915053217                        </td><td>                                 </td><td>                                  </td><td>0.7749226814076573                </td><td>1.0695770981890422              </td><td>                                </td><td>0.7468053029174522              </td><td>0.47644538603299535             </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td></tr>\n",
       "<tr><td>zeros  </td><td>0                 </td><td>        </td><td>      </td><td>                </td><td>0                </td><td>                 </td><td>0                             </td><td>                         </td><td>                     </td><td>2438              </td><td>                </td><td>                         </td><td>61                            </td><td>1246                        </td><td>3344                           </td><td>1956                            </td><td>2439                        </td><td>1981                                      </td><td>                                 </td><td>                                  </td><td>2284                              </td><td>2312                            </td><td>                                </td><td>3414                            </td><td>3738                            </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td></tr>\n",
       "<tr><td>missing</td><td>0                 </td><td>0       </td><td>0     </td><td>0               </td><td>0                </td><td>950              </td><td>145                           </td><td>508                      </td><td>0                    </td><td>2345              </td><td>956             </td><td>0                        </td><td>1833                          </td><td>2473                        </td><td>1149                           </td><td>1703                            </td><td>964                         </td><td>1852                                      </td><td>0                                </td><td>0                                 </td><td>2072                              </td><td>1763                            </td><td>0                               </td><td>1636                            </td><td>2072                            </td><td>0                                             </td><td>0                                                  </td><td>0                                     </td><td>0                         </td><td>0                            </td><td>0                </td><td>0                 </td><td>0                </td></tr>\n",
       "<tr><td>0      </td><td>6.0               </td><td>M       </td><td>WHITE </td><td>38-42           </td><td>17.0             </td><td>false            </td><td>5.0                           </td><td>Standard                 </td><td>High School Diploma  </td><td>0.0               </td><td>Property        </td><td>More than 3 years        </td><td>4.0                           </td><td>0.0                         </td><td>1.0                            </td><td>3.0                             </td><td>0.0                         </td><td>0.0                                       </td><td>false                            </td><td>false                             </td><td>1.0                               </td><td>0.0                             </td><td>false                           </td><td>2.0                             </td><td>0.0                             </td><td>false                                         </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>false            </td><td>false             </td><td>true             </td></tr>\n",
       "<tr><td>1      </td><td>8.0               </td><td>M       </td><td>BLACK </td><td>38-42           </td><td>16.0             </td><td>false            </td><td>5.0                           </td><td>High                     </td><td>High School Diploma  </td><td>nan               </td><td>Drug            </td><td>Greater than 2 to 3 years</td><td>6.0                           </td><td>nan                         </td><td>nan                            </td><td>1.0                             </td><td>2.0                         </td><td>nan                                       </td><td>false                            </td><td>false                             </td><td>1.0                               </td><td>nan                             </td><td>true                            </td><td>0.0                             </td><td>nan                             </td><td>true                                          </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>false            </td><td>true              </td><td>false            </td></tr>\n",
       "<tr><td>2      </td><td>12.0              </td><td>M       </td><td>BLACK </td><td>33-37           </td><td>16.0             </td><td>false            </td><td>5.0                           </td><td>Specialized              </td><td>High School Diploma  </td><td>nan               </td><td>Other           </td><td>1-2 years                </td><td>nan                           </td><td>1.0                         </td><td>1.0                            </td><td>1.0                             </td><td>2.0                         </td><td>3.0                                       </td><td>false                            </td><td>false                             </td><td>nan                               </td><td>1.0                             </td><td>false                           </td><td>0.0                             </td><td>nan                             </td><td>false                                         </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>true                         </td><td>true             </td><td>true              </td><td>true             </td></tr>\n",
       "<tr><td>3      </td><td>15.0              </td><td>M       </td><td>WHITE </td><td>33-37           </td><td>5.0              </td><td>false            </td><td>7.0                           </td><td>Standard                 </td><td>Less than HS diploma </td><td>1.0               </td><td>Violent/Non-Sex </td><td>Greater than 2 to 3 years</td><td>9.0                           </td><td>3.0                         </td><td>2.0                            </td><td>2.0                             </td><td>4.0                         </td><td>4.0                                       </td><td>false                            </td><td>true                              </td><td>nan                               </td><td>2.0                             </td><td>true                            </td><td>1.0                             </td><td>1.0                             </td><td>true                                          </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>true             </td><td>true              </td><td>true             </td></tr>\n",
       "<tr><td>4      </td><td>16.0              </td><td>M       </td><td>BLACK </td><td>33-37           </td><td>3.0              </td><td>false            </td><td>4.0                           </td><td>Standard                 </td><td>Less than HS diploma </td><td>nan               </td><td>                </td><td>More than 3 years        </td><td>4.0                           </td><td>nan                         </td><td>0.0                            </td><td>0.0                             </td><td>3.0                         </td><td>4.0                                       </td><td>false                            </td><td>true                              </td><td>2.0                               </td><td>nan                             </td><td>false                           </td><td>0.0                             </td><td>nan                             </td><td>true                                          </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>true             </td><td>true              </td><td>false            </td></tr>\n",
       "<tr><td>5      </td><td>23.0              </td><td>F       </td><td>WHITE </td><td>48 or older     </td><td>5.0              </td><td>                 </td><td>4.0                           </td><td>                         </td><td>High School Diploma  </td><td>0.0               </td><td>Violent/Non-Sex </td><td>1-2 years                </td><td>2.0                           </td><td>nan                         </td><td>nan                            </td><td>nan                             </td><td>0.0                         </td><td>1.0                                       </td><td>true                             </td><td>false                             </td><td>2.0                               </td><td>2.0                             </td><td>true                            </td><td>1.0                             </td><td>0.0                             </td><td>false                                         </td><td>true                                               </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>true             </td><td>true              </td><td>false            </td></tr>\n",
       "<tr><td>6      </td><td>27.0              </td><td>M       </td><td>WHITE </td><td>48 or older     </td><td>14.0             </td><td>false            </td><td>2.0                           </td><td>Specialized              </td><td>Less than HS diploma </td><td>0.0               </td><td>Drug            </td><td>1-2 years                </td><td>9.0                           </td><td>nan                         </td><td>0.0                            </td><td>0.0                             </td><td>2.0                         </td><td>nan                                       </td><td>false                            </td><td>false                             </td><td>nan                               </td><td>nan                             </td><td>false                           </td><td>0.0                             </td><td>nan                             </td><td>true                                          </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>true             </td><td>false             </td><td>true             </td></tr>\n",
       "<tr><td>7      </td><td>28.0              </td><td>M       </td><td>WHITE </td><td>48 or older     </td><td>23.0             </td><td>false            </td><td>3.0                           </td><td>Standard                 </td><td>Less than HS diploma </td><td>0.0               </td><td>Other           </td><td>1-2 years                </td><td>nan                           </td><td>nan                         </td><td>nan                            </td><td>nan                             </td><td>1.0                         </td><td>nan                                       </td><td>false                            </td><td>false                             </td><td>nan                               </td><td>nan                             </td><td>true                            </td><td>nan                             </td><td>1.0                             </td><td>true                                          </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>true             </td><td>true              </td><td>false            </td></tr>\n",
       "<tr><td>8      </td><td>31.0              </td><td>M       </td><td>WHITE </td><td>43-47           </td><td>14.0             </td><td>false            </td><td>10.0                          </td><td>Specialized              </td><td>At least some college</td><td>0.0               </td><td>Property        </td><td>1-2 years                </td><td>nan                           </td><td>nan                         </td><td>nan                            </td><td>nan                             </td><td>0.0                         </td><td>nan                                       </td><td>true                             </td><td>true                              </td><td>nan                               </td><td>nan                             </td><td>false                           </td><td>nan                             </td><td>0.0                             </td><td>true                                          </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>true                         </td><td>true             </td><td>false             </td><td>true             </td></tr>\n",
       "<tr><td>9      </td><td>35.0              </td><td>M       </td><td>WHITE </td><td>33-37           </td><td>14.0             </td><td>false            </td><td>4.0                           </td><td>Standard                 </td><td>Less than HS diploma </td><td>0.0               </td><td>Drug            </td><td>Less than 1 year         </td><td>5.0                           </td><td>nan                         </td><td>1.0                            </td><td>0.0                             </td><td>4.0                         </td><td>nan                                       </td><td>false                            </td><td>true                              </td><td>nan                               </td><td>nan                             </td><td>false                           </td><td>0.0                             </td><td>nan                             </td><td>true                                          </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>false            </td><td>false             </td><td>false            </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NIJ_Test_Mod.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'Gender',\n",
       " 'Race',\n",
       " 'Age_at_Release',\n",
       " 'Residence_PUMA',\n",
       " 'Gang_Affiliated',\n",
       " 'Supervision_Risk_Score_First',\n",
       " 'Supervision_Level_First',\n",
       " 'Education_Level',\n",
       " 'Dependents',\n",
       " 'Prison_Offense',\n",
       " 'Prison_Years',\n",
       " 'Prior_Arrest_Episodes_Felony',\n",
       " 'Prior_Arrest_Episodes_Misd',\n",
       " 'Prior_Arrest_Episodes_Violent',\n",
       " 'Prior_Arrest_Episodes_Property',\n",
       " 'Prior_Arrest_Episodes_Drug',\n",
       " 'Prior_Arrest_Episodes_PPViolationCharges',\n",
       " 'Prior_Arrest_Episodes_DVCharges',\n",
       " 'Prior_Arrest_Episodes_GunCharges',\n",
       " 'Prior_Conviction_Episodes_Felony',\n",
       " 'Prior_Conviction_Episodes_Misd',\n",
       " 'Prior_Conviction_Episodes_Viol',\n",
       " 'Prior_Conviction_Episodes_Prop',\n",
       " 'Prior_Conviction_Episodes_Drug',\n",
       " 'Prior_Conviction_Episodes_PPViolationCharges',\n",
       " 'Prior_Conviction_Episodes_DomesticViolenceCharges',\n",
       " 'Prior_Conviction_Episodes_GunCharges',\n",
       " 'Prior_Revocations_Parole',\n",
       " 'Prior_Revocations_Probation',\n",
       " 'Condition_MH_SA',\n",
       " 'Condition_Cog_Ed',\n",
       " 'Condition_Other']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NIJ_Test_Mod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NIJ_Test_Mod.ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "H2OValueError",
     "evalue": "Column(s) selected to drop are not in original frame: ['ID']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mH2OValueError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-b7251d93bf09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mNIJ_Test_Mod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNIJ_Test_Mod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ID\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h2o\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, index, axis)\u001b[0m\n\u001b[0;32m   2529\u001b[0m                     \u001b[1;31m#Check if index is an actual column(s) in the frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2530\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2531\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mH2OValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Column(s) selected to drop are not in original frame: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2532\u001b[0m                     \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2533\u001b[0m                 \u001b[0mfr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mH2OFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mExprNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cols\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mH2OValueError\u001b[0m: Column(s) selected to drop are not in original frame: ['ID']"
     ]
    }
   ],
   "source": [
    "NIJ_Test_Mod=NIJ_Test_Mod.drop([\"ID\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender',\n",
       " 'Race',\n",
       " 'Age_at_Release',\n",
       " 'Residence_PUMA',\n",
       " 'Gang_Affiliated',\n",
       " 'Supervision_Risk_Score_First',\n",
       " 'Supervision_Level_First',\n",
       " 'Education_Level',\n",
       " 'Dependents',\n",
       " 'Prison_Offense',\n",
       " 'Prison_Years',\n",
       " 'Prior_Arrest_Episodes_Felony',\n",
       " 'Prior_Arrest_Episodes_Misd',\n",
       " 'Prior_Arrest_Episodes_Violent',\n",
       " 'Prior_Arrest_Episodes_Property',\n",
       " 'Prior_Arrest_Episodes_Drug',\n",
       " 'Prior_Arrest_Episodes_PPViolationCharges',\n",
       " 'Prior_Arrest_Episodes_DVCharges',\n",
       " 'Prior_Arrest_Episodes_GunCharges',\n",
       " 'Prior_Conviction_Episodes_Felony',\n",
       " 'Prior_Conviction_Episodes_Misd',\n",
       " 'Prior_Conviction_Episodes_Viol',\n",
       " 'Prior_Conviction_Episodes_Prop',\n",
       " 'Prior_Conviction_Episodes_Drug',\n",
       " 'Prior_Conviction_Episodes_PPViolationCharges',\n",
       " 'Prior_Conviction_Episodes_DomesticViolenceCharges',\n",
       " 'Prior_Conviction_Episodes_GunCharges',\n",
       " 'Prior_Revocations_Parole',\n",
       " 'Prior_Revocations_Probation',\n",
       " 'Condition_MH_SA',\n",
       " 'Condition_Cog_Ed',\n",
       " 'Condition_Other']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NIJ_Test_Mod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "['ID', 'Gender', 'Race', 'Age_at_Release', 'Residence_PUMA', 'Gang_Affiliated', 'Supervision_Risk_Score_First', 'Supervision_Level_First', 'Education_Level', 'Dependents', 'Prison_Offense', 'Prison_Years', 'Prior_Arrest_Episodes_Felony', 'Prior_Arrest_Episodes_Misd', 'Prior_Arrest_Episodes_Violent', 'Prior_Arrest_Episodes_Property', 'Prior_Arrest_Episodes_Drug', 'Prior_Arrest_Episodes_PPViolationCharges', 'Prior_Arrest_Episodes_DVCharges', 'Prior_Arrest_Episodes_GunCharges', 'Prior_Conviction_Episodes_Felony', 'Prior_Conviction_Episodes_Misd', 'Prior_Conviction_Episodes_Viol', 'Prior_Conviction_Episodes_Prop', 'Prior_Conviction_Episodes_Drug', 'Prior_Conviction_Episodes_PPViolationCharges', 'Prior_Conviction_Episodes_DomesticViolenceCharges', 'Prior_Conviction_Episodes_GunCharges', 'Prior_Revocations_Parole', 'Prior_Revocations_Probation', 'Condition_MH_SA', 'Condition_Cog_Ed', 'Condition_Other', 'Recidivism_Arrest_Year1']\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "NIJ_Train_Mod_Lim = NIJ_Train_Mod[NIJ_Train_Mod.columns[0:-20]]\n",
    "# print(NIJ_Train_Mod_Lim.head())\n",
    "NIJ_y_train_Lim = NIJ_Train_Mod[NIJ_Train_Mod.columns[-3]]\n",
    "# print(NIJ_y_train_Lim.head())\n",
    "\n",
    "x_train_NIJ = h2o.H2OFrame(pd.concat([NIJ_Train_Mod_Lim,NIJ_y_train_Lim],axis=1))\n",
    "print(x_train_NIJ.columns)\n",
    "print(x_train_NIJ.ncols)\n",
    "# y_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender', 'Race', 'Age_at_Release', 'Residence_PUMA', 'Gang_Affiliated', 'Supervision_Risk_Score_First', 'Supervision_Level_First', 'Education_Level', 'Dependents', 'Prison_Offense', 'Prison_Years', 'Prior_Arrest_Episodes_Felony', 'Prior_Arrest_Episodes_Misd', 'Prior_Arrest_Episodes_Violent', 'Prior_Arrest_Episodes_Property', 'Prior_Arrest_Episodes_Drug', 'Prior_Arrest_Episodes_PPViolationCharges', 'Prior_Arrest_Episodes_DVCharges', 'Prior_Arrest_Episodes_GunCharges', 'Prior_Conviction_Episodes_Felony', 'Prior_Conviction_Episodes_Misd', 'Prior_Conviction_Episodes_Viol', 'Prior_Conviction_Episodes_Prop', 'Prior_Conviction_Episodes_Drug', 'Prior_Conviction_Episodes_PPViolationCharges', 'Prior_Conviction_Episodes_DomesticViolenceCharges', 'Prior_Conviction_Episodes_GunCharges', 'Prior_Revocations_Parole', 'Prior_Revocations_Probation', 'Condition_MH_SA', 'Condition_Cog_Ed', 'Condition_Other', 'Recidivism_Arrest_Year1']\n"
     ]
    }
   ],
   "source": [
    "y_lim= \"Recidivism_Arrest_Year1\"\n",
    "x_train_NIJ=x_train_NIJ.drop([\"ID\"],axis=1)\n",
    "x_lim= x_train_NIJ.columns\n",
    "print(x_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |█\n",
      "07:58:49.891: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "███████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml_lim = H2OAutoML(max_models = 10, seed = 1)\n",
    "aml_lim.train(x = x_lim, y = y_lim, training_frame = x_train_NIJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_lim= aml_lim.leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20210531_075849   </td><td style=\"text-align: right;\">0.702407</td><td style=\"text-align: right;\"> 0.553979</td><td style=\"text-align: right;\">0.47996 </td><td style=\"text-align: right;\">              0.356539</td><td style=\"text-align: right;\">0.432896</td><td style=\"text-align: right;\">0.187399</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20210531_075849</td><td style=\"text-align: right;\">0.701886</td><td style=\"text-align: right;\"> 0.554332</td><td style=\"text-align: right;\">0.480342</td><td style=\"text-align: right;\">              0.355547</td><td style=\"text-align: right;\">0.432969</td><td style=\"text-align: right;\">0.187462</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210531_075849_model_1         </td><td style=\"text-align: right;\">0.701719</td><td style=\"text-align: right;\"> 0.554617</td><td style=\"text-align: right;\">0.480573</td><td style=\"text-align: right;\">              0.352487</td><td style=\"text-align: right;\">0.433044</td><td style=\"text-align: right;\">0.187527</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20210531_075849                       </td><td style=\"text-align: right;\">0.697198</td><td style=\"text-align: right;\"> 0.557037</td><td style=\"text-align: right;\">0.470178</td><td style=\"text-align: right;\">              0.358984</td><td style=\"text-align: right;\">0.434409</td><td style=\"text-align: right;\">0.188711</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20210531_075849                       </td><td style=\"text-align: right;\">0.695324</td><td style=\"text-align: right;\"> 0.557721</td><td style=\"text-align: right;\">0.470921</td><td style=\"text-align: right;\">              0.361927</td><td style=\"text-align: right;\">0.434739</td><td style=\"text-align: right;\">0.188998</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20210531_075849                       </td><td style=\"text-align: right;\">0.693545</td><td style=\"text-align: right;\"> 0.559726</td><td style=\"text-align: right;\">0.461424</td><td style=\"text-align: right;\">              0.359735</td><td style=\"text-align: right;\">0.435787</td><td style=\"text-align: right;\">0.18991 </td></tr>\n",
       "<tr><td>GBM_3_AutoML_20210531_075849                       </td><td style=\"text-align: right;\">0.690449</td><td style=\"text-align: right;\"> 0.561736</td><td style=\"text-align: right;\">0.463679</td><td style=\"text-align: right;\">              0.36051 </td><td style=\"text-align: right;\">0.43647 </td><td style=\"text-align: right;\">0.190506</td></tr>\n",
       "<tr><td>GLM_1_AutoML_20210531_075849                       </td><td style=\"text-align: right;\">0.681036</td><td style=\"text-align: right;\"> 0.564955</td><td style=\"text-align: right;\">0.455544</td><td style=\"text-align: right;\">              0.376423</td><td style=\"text-align: right;\">0.437913</td><td style=\"text-align: right;\">0.191767</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20210531_075849                       </td><td style=\"text-align: right;\">0.680667</td><td style=\"text-align: right;\"> 0.568893</td><td style=\"text-align: right;\">0.45425 </td><td style=\"text-align: right;\">              0.374364</td><td style=\"text-align: right;\">0.439662</td><td style=\"text-align: right;\">0.193303</td></tr>\n",
       "<tr><td>DRF_1_AutoML_20210531_075849                       </td><td style=\"text-align: right;\">0.678007</td><td style=\"text-align: right;\"> 0.569444</td><td style=\"text-align: right;\">0.446666</td><td style=\"text-align: right;\">              0.379753</td><td style=\"text-align: right;\">0.439021</td><td style=\"text-align: right;\">0.192739</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20210531_075849                       </td><td style=\"text-align: right;\">0.673856</td><td style=\"text-align: right;\"> 0.568997</td><td style=\"text-align: right;\">0.442248</td><td style=\"text-align: right;\">              0.375323</td><td style=\"text-align: right;\">0.439723</td><td style=\"text-align: right;\">0.193356</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20210531_075849              </td><td style=\"text-align: right;\">0.664832</td><td style=\"text-align: right;\"> 0.575379</td><td style=\"text-align: right;\">0.437354</td><td style=\"text-align: right;\">              0.390575</td><td style=\"text-align: right;\">0.442917</td><td style=\"text-align: right;\">0.196175</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_lim.head(rows=lb_lim.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model ids for all models in the AutoML Leaderboard\n",
    "model_ids_lim = list(aml_lim.leaderboard['model_id'].as_data_frame().iloc[:,0])\n",
    "# Get the \"All Models\" Stacked Ensemble model\n",
    "se_lim = h2o.get_model([mid for mid in model_ids_lim if \"StackedEnsemble_AllModels\" in mid][0])\n",
    "# Get the Stacked Ensemble metalearner model\n",
    "metalearner_lim = se_lim.metalearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intercept': -0.984666516886417,\n",
       " 'GBM_grid__1_AutoML_20210531_075849_model_1': 0.3841967245011122,\n",
       " 'GBM_1_AutoML_20210531_075849': 0.12373939955019803,\n",
       " 'GBM_5_AutoML_20210531_075849': 0.11860128530090303,\n",
       " 'GBM_2_AutoML_20210531_075849': 0.03006182752910259,\n",
       " 'GBM_3_AutoML_20210531_075849': 0.04450615984491226,\n",
       " 'GLM_1_AutoML_20210531_075849': 0.10474133502886954,\n",
       " 'GBM_4_AutoML_20210531_075849': 0.013731906405278322,\n",
       " 'DRF_1_AutoML_20210531_075849': 0.027134365832594425,\n",
       " 'XRT_1_AutoML_20210531_075849': 0.006885993288546463,\n",
       " 'DeepLearning_1_AutoML_20210531_075849': 0.00028218313318751855}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metalearner_lim.coef_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "metalearner_lim.std_coef_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_AllModels_AutoML_20210531_075849\n",
      "\n",
      "No model summary for this model\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.16599992672772793\n",
      "RMSE: 0.40743088582939796\n",
      "LogLoss: 0.5012419572079362\n",
      "Null degrees of freedom: 10050\n",
      "Residual degrees of freedom: 10040\n",
      "Null deviance: 12311.739370632284\n",
      "Residual deviance: 10075.965823793933\n",
      "AIC: 10097.965823793933\n",
      "AUC: 0.7982632863836004\n",
      "AUCPR: 0.6364111368096138\n",
      "Gini: 0.5965265727672009\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.32277840333743085: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>5035.0</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>(1982.0/7017.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>809.0</td>\n",
       "      <td>2225.0</td>\n",
       "      <td>0.2666</td>\n",
       "      <td>(809.0/3034.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>5844.0</td>\n",
       "      <td>4207.0</td>\n",
       "      <td>0.2777</td>\n",
       "      <td>(2791.0/10051.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           False    True   Error               Rate\n",
       "0  False  5035.0  1982.0  0.2825    (1982.0/7017.0)\n",
       "1   True   809.0  2225.0  0.2666     (809.0/3034.0)\n",
       "2  Total  5844.0  4207.0  0.2777   (2791.0/10051.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.322778</td>\n",
       "      <td>0.614556</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.218948</td>\n",
       "      <td>0.738615</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.429882</td>\n",
       "      <td>0.597893</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.435698</td>\n",
       "      <td>0.761417</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.810522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.053661</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.810522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.325732</td>\n",
       "      <td>0.419778</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.325732</td>\n",
       "      <td>0.723671</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.322778</td>\n",
       "      <td>0.725449</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.810522</td>\n",
       "      <td>7017.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.810522</td>\n",
       "      <td>3032.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.024990</td>\n",
       "      <td>7017.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.053661</td>\n",
       "      <td>3034.000000</td>\n",
       "      <td>387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.810522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.810522</td>\n",
       "      <td>0.999341</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.024990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.053661</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>387.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.322778     0.614556  203.0\n",
       "1                        max f2   0.218948     0.738615  281.0\n",
       "2                  max f0point5   0.429882     0.597893  126.0\n",
       "3                  max accuracy   0.435698     0.761417  123.0\n",
       "4                 max precision   0.810522     1.000000    0.0\n",
       "5                    max recall   0.053661     1.000000  387.0\n",
       "6               max specificity   0.810522     1.000000    0.0\n",
       "7              max absolute_mcc   0.325732     0.419778  201.0\n",
       "8    max min_per_class_accuracy   0.325732     0.723671  201.0\n",
       "9   max mean_per_class_accuracy   0.322778     0.725449  203.0\n",
       "10                      max tns   0.810522  7017.000000    0.0\n",
       "11                      max fns   0.810522  3032.000000    0.0\n",
       "12                      max fps   0.024990  7017.000000  399.0\n",
       "13                      max tps   0.053661  3034.000000  387.0\n",
       "14                      max tnr   0.810522     1.000000    0.0\n",
       "15                      max fnr   0.810522     0.999341    0.0\n",
       "16                      max fpr   0.024990     1.000000  399.0\n",
       "17                      max tpr   0.053661     1.000000  387.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 30.19 %, avg score: 29.75 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>0.672434</td>\n",
       "      <td>3.115989</td>\n",
       "      <td>3.115989</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.720141</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.720141</td>\n",
       "      <td>0.031312</td>\n",
       "      <td>0.031312</td>\n",
       "      <td>211.598909</td>\n",
       "      <td>211.598909</td>\n",
       "      <td>0.030457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020098</td>\n",
       "      <td>0.628550</td>\n",
       "      <td>2.853590</td>\n",
       "      <td>2.984790</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.650404</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>0.685272</td>\n",
       "      <td>0.028675</td>\n",
       "      <td>0.059987</td>\n",
       "      <td>185.359001</td>\n",
       "      <td>198.478955</td>\n",
       "      <td>0.057137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030047</td>\n",
       "      <td>0.605233</td>\n",
       "      <td>2.848998</td>\n",
       "      <td>2.939825</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.615855</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.662287</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>0.088332</td>\n",
       "      <td>184.899802</td>\n",
       "      <td>193.982547</td>\n",
       "      <td>0.083487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040096</td>\n",
       "      <td>0.584372</td>\n",
       "      <td>2.623991</td>\n",
       "      <td>2.860671</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.595263</td>\n",
       "      <td>0.863524</td>\n",
       "      <td>0.645489</td>\n",
       "      <td>0.026368</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>162.399081</td>\n",
       "      <td>186.067087</td>\n",
       "      <td>0.106862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050045</td>\n",
       "      <td>0.563311</td>\n",
       "      <td>2.285824</td>\n",
       "      <td>2.746387</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.573408</td>\n",
       "      <td>0.829026</td>\n",
       "      <td>0.631159</td>\n",
       "      <td>0.022742</td>\n",
       "      <td>0.137442</td>\n",
       "      <td>128.582399</td>\n",
       "      <td>174.638720</td>\n",
       "      <td>0.125186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100090</td>\n",
       "      <td>0.507822</td>\n",
       "      <td>2.291949</td>\n",
       "      <td>2.519168</td>\n",
       "      <td>0.691849</td>\n",
       "      <td>0.532490</td>\n",
       "      <td>0.760437</td>\n",
       "      <td>0.581824</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.252142</td>\n",
       "      <td>129.194903</td>\n",
       "      <td>151.916812</td>\n",
       "      <td>0.217797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150035</td>\n",
       "      <td>0.466711</td>\n",
       "      <td>1.874167</td>\n",
       "      <td>2.304453</td>\n",
       "      <td>0.565737</td>\n",
       "      <td>0.485758</td>\n",
       "      <td>0.695623</td>\n",
       "      <td>0.549845</td>\n",
       "      <td>0.093606</td>\n",
       "      <td>0.345748</td>\n",
       "      <td>87.416714</td>\n",
       "      <td>130.445294</td>\n",
       "      <td>0.280336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200080</td>\n",
       "      <td>0.432515</td>\n",
       "      <td>1.791408</td>\n",
       "      <td>2.176128</td>\n",
       "      <td>0.540755</td>\n",
       "      <td>0.449355</td>\n",
       "      <td>0.656887</td>\n",
       "      <td>0.524710</td>\n",
       "      <td>0.089651</td>\n",
       "      <td>0.435399</td>\n",
       "      <td>79.140844</td>\n",
       "      <td>117.612803</td>\n",
       "      <td>0.337066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300070</td>\n",
       "      <td>0.376253</td>\n",
       "      <td>1.480042</td>\n",
       "      <td>1.944176</td>\n",
       "      <td>0.446766</td>\n",
       "      <td>0.404461</td>\n",
       "      <td>0.586870</td>\n",
       "      <td>0.484640</td>\n",
       "      <td>0.147989</td>\n",
       "      <td>0.583388</td>\n",
       "      <td>48.004178</td>\n",
       "      <td>94.417622</td>\n",
       "      <td>0.405820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400060</td>\n",
       "      <td>0.330553</td>\n",
       "      <td>1.269078</td>\n",
       "      <td>1.775444</td>\n",
       "      <td>0.383085</td>\n",
       "      <td>0.352672</td>\n",
       "      <td>0.535936</td>\n",
       "      <td>0.451656</td>\n",
       "      <td>0.126895</td>\n",
       "      <td>0.710283</td>\n",
       "      <td>26.907814</td>\n",
       "      <td>77.544367</td>\n",
       "      <td>0.444358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500050</td>\n",
       "      <td>0.286019</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>1.618824</td>\n",
       "      <td>0.299502</td>\n",
       "      <td>0.307606</td>\n",
       "      <td>0.488659</td>\n",
       "      <td>0.422852</td>\n",
       "      <td>0.099209</td>\n",
       "      <td>0.809492</td>\n",
       "      <td>-0.781163</td>\n",
       "      <td>61.882378</td>\n",
       "      <td>0.443239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600040</td>\n",
       "      <td>0.241809</td>\n",
       "      <td>0.692224</td>\n",
       "      <td>1.464416</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.264452</td>\n",
       "      <td>0.442049</td>\n",
       "      <td>0.396456</td>\n",
       "      <td>0.069216</td>\n",
       "      <td>0.878708</td>\n",
       "      <td>-30.777556</td>\n",
       "      <td>46.441616</td>\n",
       "      <td>0.399158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.700030</td>\n",
       "      <td>0.198616</td>\n",
       "      <td>0.504335</td>\n",
       "      <td>1.327281</td>\n",
       "      <td>0.152239</td>\n",
       "      <td>0.220605</td>\n",
       "      <td>0.400654</td>\n",
       "      <td>0.371338</td>\n",
       "      <td>0.050428</td>\n",
       "      <td>0.929136</td>\n",
       "      <td>-49.566505</td>\n",
       "      <td>32.728120</td>\n",
       "      <td>0.328167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.800020</td>\n",
       "      <td>0.152394</td>\n",
       "      <td>0.408742</td>\n",
       "      <td>1.212478</td>\n",
       "      <td>0.123383</td>\n",
       "      <td>0.175610</td>\n",
       "      <td>0.365999</td>\n",
       "      <td>0.346875</td>\n",
       "      <td>0.040870</td>\n",
       "      <td>0.970007</td>\n",
       "      <td>-59.125795</td>\n",
       "      <td>21.247808</td>\n",
       "      <td>0.243485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.900010</td>\n",
       "      <td>0.101538</td>\n",
       "      <td>0.227445</td>\n",
       "      <td>1.103042</td>\n",
       "      <td>0.068657</td>\n",
       "      <td>0.126880</td>\n",
       "      <td>0.332965</td>\n",
       "      <td>0.322434</td>\n",
       "      <td>0.022742</td>\n",
       "      <td>0.992749</td>\n",
       "      <td>-77.255483</td>\n",
       "      <td>10.304208</td>\n",
       "      <td>0.132837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023961</td>\n",
       "      <td>0.072519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021891</td>\n",
       "      <td>0.072973</td>\n",
       "      <td>0.301861</td>\n",
       "      <td>0.297490</td>\n",
       "      <td>0.007251</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-92.748125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010049         0.672434  3.115989   \n",
       "1       2                  0.020098         0.628550  2.853590   \n",
       "2       3                  0.030047         0.605233  2.848998   \n",
       "3       4                  0.040096         0.584372  2.623991   \n",
       "4       5                  0.050045         0.563311  2.285824   \n",
       "5       6                  0.100090         0.507822  2.291949   \n",
       "6       7                  0.150035         0.466711  1.874167   \n",
       "7       8                  0.200080         0.432515  1.791408   \n",
       "8       9                  0.300070         0.376253  1.480042   \n",
       "9      10                  0.400060         0.330553  1.269078   \n",
       "10     11                  0.500050         0.286019  0.992188   \n",
       "11     12                  0.600040         0.241809  0.692224   \n",
       "12     13                  0.700030         0.198616  0.504335   \n",
       "13     14                  0.800020         0.152394  0.408742   \n",
       "14     15                  0.900010         0.101538  0.227445   \n",
       "15     16                  1.000000         0.023961  0.072519   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          3.115989       0.940594  0.720141                  0.940594   \n",
       "1          2.984790       0.861386  0.650404                  0.900990   \n",
       "2          2.939825       0.860000  0.615855                  0.887417   \n",
       "3          2.860671       0.792079  0.595263                  0.863524   \n",
       "4          2.746387       0.690000  0.573408                  0.829026   \n",
       "5          2.519168       0.691849  0.532490                  0.760437   \n",
       "6          2.304453       0.565737  0.485758                  0.695623   \n",
       "7          2.176128       0.540755  0.449355                  0.656887   \n",
       "8          1.944176       0.446766  0.404461                  0.586870   \n",
       "9          1.775444       0.383085  0.352672                  0.535936   \n",
       "10         1.618824       0.299502  0.307606                  0.488659   \n",
       "11         1.464416       0.208955  0.264452                  0.442049   \n",
       "12         1.327281       0.152239  0.220605                  0.400654   \n",
       "13         1.212478       0.123383  0.175610                  0.365999   \n",
       "14         1.103042       0.068657  0.126880                  0.332965   \n",
       "15         1.000000       0.021891  0.072973                  0.301861   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.720141      0.031312                 0.031312  211.598909   \n",
       "1           0.685272      0.028675                 0.059987  185.359001   \n",
       "2           0.662287      0.028345                 0.088332  184.899802   \n",
       "3           0.645489      0.026368                 0.114700  162.399081   \n",
       "4           0.631159      0.022742                 0.137442  128.582399   \n",
       "5           0.581824      0.114700                 0.252142  129.194903   \n",
       "6           0.549845      0.093606                 0.345748   87.416714   \n",
       "7           0.524710      0.089651                 0.435399   79.140844   \n",
       "8           0.484640      0.147989                 0.583388   48.004178   \n",
       "9           0.451656      0.126895                 0.710283   26.907814   \n",
       "10          0.422852      0.099209                 0.809492   -0.781163   \n",
       "11          0.396456      0.069216                 0.878708  -30.777556   \n",
       "12          0.371338      0.050428                 0.929136  -49.566505   \n",
       "13          0.346875      0.040870                 0.970007  -59.125795   \n",
       "14          0.322434      0.022742                 0.992749  -77.255483   \n",
       "15          0.297490      0.007251                 1.000000  -92.748125   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        211.598909            0.030457  \n",
       "1        198.478955            0.057137  \n",
       "2        193.982547            0.083487  \n",
       "3        186.067087            0.106862  \n",
       "4        174.638720            0.125186  \n",
       "5        151.916812            0.217797  \n",
       "6        130.445294            0.280336  \n",
       "7        117.612803            0.337066  \n",
       "8         94.417622            0.405820  \n",
       "9         77.544367            0.444358  \n",
       "10        61.882378            0.443239  \n",
       "11        46.441616            0.399158  \n",
       "12        32.728120            0.328167  \n",
       "13        21.247808            0.243485  \n",
       "14        10.304208            0.132837  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.18739864504527817\n",
      "RMSE: 0.4328956514511068\n",
      "LogLoss: 0.5539789838884539\n",
      "Null degrees of freedom: 18027\n",
      "Residual degrees of freedom: 18019\n",
      "Null deviance: 21973.61593555157\n",
      "Residual deviance: 19974.2662430821\n",
      "AIC: 19992.2662430821\n",
      "AUC: 0.7024066443073457\n",
      "AUCPR: 0.47996026526243196\n",
      "Gini: 0.40481328861469135\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.24785991013167266: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>6225.0</td>\n",
       "      <td>6426.0</td>\n",
       "      <td>0.5079</td>\n",
       "      <td>(6426.0/12651.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>4274.0</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>(1103.0/5377.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>7328.0</td>\n",
       "      <td>10700.0</td>\n",
       "      <td>0.4176</td>\n",
       "      <td>(7529.0/18028.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           False     True   Error               Rate\n",
       "0  False  6225.0   6426.0  0.5079   (6426.0/12651.0)\n",
       "1   True  1103.0   4274.0  0.2051    (1103.0/5377.0)\n",
       "2  Total  7328.0  10700.0  0.4176   (7529.0/18028.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.247860</td>\n",
       "      <td>0.531691</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.146675</td>\n",
       "      <td>0.700138</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.368363</td>\n",
       "      <td>0.478947</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.510074</td>\n",
       "      <td>0.714999</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.802938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.802938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.285690</td>\n",
       "      <td>0.272344</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.314594</td>\n",
       "      <td>0.646747</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.285690</td>\n",
       "      <td>0.648811</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.802938</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.802938</td>\n",
       "      <td>5374.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>5377.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.802938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.802938</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.247860      0.531691  258.0\n",
       "1                        max f2   0.146675      0.700138  327.0\n",
       "2                  max f0point5   0.368363      0.478947  173.0\n",
       "3                  max accuracy   0.510074      0.714999   87.0\n",
       "4                 max precision   0.802938      1.000000    0.0\n",
       "5                    max recall   0.014830      1.000000  399.0\n",
       "6               max specificity   0.802938      1.000000    0.0\n",
       "7              max absolute_mcc   0.285690      0.272344  231.0\n",
       "8    max min_per_class_accuracy   0.314594      0.646747  211.0\n",
       "9   max mean_per_class_accuracy   0.285690      0.648811  231.0\n",
       "10                      max tns   0.802938  12651.000000    0.0\n",
       "11                      max fns   0.802938   5374.000000    0.0\n",
       "12                      max fps   0.014830  12651.000000  399.0\n",
       "13                      max tps   0.014830   5377.000000  399.0\n",
       "14                      max tnr   0.802938      1.000000    0.0\n",
       "15                      max fnr   0.802938      0.999442    0.0\n",
       "16                      max fpr   0.014830      1.000000  399.0\n",
       "17                      max tpr   0.014830      1.000000  399.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 29.83 %, avg score: 29.83 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.662447</td>\n",
       "      <td>2.241374</td>\n",
       "      <td>2.241374</td>\n",
       "      <td>0.668508</td>\n",
       "      <td>0.704088</td>\n",
       "      <td>0.668508</td>\n",
       "      <td>0.704088</td>\n",
       "      <td>0.022503</td>\n",
       "      <td>0.022503</td>\n",
       "      <td>124.137389</td>\n",
       "      <td>124.137389</td>\n",
       "      <td>0.017761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020024</td>\n",
       "      <td>0.623118</td>\n",
       "      <td>2.272453</td>\n",
       "      <td>2.256870</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.641601</td>\n",
       "      <td>0.673130</td>\n",
       "      <td>0.672931</td>\n",
       "      <td>0.022689</td>\n",
       "      <td>0.045192</td>\n",
       "      <td>127.245263</td>\n",
       "      <td>125.687021</td>\n",
       "      <td>0.035865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030009</td>\n",
       "      <td>0.599815</td>\n",
       "      <td>2.011679</td>\n",
       "      <td>2.175291</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.610927</td>\n",
       "      <td>0.648799</td>\n",
       "      <td>0.652301</td>\n",
       "      <td>0.020086</td>\n",
       "      <td>0.065278</td>\n",
       "      <td>101.167938</td>\n",
       "      <td>117.529101</td>\n",
       "      <td>0.050259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040049</td>\n",
       "      <td>0.577574</td>\n",
       "      <td>1.944994</td>\n",
       "      <td>2.117557</td>\n",
       "      <td>0.580110</td>\n",
       "      <td>0.587867</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.636148</td>\n",
       "      <td>0.019528</td>\n",
       "      <td>0.084806</td>\n",
       "      <td>94.499387</td>\n",
       "      <td>111.755724</td>\n",
       "      <td>0.063780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050033</td>\n",
       "      <td>0.561820</td>\n",
       "      <td>1.806786</td>\n",
       "      <td>2.055541</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>0.569852</td>\n",
       "      <td>0.613082</td>\n",
       "      <td>0.622918</td>\n",
       "      <td>0.018040</td>\n",
       "      <td>0.102845</td>\n",
       "      <td>80.678611</td>\n",
       "      <td>105.554082</td>\n",
       "      <td>0.075259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>0.504477</td>\n",
       "      <td>1.715472</td>\n",
       "      <td>1.885601</td>\n",
       "      <td>0.511654</td>\n",
       "      <td>0.532642</td>\n",
       "      <td>0.562396</td>\n",
       "      <td>0.577805</td>\n",
       "      <td>0.085736</td>\n",
       "      <td>0.188581</td>\n",
       "      <td>71.547205</td>\n",
       "      <td>88.560075</td>\n",
       "      <td>0.126214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150044</td>\n",
       "      <td>0.462883</td>\n",
       "      <td>1.579756</td>\n",
       "      <td>1.783615</td>\n",
       "      <td>0.471175</td>\n",
       "      <td>0.482494</td>\n",
       "      <td>0.531978</td>\n",
       "      <td>0.546023</td>\n",
       "      <td>0.079040</td>\n",
       "      <td>0.267621</td>\n",
       "      <td>57.975561</td>\n",
       "      <td>78.361468</td>\n",
       "      <td>0.167550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.430930</td>\n",
       "      <td>1.514527</td>\n",
       "      <td>1.716380</td>\n",
       "      <td>0.451720</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.511925</td>\n",
       "      <td>0.521138</td>\n",
       "      <td>0.075693</td>\n",
       "      <td>0.343314</td>\n",
       "      <td>51.452739</td>\n",
       "      <td>71.638017</td>\n",
       "      <td>0.204195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300033</td>\n",
       "      <td>0.377031</td>\n",
       "      <td>1.357484</td>\n",
       "      <td>1.596748</td>\n",
       "      <td>0.404881</td>\n",
       "      <td>0.402518</td>\n",
       "      <td>0.476243</td>\n",
       "      <td>0.481598</td>\n",
       "      <td>0.135763</td>\n",
       "      <td>0.479078</td>\n",
       "      <td>35.748377</td>\n",
       "      <td>59.674803</td>\n",
       "      <td>0.255143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399989</td>\n",
       "      <td>0.331449</td>\n",
       "      <td>1.214971</td>\n",
       "      <td>1.501343</td>\n",
       "      <td>0.362375</td>\n",
       "      <td>0.353714</td>\n",
       "      <td>0.447788</td>\n",
       "      <td>0.449641</td>\n",
       "      <td>0.121443</td>\n",
       "      <td>0.600521</td>\n",
       "      <td>21.497099</td>\n",
       "      <td>50.134348</td>\n",
       "      <td>0.285763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.287689</td>\n",
       "      <td>1.071110</td>\n",
       "      <td>1.415287</td>\n",
       "      <td>0.319468</td>\n",
       "      <td>0.309758</td>\n",
       "      <td>0.422121</td>\n",
       "      <td>0.421661</td>\n",
       "      <td>0.107123</td>\n",
       "      <td>0.707644</td>\n",
       "      <td>7.111048</td>\n",
       "      <td>41.528733</td>\n",
       "      <td>0.295898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600011</td>\n",
       "      <td>0.244453</td>\n",
       "      <td>0.922345</td>\n",
       "      <td>1.333123</td>\n",
       "      <td>0.275097</td>\n",
       "      <td>0.265888</td>\n",
       "      <td>0.397615</td>\n",
       "      <td>0.395696</td>\n",
       "      <td>0.092245</td>\n",
       "      <td>0.799888</td>\n",
       "      <td>-7.765486</td>\n",
       "      <td>33.312271</td>\n",
       "      <td>0.284830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699967</td>\n",
       "      <td>0.201321</td>\n",
       "      <td>0.747961</td>\n",
       "      <td>1.249561</td>\n",
       "      <td>0.223085</td>\n",
       "      <td>0.223062</td>\n",
       "      <td>0.372692</td>\n",
       "      <td>0.371044</td>\n",
       "      <td>0.074763</td>\n",
       "      <td>0.874651</td>\n",
       "      <td>-25.203930</td>\n",
       "      <td>24.956126</td>\n",
       "      <td>0.248930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799978</td>\n",
       "      <td>0.155382</td>\n",
       "      <td>0.598781</td>\n",
       "      <td>1.168202</td>\n",
       "      <td>0.178591</td>\n",
       "      <td>0.178754</td>\n",
       "      <td>0.348426</td>\n",
       "      <td>0.347005</td>\n",
       "      <td>0.059885</td>\n",
       "      <td>0.934536</td>\n",
       "      <td>-40.121949</td>\n",
       "      <td>16.820238</td>\n",
       "      <td>0.191749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899989</td>\n",
       "      <td>0.104876</td>\n",
       "      <td>0.420262</td>\n",
       "      <td>1.085088</td>\n",
       "      <td>0.125347</td>\n",
       "      <td>0.130547</td>\n",
       "      <td>0.323636</td>\n",
       "      <td>0.322951</td>\n",
       "      <td>0.042031</td>\n",
       "      <td>0.976567</td>\n",
       "      <td>-57.973790</td>\n",
       "      <td>8.508766</td>\n",
       "      <td>0.109126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013232</td>\n",
       "      <td>0.234305</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069884</td>\n",
       "      <td>0.076328</td>\n",
       "      <td>0.298258</td>\n",
       "      <td>0.298286</td>\n",
       "      <td>0.023433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-76.569458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010040         0.662447  2.241374   \n",
       "1       2                  0.020024         0.623118  2.272453   \n",
       "2       3                  0.030009         0.599815  2.011679   \n",
       "3       4                  0.040049         0.577574  1.944994   \n",
       "4       5                  0.050033         0.561820  1.806786   \n",
       "5       6                  0.100011         0.504477  1.715472   \n",
       "6       7                  0.150044         0.462883  1.579756   \n",
       "7       8                  0.200022         0.430930  1.514527   \n",
       "8       9                  0.300033         0.377031  1.357484   \n",
       "9      10                  0.399989         0.331449  1.214971   \n",
       "10     11                  0.500000         0.287689  1.071110   \n",
       "11     12                  0.600011         0.244453  0.922345   \n",
       "12     13                  0.699967         0.201321  0.747961   \n",
       "13     14                  0.799978         0.155382  0.598781   \n",
       "14     15                  0.899989         0.104876  0.420262   \n",
       "15     16                  1.000000         0.013232  0.234305   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          2.241374       0.668508  0.704088                  0.668508   \n",
       "1          2.256870       0.677778  0.641601                  0.673130   \n",
       "2          2.175291       0.600000  0.610927                  0.648799   \n",
       "3          2.117557       0.580110  0.587867                  0.631579   \n",
       "4          2.055541       0.538889  0.569852                  0.613082   \n",
       "5          1.885601       0.511654  0.532642                  0.562396   \n",
       "6          1.783615       0.471175  0.482494                  0.531978   \n",
       "7          1.716380       0.451720  0.446429                  0.511925   \n",
       "8          1.596748       0.404881  0.402518                  0.476243   \n",
       "9          1.501343       0.362375  0.353714                  0.447788   \n",
       "10         1.415287       0.319468  0.309758                  0.422121   \n",
       "11         1.333123       0.275097  0.265888                  0.397615   \n",
       "12         1.249561       0.223085  0.223062                  0.372692   \n",
       "13         1.168202       0.178591  0.178754                  0.348426   \n",
       "14         1.085088       0.125347  0.130547                  0.323636   \n",
       "15         1.000000       0.069884  0.076328                  0.298258   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.704088      0.022503                 0.022503  124.137389   \n",
       "1           0.672931      0.022689                 0.045192  127.245263   \n",
       "2           0.652301      0.020086                 0.065278  101.167938   \n",
       "3           0.636148      0.019528                 0.084806   94.499387   \n",
       "4           0.622918      0.018040                 0.102845   80.678611   \n",
       "5           0.577805      0.085736                 0.188581   71.547205   \n",
       "6           0.546023      0.079040                 0.267621   57.975561   \n",
       "7           0.521138      0.075693                 0.343314   51.452739   \n",
       "8           0.481598      0.135763                 0.479078   35.748377   \n",
       "9           0.449641      0.121443                 0.600521   21.497099   \n",
       "10          0.421661      0.107123                 0.707644    7.111048   \n",
       "11          0.395696      0.092245                 0.799888   -7.765486   \n",
       "12          0.371044      0.074763                 0.874651  -25.203930   \n",
       "13          0.347005      0.059885                 0.934536  -40.121949   \n",
       "14          0.322951      0.042031                 0.976567  -57.973790   \n",
       "15          0.298286      0.023433                 1.000000  -76.569458   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        124.137389            0.017761  \n",
       "1        125.687021            0.035865  \n",
       "2        117.529101            0.050259  \n",
       "3        111.755724            0.063780  \n",
       "4        105.554082            0.075259  \n",
       "5         88.560075            0.126214  \n",
       "6         78.361468            0.167550  \n",
       "7         71.638017            0.204195  \n",
       "8         59.674803            0.255143  \n",
       "9         50.134348            0.285763  \n",
       "10        41.528733            0.295898  \n",
       "11        33.312271            0.284830  \n",
       "12        24.956126            0.248930  \n",
       "13        16.820238            0.191749  \n",
       "14         8.508766            0.109126  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OBinomialModel.accuracy of >"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_lim.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_grid__1_AutoML_20210531_075849_model_1\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>11420.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0               48.0                      48.0              11420.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0        4.0        4.0         4.0         8.0        16.0    14.666667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.1803641307955255\n",
      "RMSE: 0.42469298416094126\n",
      "LogLoss: 0.5373316357317957\n",
      "Mean Per-Class Error: 0.3299609859264232\n",
      "AUC: 0.7341736594120815\n",
      "AUCPR: 0.5351147827302374\n",
      "Gini: 0.4683473188241629\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2886506064445672: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>7533.0</td>\n",
       "      <td>5118.0</td>\n",
       "      <td>0.4046</td>\n",
       "      <td>(5118.0/12651.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>4001.0</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>(1376.0/5377.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>8909.0</td>\n",
       "      <td>9119.0</td>\n",
       "      <td>0.3602</td>\n",
       "      <td>(6494.0/18028.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           False    True   Error               Rate\n",
       "0  False  7533.0  5118.0  0.4046   (5118.0/12651.0)\n",
       "1   True  1376.0  4001.0  0.2559    (1376.0/5377.0)\n",
       "2  Total  8909.0  9119.0  0.3602   (6494.0/18028.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.288651</td>\n",
       "      <td>0.552014</td>\n",
       "      <td>229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.166357</td>\n",
       "      <td>0.709155</td>\n",
       "      <td>322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.393825</td>\n",
       "      <td>0.517778</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.443933</td>\n",
       "      <td>0.729421</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.800273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.053457</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.800273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.315668</td>\n",
       "      <td>0.313016</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.317313</td>\n",
       "      <td>0.668327</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.295763</td>\n",
       "      <td>0.670039</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.800273</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.800273</td>\n",
       "      <td>5375.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.046615</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.053457</td>\n",
       "      <td>5377.000000</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.800273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.800273</td>\n",
       "      <td>0.999628</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.046615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.053457</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.288651      0.552014  229.0\n",
       "1                        max f2   0.166357      0.709155  322.0\n",
       "2                  max f0point5   0.393825      0.517778  153.0\n",
       "3                  max accuracy   0.443933      0.729421  118.0\n",
       "4                 max precision   0.800273      1.000000    0.0\n",
       "5                    max recall   0.053457      1.000000  397.0\n",
       "6               max specificity   0.800273      1.000000    0.0\n",
       "7              max absolute_mcc   0.315668      0.313016  208.0\n",
       "8    max min_per_class_accuracy   0.317313      0.668327  207.0\n",
       "9   max mean_per_class_accuracy   0.295763      0.670039  223.0\n",
       "10                      max tns   0.800273  12651.000000    0.0\n",
       "11                      max fns   0.800273   5375.000000    0.0\n",
       "12                      max fps   0.046615  12651.000000  399.0\n",
       "13                      max tps   0.053457   5377.000000  397.0\n",
       "14                      max tnr   0.800273      1.000000    0.0\n",
       "15                      max fnr   0.800273      0.999628    0.0\n",
       "16                      max fpr   0.046615      1.000000  399.0\n",
       "17                      max tpr   0.053457      1.000000  397.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 29.83 %, avg score: 29.87 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.638804</td>\n",
       "      <td>2.741515</td>\n",
       "      <td>2.741515</td>\n",
       "      <td>0.817680</td>\n",
       "      <td>0.680832</td>\n",
       "      <td>0.817680</td>\n",
       "      <td>0.680832</td>\n",
       "      <td>0.027525</td>\n",
       "      <td>0.027525</td>\n",
       "      <td>174.151517</td>\n",
       "      <td>174.151517</td>\n",
       "      <td>0.024916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020024</td>\n",
       "      <td>0.597155</td>\n",
       "      <td>2.440093</td>\n",
       "      <td>2.591221</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0.616030</td>\n",
       "      <td>0.772853</td>\n",
       "      <td>0.648521</td>\n",
       "      <td>0.024363</td>\n",
       "      <td>0.051888</td>\n",
       "      <td>144.009258</td>\n",
       "      <td>159.122136</td>\n",
       "      <td>0.045406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030009</td>\n",
       "      <td>0.571794</td>\n",
       "      <td>2.328333</td>\n",
       "      <td>2.503754</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.584478</td>\n",
       "      <td>0.746765</td>\n",
       "      <td>0.627213</td>\n",
       "      <td>0.023247</td>\n",
       "      <td>0.075135</td>\n",
       "      <td>132.833261</td>\n",
       "      <td>150.375375</td>\n",
       "      <td>0.064306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040049</td>\n",
       "      <td>0.555058</td>\n",
       "      <td>2.519230</td>\n",
       "      <td>2.507634</td>\n",
       "      <td>0.751381</td>\n",
       "      <td>0.563435</td>\n",
       "      <td>0.747922</td>\n",
       "      <td>0.611224</td>\n",
       "      <td>0.025293</td>\n",
       "      <td>0.100428</td>\n",
       "      <td>151.923016</td>\n",
       "      <td>150.763357</td>\n",
       "      <td>0.086042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050033</td>\n",
       "      <td>0.539386</td>\n",
       "      <td>1.974426</td>\n",
       "      <td>2.401229</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.547057</td>\n",
       "      <td>0.716186</td>\n",
       "      <td>0.598419</td>\n",
       "      <td>0.019714</td>\n",
       "      <td>0.120141</td>\n",
       "      <td>97.442605</td>\n",
       "      <td>140.122852</td>\n",
       "      <td>0.099906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>0.489032</td>\n",
       "      <td>1.827108</td>\n",
       "      <td>2.114327</td>\n",
       "      <td>0.544950</td>\n",
       "      <td>0.512296</td>\n",
       "      <td>0.630616</td>\n",
       "      <td>0.555382</td>\n",
       "      <td>0.091315</td>\n",
       "      <td>0.211456</td>\n",
       "      <td>82.710798</td>\n",
       "      <td>111.432746</td>\n",
       "      <td>0.158812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150044</td>\n",
       "      <td>0.452881</td>\n",
       "      <td>1.683834</td>\n",
       "      <td>1.970776</td>\n",
       "      <td>0.502217</td>\n",
       "      <td>0.470324</td>\n",
       "      <td>0.587800</td>\n",
       "      <td>0.527019</td>\n",
       "      <td>0.084248</td>\n",
       "      <td>0.295704</td>\n",
       "      <td>68.383362</td>\n",
       "      <td>97.077647</td>\n",
       "      <td>0.207569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.421811</td>\n",
       "      <td>1.607557</td>\n",
       "      <td>1.880022</td>\n",
       "      <td>0.479467</td>\n",
       "      <td>0.437290</td>\n",
       "      <td>0.560732</td>\n",
       "      <td>0.504599</td>\n",
       "      <td>0.080342</td>\n",
       "      <td>0.376046</td>\n",
       "      <td>60.755733</td>\n",
       "      <td>88.002204</td>\n",
       "      <td>0.250839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300033</td>\n",
       "      <td>0.372810</td>\n",
       "      <td>1.392816</td>\n",
       "      <td>1.717620</td>\n",
       "      <td>0.415419</td>\n",
       "      <td>0.396566</td>\n",
       "      <td>0.512294</td>\n",
       "      <td>0.468588</td>\n",
       "      <td>0.139297</td>\n",
       "      <td>0.515343</td>\n",
       "      <td>39.281554</td>\n",
       "      <td>71.761988</td>\n",
       "      <td>0.306822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399989</td>\n",
       "      <td>0.329827</td>\n",
       "      <td>1.170317</td>\n",
       "      <td>1.580851</td>\n",
       "      <td>0.349057</td>\n",
       "      <td>0.351070</td>\n",
       "      <td>0.471502</td>\n",
       "      <td>0.439221</td>\n",
       "      <td>0.116980</td>\n",
       "      <td>0.632323</td>\n",
       "      <td>17.031662</td>\n",
       "      <td>58.085099</td>\n",
       "      <td>0.331082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.290406</td>\n",
       "      <td>1.054374</td>\n",
       "      <td>1.475544</td>\n",
       "      <td>0.314476</td>\n",
       "      <td>0.309641</td>\n",
       "      <td>0.440093</td>\n",
       "      <td>0.413302</td>\n",
       "      <td>0.105449</td>\n",
       "      <td>0.737772</td>\n",
       "      <td>5.437438</td>\n",
       "      <td>47.554398</td>\n",
       "      <td>0.338831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600011</td>\n",
       "      <td>0.250676</td>\n",
       "      <td>0.875856</td>\n",
       "      <td>1.375587</td>\n",
       "      <td>0.261231</td>\n",
       "      <td>0.270614</td>\n",
       "      <td>0.410280</td>\n",
       "      <td>0.389518</td>\n",
       "      <td>0.087595</td>\n",
       "      <td>0.825367</td>\n",
       "      <td>-12.414403</td>\n",
       "      <td>37.558674</td>\n",
       "      <td>0.321138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699967</td>\n",
       "      <td>0.209889</td>\n",
       "      <td>0.671676</td>\n",
       "      <td>1.275068</td>\n",
       "      <td>0.200333</td>\n",
       "      <td>0.230524</td>\n",
       "      <td>0.380300</td>\n",
       "      <td>0.366814</td>\n",
       "      <td>0.067138</td>\n",
       "      <td>0.892505</td>\n",
       "      <td>-32.832385</td>\n",
       "      <td>27.506793</td>\n",
       "      <td>0.274372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799978</td>\n",
       "      <td>0.165066</td>\n",
       "      <td>0.556010</td>\n",
       "      <td>1.185173</td>\n",
       "      <td>0.165835</td>\n",
       "      <td>0.188144</td>\n",
       "      <td>0.353488</td>\n",
       "      <td>0.344477</td>\n",
       "      <td>0.055607</td>\n",
       "      <td>0.948112</td>\n",
       "      <td>-44.398952</td>\n",
       "      <td>18.517328</td>\n",
       "      <td>0.211095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899989</td>\n",
       "      <td>0.116520</td>\n",
       "      <td>0.336582</td>\n",
       "      <td>1.090874</td>\n",
       "      <td>0.100388</td>\n",
       "      <td>0.141716</td>\n",
       "      <td>0.325362</td>\n",
       "      <td>0.321945</td>\n",
       "      <td>0.033662</td>\n",
       "      <td>0.981774</td>\n",
       "      <td>-66.341841</td>\n",
       "      <td>9.087370</td>\n",
       "      <td>0.116546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046420</td>\n",
       "      <td>0.182238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054354</td>\n",
       "      <td>0.089277</td>\n",
       "      <td>0.298258</td>\n",
       "      <td>0.298676</td>\n",
       "      <td>0.018226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-81.776245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010040         0.638804  2.741515   \n",
       "1       2                  0.020024         0.597155  2.440093   \n",
       "2       3                  0.030009         0.571794  2.328333   \n",
       "3       4                  0.040049         0.555058  2.519230   \n",
       "4       5                  0.050033         0.539386  1.974426   \n",
       "5       6                  0.100011         0.489032  1.827108   \n",
       "6       7                  0.150044         0.452881  1.683834   \n",
       "7       8                  0.200022         0.421811  1.607557   \n",
       "8       9                  0.300033         0.372810  1.392816   \n",
       "9      10                  0.399989         0.329827  1.170317   \n",
       "10     11                  0.500000         0.290406  1.054374   \n",
       "11     12                  0.600011         0.250676  0.875856   \n",
       "12     13                  0.699967         0.209889  0.671676   \n",
       "13     14                  0.799978         0.165066  0.556010   \n",
       "14     15                  0.899989         0.116520  0.336582   \n",
       "15     16                  1.000000         0.046420  0.182238   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          2.741515       0.817680  0.680832                  0.817680   \n",
       "1          2.591221       0.727778  0.616030                  0.772853   \n",
       "2          2.503754       0.694444  0.584478                  0.746765   \n",
       "3          2.507634       0.751381  0.563435                  0.747922   \n",
       "4          2.401229       0.588889  0.547057                  0.716186   \n",
       "5          2.114327       0.544950  0.512296                  0.630616   \n",
       "6          1.970776       0.502217  0.470324                  0.587800   \n",
       "7          1.880022       0.479467  0.437290                  0.560732   \n",
       "8          1.717620       0.415419  0.396566                  0.512294   \n",
       "9          1.580851       0.349057  0.351070                  0.471502   \n",
       "10         1.475544       0.314476  0.309641                  0.440093   \n",
       "11         1.375587       0.261231  0.270614                  0.410280   \n",
       "12         1.275068       0.200333  0.230524                  0.380300   \n",
       "13         1.185173       0.165835  0.188144                  0.353488   \n",
       "14         1.090874       0.100388  0.141716                  0.325362   \n",
       "15         1.000000       0.054354  0.089277                  0.298258   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.680832      0.027525                 0.027525  174.151517   \n",
       "1           0.648521      0.024363                 0.051888  144.009258   \n",
       "2           0.627213      0.023247                 0.075135  132.833261   \n",
       "3           0.611224      0.025293                 0.100428  151.923016   \n",
       "4           0.598419      0.019714                 0.120141   97.442605   \n",
       "5           0.555382      0.091315                 0.211456   82.710798   \n",
       "6           0.527019      0.084248                 0.295704   68.383362   \n",
       "7           0.504599      0.080342                 0.376046   60.755733   \n",
       "8           0.468588      0.139297                 0.515343   39.281554   \n",
       "9           0.439221      0.116980                 0.632323   17.031662   \n",
       "10          0.413302      0.105449                 0.737772    5.437438   \n",
       "11          0.389518      0.087595                 0.825367  -12.414403   \n",
       "12          0.366814      0.067138                 0.892505  -32.832385   \n",
       "13          0.344477      0.055607                 0.948112  -44.398952   \n",
       "14          0.321945      0.033662                 0.981774  -66.341841   \n",
       "15          0.298676      0.018226                 1.000000  -81.776245   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        174.151517            0.024916  \n",
       "1        159.122136            0.045406  \n",
       "2        150.375375            0.064306  \n",
       "3        150.763357            0.086042  \n",
       "4        140.122852            0.099906  \n",
       "5        111.432746            0.158812  \n",
       "6         97.077647            0.207569  \n",
       "7         88.002204            0.250839  \n",
       "8         71.761988            0.306822  \n",
       "9         58.085099            0.331082  \n",
       "10        47.554398            0.338831  \n",
       "11        37.558674            0.321138  \n",
       "12        27.506793            0.274372  \n",
       "13        18.517328            0.211095  \n",
       "14         9.087370            0.116546  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.1875271743279045\n",
      "RMSE: 0.4330440789664541\n",
      "LogLoss: 0.554616829486638\n",
      "Mean Per-Class Error: 0.35248692355762146\n",
      "AUC: 0.7017187737575503\n",
      "AUCPR: 0.48057336233383735\n",
      "Gini: 0.40343754751510064\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.27701908231617783: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>7031.0</td>\n",
       "      <td>5620.0</td>\n",
       "      <td>0.4442</td>\n",
       "      <td>(5620.0/12651.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>3975.0</td>\n",
       "      <td>0.2607</td>\n",
       "      <td>(1402.0/5377.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>8433.0</td>\n",
       "      <td>9595.0</td>\n",
       "      <td>0.3895</td>\n",
       "      <td>(7022.0/18028.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           False    True   Error               Rate\n",
       "0  False  7031.0  5620.0  0.4442   (5620.0/12651.0)\n",
       "1   True  1402.0  3975.0  0.2607    (1402.0/5377.0)\n",
       "2  Total  8433.0  9595.0  0.3895   (7022.0/18028.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.277019</td>\n",
       "      <td>0.530991</td>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.138065</td>\n",
       "      <td>0.699240</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.389123</td>\n",
       "      <td>0.479859</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.511321</td>\n",
       "      <td>0.714444</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.787627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.046489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.787627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.277019</td>\n",
       "      <td>0.270508</td>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.314675</td>\n",
       "      <td>0.644411</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.277019</td>\n",
       "      <td>0.647513</td>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.787627</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.787627</td>\n",
       "      <td>5376.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.043341</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.046489</td>\n",
       "      <td>5377.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.787627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.787627</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.043341</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.046489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.277019      0.530991  237.0\n",
       "1                        max f2   0.138065      0.699240  340.0\n",
       "2                  max f0point5   0.389123      0.479859  154.0\n",
       "3                  max accuracy   0.511321      0.714444   75.0\n",
       "4                 max precision   0.787627      1.000000    0.0\n",
       "5                    max recall   0.046489      1.000000  398.0\n",
       "6               max specificity   0.787627      1.000000    0.0\n",
       "7              max absolute_mcc   0.277019      0.270508  237.0\n",
       "8    max min_per_class_accuracy   0.314675      0.644411  209.0\n",
       "9   max mean_per_class_accuracy   0.277019      0.647513  237.0\n",
       "10                      max tns   0.787627  12651.000000    0.0\n",
       "11                      max fns   0.787627   5376.000000    0.0\n",
       "12                      max fps   0.043341  12651.000000  399.0\n",
       "13                      max tps   0.046489   5377.000000  398.0\n",
       "14                      max tnr   0.787627      1.000000    0.0\n",
       "15                      max fnr   0.787627      0.999814    0.0\n",
       "16                      max fpr   0.043341      1.000000  399.0\n",
       "17                      max tpr   0.046489      1.000000  398.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 29.83 %, avg score: 29.85 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.637724</td>\n",
       "      <td>2.315469</td>\n",
       "      <td>2.315469</td>\n",
       "      <td>0.690608</td>\n",
       "      <td>0.678311</td>\n",
       "      <td>0.690608</td>\n",
       "      <td>0.678311</td>\n",
       "      <td>0.023247</td>\n",
       "      <td>0.023247</td>\n",
       "      <td>131.546889</td>\n",
       "      <td>131.546889</td>\n",
       "      <td>0.018821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020024</td>\n",
       "      <td>0.598961</td>\n",
       "      <td>2.104813</td>\n",
       "      <td>2.210433</td>\n",
       "      <td>0.627778</td>\n",
       "      <td>0.616437</td>\n",
       "      <td>0.659280</td>\n",
       "      <td>0.647460</td>\n",
       "      <td>0.021015</td>\n",
       "      <td>0.044263</td>\n",
       "      <td>110.481268</td>\n",
       "      <td>121.043255</td>\n",
       "      <td>0.034540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030009</td>\n",
       "      <td>0.575198</td>\n",
       "      <td>1.974426</td>\n",
       "      <td>2.131909</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.586022</td>\n",
       "      <td>0.635860</td>\n",
       "      <td>0.627018</td>\n",
       "      <td>0.019714</td>\n",
       "      <td>0.063976</td>\n",
       "      <td>97.442605</td>\n",
       "      <td>113.190913</td>\n",
       "      <td>0.048404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040049</td>\n",
       "      <td>0.557225</td>\n",
       "      <td>2.074660</td>\n",
       "      <td>2.117557</td>\n",
       "      <td>0.618785</td>\n",
       "      <td>0.565676</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.611640</td>\n",
       "      <td>0.020829</td>\n",
       "      <td>0.084806</td>\n",
       "      <td>107.466013</td>\n",
       "      <td>111.755724</td>\n",
       "      <td>0.063780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050033</td>\n",
       "      <td>0.543760</td>\n",
       "      <td>1.769533</td>\n",
       "      <td>2.048107</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.550202</td>\n",
       "      <td>0.610865</td>\n",
       "      <td>0.599380</td>\n",
       "      <td>0.017668</td>\n",
       "      <td>0.102473</td>\n",
       "      <td>76.953278</td>\n",
       "      <td>104.810668</td>\n",
       "      <td>0.074729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>0.490911</td>\n",
       "      <td>1.708030</td>\n",
       "      <td>1.878162</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.515483</td>\n",
       "      <td>0.560177</td>\n",
       "      <td>0.557455</td>\n",
       "      <td>0.085364</td>\n",
       "      <td>0.187837</td>\n",
       "      <td>70.802966</td>\n",
       "      <td>87.816248</td>\n",
       "      <td>0.125154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150044</td>\n",
       "      <td>0.454293</td>\n",
       "      <td>1.616926</td>\n",
       "      <td>1.791052</td>\n",
       "      <td>0.482262</td>\n",
       "      <td>0.472142</td>\n",
       "      <td>0.534196</td>\n",
       "      <td>0.529006</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.268737</td>\n",
       "      <td>61.692633</td>\n",
       "      <td>79.105157</td>\n",
       "      <td>0.169140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.423180</td>\n",
       "      <td>1.551739</td>\n",
       "      <td>1.731257</td>\n",
       "      <td>0.462819</td>\n",
       "      <td>0.438298</td>\n",
       "      <td>0.516362</td>\n",
       "      <td>0.506342</td>\n",
       "      <td>0.077553</td>\n",
       "      <td>0.346290</td>\n",
       "      <td>55.173936</td>\n",
       "      <td>73.125670</td>\n",
       "      <td>0.208435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300033</td>\n",
       "      <td>0.373220</td>\n",
       "      <td>1.310995</td>\n",
       "      <td>1.591169</td>\n",
       "      <td>0.391015</td>\n",
       "      <td>0.396974</td>\n",
       "      <td>0.474579</td>\n",
       "      <td>0.469886</td>\n",
       "      <td>0.131114</td>\n",
       "      <td>0.477404</td>\n",
       "      <td>31.099460</td>\n",
       "      <td>59.116933</td>\n",
       "      <td>0.252757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399989</td>\n",
       "      <td>0.329860</td>\n",
       "      <td>1.242880</td>\n",
       "      <td>1.504133</td>\n",
       "      <td>0.370699</td>\n",
       "      <td>0.351962</td>\n",
       "      <td>0.448620</td>\n",
       "      <td>0.440417</td>\n",
       "      <td>0.124233</td>\n",
       "      <td>0.601637</td>\n",
       "      <td>24.287997</td>\n",
       "      <td>50.413322</td>\n",
       "      <td>0.287353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.289468</td>\n",
       "      <td>1.035779</td>\n",
       "      <td>1.410452</td>\n",
       "      <td>0.308930</td>\n",
       "      <td>0.309727</td>\n",
       "      <td>0.420679</td>\n",
       "      <td>0.414276</td>\n",
       "      <td>0.103589</td>\n",
       "      <td>0.705226</td>\n",
       "      <td>3.577871</td>\n",
       "      <td>41.045192</td>\n",
       "      <td>0.292452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600011</td>\n",
       "      <td>0.249025</td>\n",
       "      <td>0.933503</td>\n",
       "      <td>1.330953</td>\n",
       "      <td>0.278425</td>\n",
       "      <td>0.269052</td>\n",
       "      <td>0.396968</td>\n",
       "      <td>0.390070</td>\n",
       "      <td>0.093361</td>\n",
       "      <td>0.798587</td>\n",
       "      <td>-6.649746</td>\n",
       "      <td>33.095301</td>\n",
       "      <td>0.282975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699967</td>\n",
       "      <td>0.208531</td>\n",
       "      <td>0.746100</td>\n",
       "      <td>1.247436</td>\n",
       "      <td>0.222531</td>\n",
       "      <td>0.228701</td>\n",
       "      <td>0.372058</td>\n",
       "      <td>0.367026</td>\n",
       "      <td>0.074577</td>\n",
       "      <td>0.873163</td>\n",
       "      <td>-25.389990</td>\n",
       "      <td>24.743570</td>\n",
       "      <td>0.246810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799978</td>\n",
       "      <td>0.164399</td>\n",
       "      <td>0.595061</td>\n",
       "      <td>1.165878</td>\n",
       "      <td>0.177482</td>\n",
       "      <td>0.187068</td>\n",
       "      <td>0.347733</td>\n",
       "      <td>0.344529</td>\n",
       "      <td>0.059513</td>\n",
       "      <td>0.932676</td>\n",
       "      <td>-40.493862</td>\n",
       "      <td>16.587760</td>\n",
       "      <td>0.189099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899989</td>\n",
       "      <td>0.116534</td>\n",
       "      <td>0.431419</td>\n",
       "      <td>1.084261</td>\n",
       "      <td>0.128674</td>\n",
       "      <td>0.140861</td>\n",
       "      <td>0.323390</td>\n",
       "      <td>0.321896</td>\n",
       "      <td>0.043147</td>\n",
       "      <td>0.975823</td>\n",
       "      <td>-56.858050</td>\n",
       "      <td>8.426109</td>\n",
       "      <td>0.108065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042306</td>\n",
       "      <td>0.241744</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.088285</td>\n",
       "      <td>0.298258</td>\n",
       "      <td>0.298532</td>\n",
       "      <td>0.024177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-75.825631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010040         0.637724  2.315469   \n",
       "1       2                  0.020024         0.598961  2.104813   \n",
       "2       3                  0.030009         0.575198  1.974426   \n",
       "3       4                  0.040049         0.557225  2.074660   \n",
       "4       5                  0.050033         0.543760  1.769533   \n",
       "5       6                  0.100011         0.490911  1.708030   \n",
       "6       7                  0.150044         0.454293  1.616926   \n",
       "7       8                  0.200022         0.423180  1.551739   \n",
       "8       9                  0.300033         0.373220  1.310995   \n",
       "9      10                  0.399989         0.329860  1.242880   \n",
       "10     11                  0.500000         0.289468  1.035779   \n",
       "11     12                  0.600011         0.249025  0.933503   \n",
       "12     13                  0.699967         0.208531  0.746100   \n",
       "13     14                  0.799978         0.164399  0.595061   \n",
       "14     15                  0.899989         0.116534  0.431419   \n",
       "15     16                  1.000000         0.042306  0.241744   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          2.315469       0.690608  0.678311                  0.690608   \n",
       "1          2.210433       0.627778  0.616437                  0.659280   \n",
       "2          2.131909       0.588889  0.586022                  0.635860   \n",
       "3          2.117557       0.618785  0.565676                  0.631579   \n",
       "4          2.048107       0.527778  0.550202                  0.610865   \n",
       "5          1.878162       0.509434  0.515483                  0.560177   \n",
       "6          1.791052       0.482262  0.472142                  0.534196   \n",
       "7          1.731257       0.462819  0.438298                  0.516362   \n",
       "8          1.591169       0.391015  0.396974                  0.474579   \n",
       "9          1.504133       0.370699  0.351962                  0.448620   \n",
       "10         1.410452       0.308930  0.309727                  0.420679   \n",
       "11         1.330953       0.278425  0.269052                  0.396968   \n",
       "12         1.247436       0.222531  0.228701                  0.372058   \n",
       "13         1.165878       0.177482  0.187068                  0.347733   \n",
       "14         1.084261       0.128674  0.140861                  0.323390   \n",
       "15         1.000000       0.072102  0.088285                  0.298258   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.678311      0.023247                 0.023247  131.546889   \n",
       "1           0.647460      0.021015                 0.044263  110.481268   \n",
       "2           0.627018      0.019714                 0.063976   97.442605   \n",
       "3           0.611640      0.020829                 0.084806  107.466013   \n",
       "4           0.599380      0.017668                 0.102473   76.953278   \n",
       "5           0.557455      0.085364                 0.187837   70.802966   \n",
       "6           0.529006      0.080900                 0.268737   61.692633   \n",
       "7           0.506342      0.077553                 0.346290   55.173936   \n",
       "8           0.469886      0.131114                 0.477404   31.099460   \n",
       "9           0.440417      0.124233                 0.601637   24.287997   \n",
       "10          0.414276      0.103589                 0.705226    3.577871   \n",
       "11          0.390070      0.093361                 0.798587   -6.649746   \n",
       "12          0.367026      0.074577                 0.873163  -25.389990   \n",
       "13          0.344529      0.059513                 0.932676  -40.493862   \n",
       "14          0.321896      0.043147                 0.975823  -56.858050   \n",
       "15          0.298532      0.024177                 1.000000  -75.825631   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        131.546889            0.018821  \n",
       "1        121.043255            0.034540  \n",
       "2        113.190913            0.048404  \n",
       "3        111.755724            0.063780  \n",
       "4        104.810668            0.074729  \n",
       "5         87.816248            0.125154  \n",
       "6         79.105157            0.169140  \n",
       "7         73.125670            0.208435  \n",
       "8         59.116933            0.252757  \n",
       "9         50.413322            0.287353  \n",
       "10        41.045192            0.292452  \n",
       "11        33.095301            0.282975  \n",
       "12        24.743570            0.246810  \n",
       "13        16.587760            0.189099  \n",
       "14         8.426109            0.108065  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>cv_1_valid</th>\n",
       "      <th>cv_2_valid</th>\n",
       "      <th>cv_3_valid</th>\n",
       "      <th>cv_4_valid</th>\n",
       "      <th>cv_5_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.59268755</td>\n",
       "      <td>0.017917497</td>\n",
       "      <td>0.6134221</td>\n",
       "      <td>0.6103716</td>\n",
       "      <td>0.583472</td>\n",
       "      <td>0.5819695</td>\n",
       "      <td>0.5742025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.70180947</td>\n",
       "      <td>0.008323527</td>\n",
       "      <td>0.71037215</td>\n",
       "      <td>0.7020771</td>\n",
       "      <td>0.7094561</td>\n",
       "      <td>0.69138956</td>\n",
       "      <td>0.69575244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>err</td>\n",
       "      <td>0.40731248</td>\n",
       "      <td>0.017917497</td>\n",
       "      <td>0.38657793</td>\n",
       "      <td>0.3896284</td>\n",
       "      <td>0.41652802</td>\n",
       "      <td>0.4180305</td>\n",
       "      <td>0.4257975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>err_count</td>\n",
       "      <td>1468.6</td>\n",
       "      <td>64.43834</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>1535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f0point5</td>\n",
       "      <td>0.44821566</td>\n",
       "      <td>0.011457166</td>\n",
       "      <td>0.45645508</td>\n",
       "      <td>0.46047452</td>\n",
       "      <td>0.45113546</td>\n",
       "      <td>0.43998313</td>\n",
       "      <td>0.4330302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.5327777</td>\n",
       "      <td>0.0086325</td>\n",
       "      <td>0.5356429</td>\n",
       "      <td>0.5382846</td>\n",
       "      <td>0.5423522</td>\n",
       "      <td>0.5256531</td>\n",
       "      <td>0.5219558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f2</td>\n",
       "      <td>0.6570421</td>\n",
       "      <td>0.013262475</td>\n",
       "      <td>0.6480735</td>\n",
       "      <td>0.64773804</td>\n",
       "      <td>0.67980444</td>\n",
       "      <td>0.65275174</td>\n",
       "      <td>0.65684277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lift_top_group</td>\n",
       "      <td>2.3398</td>\n",
       "      <td>0.19016156</td>\n",
       "      <td>2.3748322</td>\n",
       "      <td>2.0508394</td>\n",
       "      <td>2.3289945</td>\n",
       "      <td>2.3608978</td>\n",
       "      <td>2.5834358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logloss</td>\n",
       "      <td>0.554617</td>\n",
       "      <td>0.0043693692</td>\n",
       "      <td>0.5486169</td>\n",
       "      <td>0.5586578</td>\n",
       "      <td>0.5534904</td>\n",
       "      <td>0.55916035</td>\n",
       "      <td>0.55315953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_per_class_error</td>\n",
       "      <td>0.48624802</td>\n",
       "      <td>0.03578697</td>\n",
       "      <td>0.44545096</td>\n",
       "      <td>0.45005968</td>\n",
       "      <td>0.5178713</td>\n",
       "      <td>0.5011848</td>\n",
       "      <td>0.5166732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mcc</td>\n",
       "      <td>0.27082872</td>\n",
       "      <td>0.012907638</td>\n",
       "      <td>0.28198448</td>\n",
       "      <td>0.2759936</td>\n",
       "      <td>0.28225094</td>\n",
       "      <td>0.25692683</td>\n",
       "      <td>0.25698775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mean_per_class_accuracy</td>\n",
       "      <td>0.64613557</td>\n",
       "      <td>0.0072014914</td>\n",
       "      <td>0.65403175</td>\n",
       "      <td>0.6496271</td>\n",
       "      <td>0.6500717</td>\n",
       "      <td>0.63850355</td>\n",
       "      <td>0.6384437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mean_per_class_error</td>\n",
       "      <td>0.35386443</td>\n",
       "      <td>0.0072014914</td>\n",
       "      <td>0.34596822</td>\n",
       "      <td>0.35037294</td>\n",
       "      <td>0.34992832</td>\n",
       "      <td>0.36149642</td>\n",
       "      <td>0.3615563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.18752722</td>\n",
       "      <td>0.0018154195</td>\n",
       "      <td>0.18496458</td>\n",
       "      <td>0.18935947</td>\n",
       "      <td>0.18723407</td>\n",
       "      <td>0.18918987</td>\n",
       "      <td>0.18688814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pr_auc</td>\n",
       "      <td>0.48104534</td>\n",
       "      <td>0.009485966</td>\n",
       "      <td>0.48875266</td>\n",
       "      <td>0.47948438</td>\n",
       "      <td>0.4925803</td>\n",
       "      <td>0.47429317</td>\n",
       "      <td>0.47011614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.40537637</td>\n",
       "      <td>0.0128613375</td>\n",
       "      <td>0.4155039</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.40565178</td>\n",
       "      <td>0.39686313</td>\n",
       "      <td>0.38886312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.10395077</td>\n",
       "      <td>0.007772591</td>\n",
       "      <td>0.112204544</td>\n",
       "      <td>0.10355048</td>\n",
       "      <td>0.11130711</td>\n",
       "      <td>0.09500747</td>\n",
       "      <td>0.09768424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.77851915</td>\n",
       "      <td>0.028567614</td>\n",
       "      <td>0.7535145</td>\n",
       "      <td>0.74931383</td>\n",
       "      <td>0.8180147</td>\n",
       "      <td>0.778192</td>\n",
       "      <td>0.7935606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rmse</td>\n",
       "      <td>0.43304008</td>\n",
       "      <td>0.0020975024</td>\n",
       "      <td>0.4300751</td>\n",
       "      <td>0.43515456</td>\n",
       "      <td>0.43270552</td>\n",
       "      <td>0.43495962</td>\n",
       "      <td>0.4323056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>specificity</td>\n",
       "      <td>0.513752</td>\n",
       "      <td>0.03578697</td>\n",
       "      <td>0.55454904</td>\n",
       "      <td>0.5499403</td>\n",
       "      <td>0.48212868</td>\n",
       "      <td>0.49881518</td>\n",
       "      <td>0.4833268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean            sd   cv_1_valid  \\\n",
       "0                  accuracy  0.59268755   0.017917497    0.6134221   \n",
       "1                       auc  0.70180947   0.008323527   0.71037215   \n",
       "2                       err  0.40731248   0.017917497   0.38657793   \n",
       "3                 err_count      1468.6      64.43834       1394.0   \n",
       "4                  f0point5  0.44821566   0.011457166   0.45645508   \n",
       "5                        f1   0.5327777     0.0086325    0.5356429   \n",
       "6                        f2   0.6570421   0.013262475    0.6480735   \n",
       "7            lift_top_group      2.3398    0.19016156    2.3748322   \n",
       "8                   logloss    0.554617  0.0043693692    0.5486169   \n",
       "9       max_per_class_error  0.48624802    0.03578697   0.44545096   \n",
       "10                      mcc  0.27082872   0.012907638   0.28198448   \n",
       "11  mean_per_class_accuracy  0.64613557  0.0072014914   0.65403175   \n",
       "12     mean_per_class_error  0.35386443  0.0072014914   0.34596822   \n",
       "13                      mse  0.18752722  0.0018154195   0.18496458   \n",
       "14                   pr_auc  0.48104534   0.009485966   0.48875266   \n",
       "15                precision  0.40537637  0.0128613375    0.4155039   \n",
       "16                       r2  0.10395077   0.007772591  0.112204544   \n",
       "17                   recall  0.77851915   0.028567614    0.7535145   \n",
       "18                     rmse  0.43304008  0.0020975024    0.4300751   \n",
       "19              specificity    0.513752    0.03578697   0.55454904   \n",
       "\n",
       "    cv_2_valid  cv_3_valid  cv_4_valid  cv_5_valid  \n",
       "0    0.6103716    0.583472   0.5819695   0.5742025  \n",
       "1    0.7020771   0.7094561  0.69138956  0.69575244  \n",
       "2    0.3896284  0.41652802   0.4180305   0.4257975  \n",
       "3       1405.0      1502.0      1507.0      1535.0  \n",
       "4   0.46047452  0.45113546  0.43998313   0.4330302  \n",
       "5    0.5382846   0.5423522   0.5256531   0.5219558  \n",
       "6   0.64773804  0.67980444  0.65275174  0.65684277  \n",
       "7    2.0508394   2.3289945   2.3608978   2.5834358  \n",
       "8    0.5586578   0.5534904  0.55916035  0.55315953  \n",
       "9   0.45005968   0.5178713   0.5011848   0.5166732  \n",
       "10   0.2759936  0.28225094  0.25692683  0.25698775  \n",
       "11   0.6496271   0.6500717  0.63850355   0.6384437  \n",
       "12  0.35037294  0.34992832  0.36149642   0.3615563  \n",
       "13  0.18935947  0.18723407  0.18918987  0.18688814  \n",
       "14  0.47948438   0.4925803  0.47429317  0.47011614  \n",
       "15        0.42  0.40565178  0.39686313  0.38886312  \n",
       "16  0.10355048  0.11130711  0.09500747  0.09768424  \n",
       "17  0.74931383   0.8180147    0.778192   0.7935606  \n",
       "18  0.43515456  0.43270552  0.43495962   0.4323056  \n",
       "19   0.5499403  0.48212868  0.49881518   0.4833268  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:59:56</td>\n",
       "      <td>2.826 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.457493</td>\n",
       "      <td>0.609381</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.298258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.701742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:59:56</td>\n",
       "      <td>2.882 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.444949</td>\n",
       "      <td>0.582368</td>\n",
       "      <td>0.694378</td>\n",
       "      <td>0.480581</td>\n",
       "      <td>2.434605</td>\n",
       "      <td>0.422066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:59:56</td>\n",
       "      <td>2.944 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.438556</td>\n",
       "      <td>0.568414</td>\n",
       "      <td>0.702225</td>\n",
       "      <td>0.490035</td>\n",
       "      <td>2.519230</td>\n",
       "      <td>0.378800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:59:56</td>\n",
       "      <td>3.011 sec</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.434758</td>\n",
       "      <td>0.559903</td>\n",
       "      <td>0.709754</td>\n",
       "      <td>0.498595</td>\n",
       "      <td>2.450122</td>\n",
       "      <td>0.401653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:59:56</td>\n",
       "      <td>3.076 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.432147</td>\n",
       "      <td>0.553974</td>\n",
       "      <td>0.715806</td>\n",
       "      <td>0.506856</td>\n",
       "      <td>2.611849</td>\n",
       "      <td>0.400599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:59:56</td>\n",
       "      <td>3.138 sec</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.430319</td>\n",
       "      <td>0.549846</td>\n",
       "      <td>0.719728</td>\n",
       "      <td>0.511409</td>\n",
       "      <td>2.593325</td>\n",
       "      <td>0.369037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:59:56</td>\n",
       "      <td>3.203 sec</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.428716</td>\n",
       "      <td>0.546224</td>\n",
       "      <td>0.724054</td>\n",
       "      <td>0.517206</td>\n",
       "      <td>2.630373</td>\n",
       "      <td>0.398491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:59:56</td>\n",
       "      <td>3.266 sec</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.427440</td>\n",
       "      <td>0.543379</td>\n",
       "      <td>0.727108</td>\n",
       "      <td>0.522217</td>\n",
       "      <td>2.648896</td>\n",
       "      <td>0.377247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:59:56</td>\n",
       "      <td>3.342 sec</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.426214</td>\n",
       "      <td>0.540695</td>\n",
       "      <td>0.730384</td>\n",
       "      <td>0.527675</td>\n",
       "      <td>2.667420</td>\n",
       "      <td>0.370091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:59:56</td>\n",
       "      <td>3.407 sec</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.425202</td>\n",
       "      <td>0.538438</td>\n",
       "      <td>0.732828</td>\n",
       "      <td>0.532826</td>\n",
       "      <td>2.722991</td>\n",
       "      <td>0.382627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-31 07:59:56</td>\n",
       "      <td>3.453 sec</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.424693</td>\n",
       "      <td>0.537332</td>\n",
       "      <td>0.734174</td>\n",
       "      <td>0.535115</td>\n",
       "      <td>2.741515</td>\n",
       "      <td>0.360217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0     2021-05-31 07:59:56   2.826 sec              0.0       0.457493   \n",
       "1     2021-05-31 07:59:56   2.882 sec              5.0       0.444949   \n",
       "2     2021-05-31 07:59:56   2.944 sec             10.0       0.438556   \n",
       "3     2021-05-31 07:59:56   3.011 sec             15.0       0.434758   \n",
       "4     2021-05-31 07:59:56   3.076 sec             20.0       0.432147   \n",
       "5     2021-05-31 07:59:56   3.138 sec             25.0       0.430319   \n",
       "6     2021-05-31 07:59:56   3.203 sec             30.0       0.428716   \n",
       "7     2021-05-31 07:59:56   3.266 sec             35.0       0.427440   \n",
       "8     2021-05-31 07:59:56   3.342 sec             40.0       0.426214   \n",
       "9     2021-05-31 07:59:56   3.407 sec             45.0       0.425202   \n",
       "10    2021-05-31 07:59:56   3.453 sec             48.0       0.424693   \n",
       "\n",
       "    training_logloss  training_auc  training_pr_auc  training_lift  \\\n",
       "0           0.609381      0.500000         0.298258       1.000000   \n",
       "1           0.582368      0.694378         0.480581       2.434605   \n",
       "2           0.568414      0.702225         0.490035       2.519230   \n",
       "3           0.559903      0.709754         0.498595       2.450122   \n",
       "4           0.553974      0.715806         0.506856       2.611849   \n",
       "5           0.549846      0.719728         0.511409       2.593325   \n",
       "6           0.546224      0.724054         0.517206       2.630373   \n",
       "7           0.543379      0.727108         0.522217       2.648896   \n",
       "8           0.540695      0.730384         0.527675       2.667420   \n",
       "9           0.538438      0.732828         0.532826       2.722991   \n",
       "10          0.537332      0.734174         0.535115       2.741515   \n",
       "\n",
       "    training_classification_error  \n",
       "0                        0.701742  \n",
       "1                        0.422066  \n",
       "2                        0.378800  \n",
       "3                        0.401653  \n",
       "4                        0.400599  \n",
       "5                        0.369037  \n",
       "6                        0.398491  \n",
       "7                        0.377247  \n",
       "8                        0.370091  \n",
       "9                        0.382627  \n",
       "10                       0.360217  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age_at_Release</td>\n",
       "      <td>491.864349</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.187303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gang_Affiliated</td>\n",
       "      <td>454.186768</td>\n",
       "      <td>0.923398</td>\n",
       "      <td>0.172955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prior_Arrest_Episodes_PPViolationCharges</td>\n",
       "      <td>323.397522</td>\n",
       "      <td>0.657493</td>\n",
       "      <td>0.123150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prior_Arrest_Episodes_Felony</td>\n",
       "      <td>285.654205</td>\n",
       "      <td>0.580758</td>\n",
       "      <td>0.108778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prior_Arrest_Episodes_Property</td>\n",
       "      <td>238.625717</td>\n",
       "      <td>0.485145</td>\n",
       "      <td>0.090869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prior_Arrest_Episodes_Misd</td>\n",
       "      <td>103.601967</td>\n",
       "      <td>0.210631</td>\n",
       "      <td>0.039452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Supervision_Risk_Score_First</td>\n",
       "      <td>101.474442</td>\n",
       "      <td>0.206306</td>\n",
       "      <td>0.038642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Prison_Years</td>\n",
       "      <td>100.134232</td>\n",
       "      <td>0.203581</td>\n",
       "      <td>0.038131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Prison_Offense</td>\n",
       "      <td>86.394936</td>\n",
       "      <td>0.175648</td>\n",
       "      <td>0.032899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prior_Conviction_Episodes_Misd</td>\n",
       "      <td>53.733433</td>\n",
       "      <td>0.109244</td>\n",
       "      <td>0.020462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Condition_MH_SA</td>\n",
       "      <td>49.494095</td>\n",
       "      <td>0.100625</td>\n",
       "      <td>0.018847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Residence_PUMA</td>\n",
       "      <td>40.342537</td>\n",
       "      <td>0.082020</td>\n",
       "      <td>0.015362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Prior_Conviction_Episodes_Prop</td>\n",
       "      <td>36.630653</td>\n",
       "      <td>0.074473</td>\n",
       "      <td>0.013949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Supervision_Level_First</td>\n",
       "      <td>34.735821</td>\n",
       "      <td>0.070621</td>\n",
       "      <td>0.013227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gender</td>\n",
       "      <td>34.413174</td>\n",
       "      <td>0.069965</td>\n",
       "      <td>0.013105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Education_Level</td>\n",
       "      <td>30.797804</td>\n",
       "      <td>0.062614</td>\n",
       "      <td>0.011728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Prior_Revocations_Parole</td>\n",
       "      <td>29.704296</td>\n",
       "      <td>0.060391</td>\n",
       "      <td>0.011311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Prior_Arrest_Episodes_Violent</td>\n",
       "      <td>22.173504</td>\n",
       "      <td>0.045081</td>\n",
       "      <td>0.008444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Prior_Arrest_Episodes_DVCharges</td>\n",
       "      <td>19.458364</td>\n",
       "      <td>0.039560</td>\n",
       "      <td>0.007410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dependents</td>\n",
       "      <td>18.627096</td>\n",
       "      <td>0.037870</td>\n",
       "      <td>0.007093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    variable  relative_importance  \\\n",
       "0                             Age_at_Release           491.864349   \n",
       "1                            Gang_Affiliated           454.186768   \n",
       "2   Prior_Arrest_Episodes_PPViolationCharges           323.397522   \n",
       "3               Prior_Arrest_Episodes_Felony           285.654205   \n",
       "4             Prior_Arrest_Episodes_Property           238.625717   \n",
       "5                 Prior_Arrest_Episodes_Misd           103.601967   \n",
       "6               Supervision_Risk_Score_First           101.474442   \n",
       "7                               Prison_Years           100.134232   \n",
       "8                             Prison_Offense            86.394936   \n",
       "9             Prior_Conviction_Episodes_Misd            53.733433   \n",
       "10                           Condition_MH_SA            49.494095   \n",
       "11                            Residence_PUMA            40.342537   \n",
       "12            Prior_Conviction_Episodes_Prop            36.630653   \n",
       "13                   Supervision_Level_First            34.735821   \n",
       "14                                    Gender            34.413174   \n",
       "15                           Education_Level            30.797804   \n",
       "16                  Prior_Revocations_Parole            29.704296   \n",
       "17             Prior_Arrest_Episodes_Violent            22.173504   \n",
       "18           Prior_Arrest_Episodes_DVCharges            19.458364   \n",
       "19                                Dependents            18.627096   \n",
       "\n",
       "    scaled_importance  percentage  \n",
       "0            1.000000    0.187303  \n",
       "1            0.923398    0.172955  \n",
       "2            0.657493    0.123150  \n",
       "3            0.580758    0.108778  \n",
       "4            0.485145    0.090869  \n",
       "5            0.210631    0.039452  \n",
       "6            0.206306    0.038642  \n",
       "7            0.203581    0.038131  \n",
       "8            0.175648    0.032899  \n",
       "9            0.109244    0.020462  \n",
       "10           0.100625    0.018847  \n",
       "11           0.082020    0.015362  \n",
       "12           0.074473    0.013949  \n",
       "13           0.070621    0.013227  \n",
       "14           0.069965    0.013105  \n",
       "15           0.062614    0.011728  \n",
       "16           0.060391    0.011311  \n",
       "17           0.045081    0.008444  \n",
       "18           0.039560    0.007410  \n",
       "19           0.037870    0.007093  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbm_lim = h2o.get_model([mid for mid in model_ids_lim if \"GBM\" in mid][0])\n",
    "print(gbm_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset column 'Gang_Affiliated' has levels not trained on: [\"false\", \"true\"]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset column 'Prior_Arrest_Episodes_DVCharges' has levels not trained on: [\"false\", \"true\"]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset column 'Prior_Arrest_Episodes_GunCharges' has levels not trained on: [\"false\", \"true\"]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset column 'Prior_Conviction_Episodes_Viol' has levels not trained on: [\"false\", \"true\"]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset column 'Prior_Conviction_Episodes_PPViolationCharges' has levels not trained on: [\"false\", \"true\"]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset column 'Prior_Conviction_Episodes_DomesticViolenceCharges' has levels not trained on: [\"false\", \"true\"]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset column 'Prior_Conviction_Episodes_GunCharges' has levels not trained on: [\"false\", \"true\"]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset column 'Prior_Revocations_Parole' has levels not trained on: [\"false\", \"true\"]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset column 'Prior_Revocations_Probation' has levels not trained on: [\"false\", \"true\"]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset column 'Condition_MH_SA' has levels not trained on: [\"false\", \"true\"]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset column 'Condition_Cog_Ed' has levels not trained on: [\"false\", \"true\"]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset column 'Condition_Other' has levels not trained on: [\"false\", \"true\"]\n",
      "  warnings.warn(w)\n"
     ]
    }
   ],
   "source": [
    "preds = aml_lim.predict(NIJ_Test_Mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7807"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">   False</th><th style=\"text-align: right;\">    True</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.842976</td><td style=\"text-align: right;\">0.157024</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.811605</td><td style=\"text-align: right;\">0.188395</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.766002</td><td style=\"text-align: right;\">0.233998</td></tr>\n",
       "<tr><td>True     </td><td style=\"text-align: right;\">0.744743</td><td style=\"text-align: right;\">0.255257</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.82932 </td><td style=\"text-align: right;\">0.17068 </td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.857525</td><td style=\"text-align: right;\">0.142475</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.811341</td><td style=\"text-align: right;\">0.188659</td></tr>\n",
       "<tr><td>True     </td><td style=\"text-align: right;\">0.701133</td><td style=\"text-align: right;\">0.298867</td></tr>\n",
       "<tr><td>True     </td><td style=\"text-align: right;\">0.520783</td><td style=\"text-align: right;\">0.479217</td></tr>\n",
       "<tr><td>True     </td><td style=\"text-align: right;\">0.716103</td><td style=\"text-align: right;\">0.283897</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_value = pd.DataFrame(preds)\n",
    "predicted_value.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
