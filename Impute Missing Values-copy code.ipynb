{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NIJ_Training_df= pd.read_csv(\"NIJ_s_Recidivism_Challenge_Training_Dataset-sara.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Gender', 'Race', 'Age_at_Release', 'Residence_PUMA',\n",
       "       'Gang_Affiliated', 'Supervision_Risk_Score_First',\n",
       "       'Supervision_Level_First', 'Education_Level', 'Dependents',\n",
       "       'Prison_Offense', 'Prison_Years', 'Prior_Arrest_Episodes_Felony',\n",
       "       'Prior_Arrest_Episodes_Misd', 'Prior_Arrest_Episodes_Violent',\n",
       "       'Prior_Arrest_Episodes_Property', 'Prior_Arrest_Episodes_Drug',\n",
       "       'Prior_Arrest_Episodes_PPViolationCharges',\n",
       "       'Prior_Arrest_Episodes_DVCharges', 'Prior_Arrest_Episodes_GunCharges',\n",
       "       'Prior_Conviction_Episodes_Felony', 'Prior_Conviction_Episodes_Misd',\n",
       "       'Prior_Conviction_Episodes_Viol', 'Prior_Conviction_Episodes_Prop',\n",
       "       'Prior_Conviction_Episodes_Drug',\n",
       "       'Prior_Conviction_Episodes_PPViolationCharges',\n",
       "       'Prior_Conviction_Episodes_DomesticViolenceCharges',\n",
       "       'Prior_Conviction_Episodes_GunCharges', 'Prior_Revocations_Parole',\n",
       "       'Prior_Revocations_Probation', 'Condition_MH_SA', 'Condition_Cog_Ed',\n",
       "       'Condition_Other', 'Violations_ElectronicMonitoring',\n",
       "       'Violations_Instruction', 'Violations_FailToReport',\n",
       "       'Violations_MoveWithoutPermission', 'Delinquency_Reports',\n",
       "       'Program_Attendances', 'Program_UnexcusedAbsences', 'Residence_Changes',\n",
       "       'Avg_Days_per_DrugTest', 'DrugTests_THC_Positive',\n",
       "       'DrugTests_Cocaine_Positive', 'DrugTests_Meth_Positive',\n",
       "       'DrugTests_Other_Positive', 'Percent_Days_Employed', 'Jobs_Per_Year',\n",
       "       'Employment_Exempt', 'Recidivism_Within_3years',\n",
       "       'Recidivism_Arrest_Year1', 'Recidivism_Arrest_Year2',\n",
       "       'Recidivism_Arrest_Year3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NIJ_Training_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Gender', 'Race', 'Age_at_Release', 'Residence_PUMA',\n",
       "       'Gang_Affiliated', 'Supervision_Risk_Score_First',\n",
       "       'Supervision_Level_First', 'Education_Level', 'Dependents',\n",
       "       'Prison_Offense', 'Prison_Years', 'Prior_Arrest_Episodes_Felony',\n",
       "       'Prior_Arrest_Episodes_Misd', 'Prior_Arrest_Episodes_Violent',\n",
       "       'Prior_Arrest_Episodes_Property', 'Prior_Arrest_Episodes_Drug',\n",
       "       'Prior_Arrest_Episodes_PPViolationCharges',\n",
       "       'Prior_Arrest_Episodes_DVCharges', 'Prior_Arrest_Episodes_GunCharges',\n",
       "       'Prior_Conviction_Episodes_Felony', 'Prior_Conviction_Episodes_Misd',\n",
       "       'Prior_Conviction_Episodes_Viol', 'Prior_Conviction_Episodes_Prop',\n",
       "       'Prior_Conviction_Episodes_Drug',\n",
       "       'Prior_Conviction_Episodes_PPViolationCharges',\n",
       "       'Prior_Conviction_Episodes_DomesticViolenceCharges',\n",
       "       'Prior_Conviction_Episodes_GunCharges', 'Prior_Revocations_Parole',\n",
       "       'Prior_Revocations_Probation', 'Condition_MH_SA', 'Condition_Cog_Ed',\n",
       "       'Condition_Other', 'Violations_ElectronicMonitoring',\n",
       "       'Violations_Instruction', 'Violations_FailToReport',\n",
       "       'Violations_MoveWithoutPermission', 'Delinquency_Reports',\n",
       "       'Program_Attendances', 'Program_UnexcusedAbsences', 'Residence_Changes',\n",
       "       'Avg_Days_per_DrugTest', 'DrugTests_THC_Positive',\n",
       "       'DrugTests_Cocaine_Positive', 'DrugTests_Meth_Positive',\n",
       "       'DrugTests_Other_Positive', 'Percent_Days_Employed', 'Jobs_Per_Year',\n",
       "       'Employment_Exempt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train =NIJ_Training_df[NIJ_Training_df.columns[0:-4]]\n",
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                                      0\n",
       "Gender                                                  0\n",
       "Race                                                    0\n",
       "Age_at_Release                                          0\n",
       "Residence_PUMA                                          0\n",
       "Gang_Affiliated                                      2217\n",
       "Supervision_Risk_Score_First                          330\n",
       "Supervision_Level_First                              1212\n",
       "Education_Level                                         0\n",
       "Dependents                                              0\n",
       "Prison_Offense                                       2321\n",
       "Prison_Years                                            0\n",
       "Prior_Arrest_Episodes_Felony                            0\n",
       "Prior_Arrest_Episodes_Misd                              0\n",
       "Prior_Arrest_Episodes_Violent                           0\n",
       "Prior_Arrest_Episodes_Property                          0\n",
       "Prior_Arrest_Episodes_Drug                              0\n",
       "Prior_Arrest_Episodes_PPViolationCharges                0\n",
       "Prior_Arrest_Episodes_DVCharges                         0\n",
       "Prior_Arrest_Episodes_GunCharges                        0\n",
       "Prior_Conviction_Episodes_Felony                        0\n",
       "Prior_Conviction_Episodes_Misd                          0\n",
       "Prior_Conviction_Episodes_Viol                          0\n",
       "Prior_Conviction_Episodes_Prop                          0\n",
       "Prior_Conviction_Episodes_Drug                          0\n",
       "Prior_Conviction_Episodes_PPViolationCharges            0\n",
       "Prior_Conviction_Episodes_DomesticViolenceCharges       0\n",
       "Prior_Conviction_Episodes_GunCharges                    0\n",
       "Prior_Revocations_Parole                                0\n",
       "Prior_Revocations_Probation                             0\n",
       "Condition_MH_SA                                         0\n",
       "Condition_Cog_Ed                                        0\n",
       "Condition_Other                                         0\n",
       "Violations_ElectronicMonitoring                         0\n",
       "Violations_Instruction                                  0\n",
       "Violations_FailToReport                                 0\n",
       "Violations_MoveWithoutPermission                        0\n",
       "Delinquency_Reports                                     0\n",
       "Program_Attendances                                     0\n",
       "Program_UnexcusedAbsences                               0\n",
       "Residence_Changes                                       0\n",
       "Avg_Days_per_DrugTest                                4260\n",
       "DrugTests_THC_Positive                               3632\n",
       "DrugTests_Cocaine_Positive                           3632\n",
       "DrugTests_Meth_Positive                              3632\n",
       "DrugTests_Other_Positive                             3632\n",
       "Percent_Days_Employed                                 307\n",
       "Jobs_Per_Year                                         534\n",
       "Employment_Exempt                                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of records having null Values in each column\n",
    "x_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8190"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total Number of Records in a Dataset with null values in any column\n",
    "x_train.isna().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                                         0\n",
       "Race                                           0\n",
       "Age_at_Release                                 0\n",
       "Gang_Affiliated                             2217\n",
       "Supervision_Level_First                     1212\n",
       "Education_Level                                0\n",
       "Dependents                                     0\n",
       "Prison_Offense                              2321\n",
       "Prison_Years                                   0\n",
       "Prior_Arrest_Episodes_Felony                   0\n",
       "Prior_Arrest_Episodes_Misd                     0\n",
       "Prior_Arrest_Episodes_Violent                  0\n",
       "Prior_Arrest_Episodes_Property                 0\n",
       "Prior_Arrest_Episodes_Drug                     0\n",
       "Prior_Arrest_Episodes_PPViolationCharges       0\n",
       "Prior_Conviction_Episodes_Felony               0\n",
       "Prior_Conviction_Episodes_Misd                 0\n",
       "Prior_Conviction_Episodes_Prop                 0\n",
       "Prior_Conviction_Episodes_Drug                 0\n",
       "Delinquency_Reports                            0\n",
       "Program_Attendances                            0\n",
       "Program_UnexcusedAbsences                      0\n",
       "Residence_Changes                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the Categoricorical columns for feature engineering(get Dummies)\n",
    "cat_columns=[col for col in x_train.columns if x_train[col].dtypes=='O']\n",
    "x_train[cat_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5211"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[cat_columns].isna().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender_F  Gender_M  Gender_nan  Race_BLACK  Race_WHITE  Race_nan  \\\n",
      "0         0         1           0           1           0         0   \n",
      "1         0         1           0           1           0         0   \n",
      "2         0         1           0           1           0         0   \n",
      "3         0         1           0           0           1         0   \n",
      "4         0         1           0           0           1         0   \n",
      "\n",
      "   Age_at_Release_18-22  Age_at_Release_23-27  Age_at_Release_28-32  \\\n",
      "0                     0                     0                     0   \n",
      "1                     0                     0                     0   \n",
      "2                     0                     0                     0   \n",
      "3                     0                     0                     0   \n",
      "4                     0                     0                     0   \n",
      "\n",
      "   Age_at_Release_33-37  ...  Program_UnexcusedAbsences_0  \\\n",
      "0                     0  ...                            1   \n",
      "1                     1  ...                            1   \n",
      "2                     0  ...                            1   \n",
      "3                     0  ...                            1   \n",
      "4                     1  ...                            1   \n",
      "\n",
      "   Program_UnexcusedAbsences_1  Program_UnexcusedAbsences_2  \\\n",
      "0                            0                            0   \n",
      "1                            0                            0   \n",
      "2                            0                            0   \n",
      "3                            0                            0   \n",
      "4                            0                            0   \n",
      "\n",
      "   Program_UnexcusedAbsences_3 or more  Program_UnexcusedAbsences_nan  \\\n",
      "0                                    0                              0   \n",
      "1                                    0                              0   \n",
      "2                                    0                              0   \n",
      "3                                    0                              0   \n",
      "4                                    0                              0   \n",
      "\n",
      "   Residence_Changes_0  Residence_Changes_1  Residence_Changes_2  \\\n",
      "0                    0                    0                    1   \n",
      "1                    0                    0                    1   \n",
      "2                    1                    0                    0   \n",
      "3                    0                    0                    0   \n",
      "4                    1                    0                    0   \n",
      "\n",
      "   Residence_Changes_3 or more  Residence_Changes_nan  \n",
      "0                            0                      0  \n",
      "1                            0                      0  \n",
      "2                            0                      0  \n",
      "3                            1                      0  \n",
      "4                            0                      0  \n",
      "\n",
      "[5 rows x 135 columns]\n"
     ]
    }
   ],
   "source": [
    "cat_variables = x_train[cat_columns]\n",
    "# print(cat_variables)\n",
    "cat_dummies = pd.get_dummies(cat_variables,dummy_na=True)\n",
    "print(cat_dummies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Gender', 'Race', 'Age_at_Release', 'Residence_PUMA',\n",
       "       'Gang_Affiliated', 'Supervision_Risk_Score_First',\n",
       "       'Supervision_Level_First', 'Education_Level', 'Dependents',\n",
       "       'Prison_Offense', 'Prison_Years', 'Prior_Arrest_Episodes_Felony',\n",
       "       'Prior_Arrest_Episodes_Misd', 'Prior_Arrest_Episodes_Violent',\n",
       "       'Prior_Arrest_Episodes_Property', 'Prior_Arrest_Episodes_Drug',\n",
       "       'Prior_Arrest_Episodes_PPViolationCharges',\n",
       "       'Prior_Arrest_Episodes_DVCharges', 'Prior_Arrest_Episodes_GunCharges',\n",
       "       'Prior_Conviction_Episodes_Felony', 'Prior_Conviction_Episodes_Misd',\n",
       "       'Prior_Conviction_Episodes_Viol', 'Prior_Conviction_Episodes_Prop',\n",
       "       'Prior_Conviction_Episodes_Drug',\n",
       "       'Prior_Conviction_Episodes_PPViolationCharges',\n",
       "       'Prior_Conviction_Episodes_DomesticViolenceCharges',\n",
       "       'Prior_Conviction_Episodes_GunCharges', 'Prior_Revocations_Parole',\n",
       "       'Prior_Revocations_Probation', 'Condition_MH_SA', 'Condition_Cog_Ed',\n",
       "       'Condition_Other', 'Violations_ElectronicMonitoring',\n",
       "       'Violations_Instruction', 'Violations_FailToReport',\n",
       "       'Violations_MoveWithoutPermission', 'Delinquency_Reports',\n",
       "       'Program_Attendances', 'Program_UnexcusedAbsences', 'Residence_Changes',\n",
       "       'Avg_Days_per_DrugTest', 'DrugTests_THC_Positive',\n",
       "       'DrugTests_Cocaine_Positive', 'DrugTests_Meth_Positive',\n",
       "       'DrugTests_Other_Positive', 'Percent_Days_Employed', 'Jobs_Per_Year',\n",
       "       'Employment_Exempt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(cat_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Residence_PUMA', 'Supervision_Risk_Score_First',\n",
       "       'Prior_Arrest_Episodes_DVCharges', 'Prior_Arrest_Episodes_GunCharges',\n",
       "       'Prior_Conviction_Episodes_Viol',\n",
       "       'Prior_Conviction_Episodes_PPViolationCharges',\n",
       "       'Prior_Conviction_Episodes_DomesticViolenceCharges',\n",
       "       'Prior_Conviction_Episodes_GunCharges', 'Prior_Revocations_Parole',\n",
       "       'Prior_Revocations_Probation', 'Condition_MH_SA', 'Condition_Cog_Ed',\n",
       "       'Condition_Other', 'Violations_ElectronicMonitoring',\n",
       "       'Violations_Instruction', 'Violations_FailToReport',\n",
       "       'Violations_MoveWithoutPermission', 'Avg_Days_per_DrugTest',\n",
       "       'DrugTests_THC_Positive', 'DrugTests_Cocaine_Positive',\n",
       "       'DrugTests_Meth_Positive', 'DrugTests_Other_Positive',\n",
       "       'Percent_Days_Employed', 'Jobs_Per_Year', 'Employment_Exempt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 - null\n",
    "get dummies, dummy_na - gang_affiliated _false=np.null, gangaffliated_true= np.nullgang_affiliated_nan=1\n",
    "drop ganga_affliated_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Residence_PUMA', 'Supervision_Risk_Score_First',\n",
      "       'Prior_Arrest_Episodes_DVCharges', 'Prior_Arrest_Episodes_GunCharges',\n",
      "       'Prior_Conviction_Episodes_Viol',\n",
      "       'Prior_Conviction_Episodes_PPViolationCharges',\n",
      "       'Prior_Conviction_Episodes_DomesticViolenceCharges',\n",
      "       'Prior_Conviction_Episodes_GunCharges', 'Prior_Revocations_Parole',\n",
      "       ...\n",
      "       'Program_UnexcusedAbsences_0', 'Program_UnexcusedAbsences_1',\n",
      "       'Program_UnexcusedAbsences_2', 'Program_UnexcusedAbsences_3 or more',\n",
      "       'Program_UnexcusedAbsences_nan', 'Residence_Changes_0',\n",
      "       'Residence_Changes_1', 'Residence_Changes_2',\n",
      "       'Residence_Changes_3 or more', 'Residence_Changes_nan'],\n",
      "      dtype='object', length=161)\n"
     ]
    }
   ],
   "source": [
    "x_train = pd.concat([x_train, cat_dummies], axis=1)\n",
    "print(x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.loc[x_train.Gang_Affiliated_nan == 1, [\"Gang_Affiliated_False\", \"Gang_Affiliated_True\"]] = np.nan\n",
    "# x_train.drop('Gang_Affiliated_nan',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.loc[x_train.Supervision_Level_First_nan == 1, [\"Supervision_Level_First_High\", \"Supervision_Level_First_Specialized\",\"Supervision_Level_First_Standard\"]] = np.nan\n",
    "# x_train.drop('Supervision_Level_First_nan',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.loc[x_train.Prison_Offense_nan == 1, [\"Prison_Offense_Drug\", \"Prison_Offense_Other\",\"Prison_Offense_Property\",\"Prison_Offense_Violent/Non-Sex\",\"Prison_Offense_Violent/Sex\"]] = np.nan\n",
    "# x_train.drop('Prison_Offense_nan',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop(['Gender_nan','Race_nan','Age_at_Release_nan','Gang_Affiliated_nan','Supervision_Level_First_nan','Education_Level_nan','Dependents_nan','Prison_Offense_nan','Prison_Years_nan','Prior_Arrest_Episodes_Felony_nan','Prior_Arrest_Episodes_Misd_nan','Prior_Arrest_Episodes_Violent_nan','Prior_Arrest_Episodes_Property_nan','Prior_Arrest_Episodes_Drug_nan','Prior_Arrest_Episodes_PPViolationCharges_nan','Prior_Conviction_Episodes_Felony_nan','Prior_Conviction_Episodes_Misd_nan','Prior_Conviction_Episodes_Prop_nan','Prior_Conviction_Episodes_Drug_nan','Delinquency_Reports_nan','Program_Attendances_nan','Program_UnexcusedAbsences_nan','Residence_Changes_nan'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8190"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_nan_values = x_train[x_train.isna().any(axis=1)]\n",
    "len(x_train_nan_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=10)\n",
    "x_train = pd.DataFrame(imputer.fit_transform(x_train),columns = x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                     False\n",
       "Residence_PUMA                         False\n",
       "Supervision_Risk_Score_First           False\n",
       "Prior_Arrest_Episodes_DVCharges        False\n",
       "Prior_Arrest_Episodes_GunCharges       False\n",
       "                                       ...  \n",
       "Program_UnexcusedAbsences_3 or more    False\n",
       "Residence_Changes_0                    False\n",
       "Residence_Changes_1                    False\n",
       "Residence_Changes_2                    False\n",
       "Residence_Changes_3 or more            False\n",
       "Length: 138, dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.291-b10, mixed mode)\n",
      "  Starting server from C:\\Users\\Vimalathithan\\anaconda3\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\VIMALA~1\\AppData\\Local\\Temp\\tmpikqfpg04\n",
      "  JVM stdout: C:\\Users\\VIMALA~1\\AppData\\Local\\Temp\\tmpikqfpg04\\h2o_Vimalathithan_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\VIMALA~1\\AppData\\Local\\Temp\\tmpikqfpg04\\h2o_Vimalathithan_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>06 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Chicago</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.32.1.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>8 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Vimalathithan_wz1old</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.542 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.8 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         06 secs\n",
       "H2O_cluster_timezone:       America/Chicago\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.32.1.3\n",
       "H2O_cluster_version_age:    8 days\n",
       "H2O_cluster_name:           H2O_from_python_Vimalathithan_wz1old\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.542 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         accepting new members, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.8.8 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "NIJ_Train_Mod = h2o.import_file(\"NIJ_s_Recidivism_Challenge_Training_Dataset-sara.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NIJ_Train_Mod[\"Recidivism_Arrest_Year1\"]=NIJ_Train_Mod[\"Recidivism_Arrest_Year1\"].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:18028\n",
      "Cols:53\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>ID                </th><th>Gender  </th><th>Race  </th><th>Age_at_Release  </th><th>Residence_PUMA    </th><th>Gang_Affiliated  </th><th>Supervision_Risk_Score_First  </th><th>Supervision_Level_First  </th><th>Education_Level      </th><th>Dependents        </th><th>Prison_Offense  </th><th>Prison_Years     </th><th>Prior_Arrest_Episodes_Felony  </th><th>Prior_Arrest_Episodes_Misd  </th><th>Prior_Arrest_Episodes_Violent  </th><th>Prior_Arrest_Episodes_Property  </th><th>Prior_Arrest_Episodes_Drug  </th><th>Prior_Arrest_Episodes_PPViolationCharges  </th><th>Prior_Arrest_Episodes_DVCharges  </th><th>Prior_Arrest_Episodes_GunCharges  </th><th>Prior_Conviction_Episodes_Felony  </th><th>Prior_Conviction_Episodes_Misd  </th><th>Prior_Conviction_Episodes_Viol  </th><th>Prior_Conviction_Episodes_Prop  </th><th>Prior_Conviction_Episodes_Drug  </th><th>Prior_Conviction_Episodes_PPViolationCharges  </th><th>Prior_Conviction_Episodes_DomesticViolenceCharges  </th><th>Prior_Conviction_Episodes_GunCharges  </th><th>Prior_Revocations_Parole  </th><th>Prior_Revocations_Probation  </th><th>Condition_MH_SA  </th><th>Condition_Cog_Ed  </th><th>Condition_Other  </th><th>Violations_ElectronicMonitoring  </th><th>Violations_Instruction  </th><th>Violations_FailToReport  </th><th>Violations_MoveWithoutPermission  </th><th>Delinquency_Reports  </th><th>Program_Attendances  </th><th>Program_UnexcusedAbsences  </th><th>Residence_Changes  </th><th>Avg_Days_per_DrugTest  </th><th>DrugTests_THC_Positive  </th><th>DrugTests_Cocaine_Positive  </th><th>DrugTests_Meth_Positive  </th><th>DrugTests_Other_Positive  </th><th>Percent_Days_Employed  </th><th>Jobs_Per_Year     </th><th>Employment_Exempt  </th><th>Recidivism_Within_3years  </th><th>Recidivism_Arrest_Year1  </th><th>Recidivism_Arrest_Year2  </th><th>Recidivism_Arrest_Year3  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int               </td><td>enum    </td><td>enum  </td><td>enum            </td><td>int               </td><td>enum             </td><td>int                           </td><td>enum                     </td><td>enum                 </td><td>int               </td><td>enum            </td><td>enum             </td><td>int                           </td><td>int                         </td><td>int                            </td><td>int                             </td><td>int                         </td><td>int                                       </td><td>enum                             </td><td>enum                              </td><td>int                               </td><td>int                             </td><td>enum                            </td><td>int                             </td><td>int                             </td><td>enum                                          </td><td>enum                                               </td><td>enum                                  </td><td>enum                      </td><td>enum                         </td><td>enum             </td><td>enum              </td><td>enum             </td><td>enum                             </td><td>enum                    </td><td>enum                     </td><td>enum                              </td><td>int                  </td><td>int                  </td><td>int                        </td><td>int                </td><td>real                   </td><td>real                    </td><td>real                        </td><td>real                     </td><td>real                      </td><td>real                   </td><td>real              </td><td>enum               </td><td>enum                      </td><td>enum                     </td><td>enum                     </td><td>enum                     </td></tr>\n",
       "<tr><td>mins   </td><td>1.0               </td><td>        </td><td>      </td><td>                </td><td>1.0               </td><td>                 </td><td>1.0                           </td><td>                         </td><td>                     </td><td>0.0               </td><td>                </td><td>                 </td><td>0.0                           </td><td>0.0                         </td><td>0.0                            </td><td>0.0                             </td><td>0.0                         </td><td>0.0                                       </td><td>                                 </td><td>                                  </td><td>0.0                               </td><td>0.0                             </td><td>                                </td><td>0.0                             </td><td>0.0                             </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td><td>                                 </td><td>                        </td><td>                         </td><td>                                  </td><td>0.0                  </td><td>0.0                  </td><td>0.0                        </td><td>0.0                </td><td>0.5                    </td><td>0.0                     </td><td>0.0                         </td><td>0.0                      </td><td>0.0                       </td><td>0.0                    </td><td>0.0               </td><td>                   </td><td>                          </td><td>                         </td><td>                         </td><td>                         </td></tr>\n",
       "<tr><td>mean   </td><td>13386.065342800088</td><td>        </td><td>      </td><td>                </td><td>12.307577102285334</td><td>                 </td><td>6.064753079444005             </td><td>                         </td><td>                     </td><td>0.812723373838456 </td><td>                </td><td>                 </td><td>4.414911449602799             </td><td>2.0828792191947945          </td><td>0.6597998822836962             </td><td>1.4095408895265422              </td><td>1.3619173262972735          </td><td>1.4528496645284967                        </td><td>                                 </td><td>                                  </td><td>0.8324328437714025                </td><td>1.0695922948801506              </td><td>                                </td><td>0.6161360601588306              </td><td>0.3367316341829085              </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td><td>                                 </td><td>                        </td><td>                         </td><td>                                  </td><td>0.36162238136670904  </td><td>1.9260880598908772   </td><td>0.168132468005095          </td><td>0.5673466841350053 </td><td>93.5858598589523       </td><td>0.06312002135558488     </td><td>0.014172916040219505        </td><td>0.012768276397193669     </td><td>0.007681323101278133      </td><td>0.48003490711381985    </td><td>0.7664227222145307</td><td>                   </td><td>                          </td><td>                         </td><td>                         </td><td>                         </td></tr>\n",
       "<tr><td>maxs   </td><td>26761.0           </td><td>        </td><td>      </td><td>                </td><td>25.0              </td><td>                 </td><td>10.0                          </td><td>                         </td><td>                     </td><td>2.0               </td><td>                </td><td>                 </td><td>9.0                           </td><td>5.0                         </td><td>2.0                            </td><td>4.0                             </td><td>4.0                         </td><td>4.0                                       </td><td>                                 </td><td>                                  </td><td>2.0                               </td><td>3.0                             </td><td>                                </td><td>2.0                             </td><td>1.0                             </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td><td>                                 </td><td>                        </td><td>                         </td><td>                                  </td><td>3.0                  </td><td>9.0                  </td><td>2.0                        </td><td>2.0                </td><td>1087.0                 </td><td>1.0                     </td><td>1.0                         </td><td>1.0                      </td><td>1.0                       </td><td>1.0                    </td><td>8.0               </td><td>                   </td><td>                          </td><td>                         </td><td>                         </td><td>                         </td></tr>\n",
       "<tr><td>sigma  </td><td>7721.4519921005185</td><td>        </td><td>      </td><td>                </td><td>7.143255483699997 </td><td>                 </td><td>2.382810692938381             </td><td>                         </td><td>                     </td><td>0.8167430677526973</td><td>                </td><td>                 </td><td>2.4116594385660526            </td><td>1.67257483980013            </td><td>0.7428877504621911             </td><td>1.3091293195913845              </td><td>1.3107390889979271          </td><td>1.3851498561202298                        </td><td>                                 </td><td>                                  </td><td>0.7772946645801881                </td><td>1.066248561059514               </td><td>                                </td><td>0.750285071892752               </td><td>0.4726099706580711              </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td><td>                                 </td><td>                        </td><td>                         </td><td>                                  </td><td>0.8430023110788695   </td><td>2.7639959132384333   </td><td>0.4887386930153355         </td><td>0.7305650615200656 </td><td>117.56134050131499     </td><td>0.13835671043544065     </td><td>0.06347303019200731         </td><td>0.0595718800725739       </td><td>0.04222438425341268       </td><td>0.42439649611104074    </td><td>0.8134739701739367</td><td>                   </td><td>                          </td><td>                         </td><td>                         </td><td>                         </td></tr>\n",
       "<tr><td>zeros  </td><td>0                 </td><td>        </td><td>      </td><td>                </td><td>0                 </td><td>                 </td><td>0                             </td><td>                         </td><td>                     </td><td>5599              </td><td>                </td><td>                 </td><td>172                           </td><td>2853                        </td><td>7705                           </td><td>4561                            </td><td>5563                        </td><td>4718                                      </td><td>                                 </td><td>                                  </td><td>5255                              </td><td>5507                            </td><td>                                </td><td>7784                            </td><td>8848                            </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td><td>                                 </td><td>                        </td><td>                         </td><td>                                  </td><td>12248                </td><td>9534                 </td><td>14531                      </td><td>9245               </td><td>0                      </td><td>9893                    </td><td>13073                       </td><td>12975                    </td><td>13328                     </td><td>5713                   </td><td>5455              </td><td>                   </td><td>                          </td><td>                         </td><td>                         </td><td>                         </td></tr>\n",
       "<tr><td>missing</td><td>0                 </td><td>0       </td><td>0     </td><td>0               </td><td>0                 </td><td>2217             </td><td>330                           </td><td>1212                     </td><td>0                    </td><td>5437              </td><td>2321            </td><td>0                </td><td>4307                          </td><td>5733                        </td><td>2737                           </td><td>4088                            </td><td>2110                        </td><td>4465                                      </td><td>0                                </td><td>0                                 </td><td>4887                              </td><td>4219                            </td><td>0                               </td><td>3799                            </td><td>4688                            </td><td>0                                             </td><td>0                                                  </td><td>0                                     </td><td>0                         </td><td>0                            </td><td>0                </td><td>0                 </td><td>0                </td><td>0                                </td><td>0                       </td><td>0                        </td><td>0                                 </td><td>3087                 </td><td>2266                 </td><td>1541                       </td><td>1999               </td><td>4260                   </td><td>3632                    </td><td>3632                        </td><td>3632                     </td><td>3632                      </td><td>307                    </td><td>534               </td><td>0                  </td><td>0                         </td><td>0                        </td><td>0                        </td><td>0                        </td></tr>\n",
       "<tr><td>0      </td><td>1.0               </td><td>M       </td><td>BLACK </td><td>43-47           </td><td>16.0              </td><td>false            </td><td>3.0                           </td><td>Standard                 </td><td>At least some college</td><td>nan               </td><td>Drug            </td><td>More than 3 years</td><td>6.0                           </td><td>nan                         </td><td>1.0                            </td><td>3.0                             </td><td>3.0                         </td><td>4.0                                       </td><td>false                            </td><td>false                             </td><td>nan                               </td><td>3.0                             </td><td>false                           </td><td>2.0                             </td><td>nan                             </td><td>false                                         </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>true             </td><td>true              </td><td>false            </td><td>false                            </td><td>false                   </td><td>false                    </td><td>false                             </td><td>0.0                  </td><td>6.0                  </td><td>0.0                        </td><td>2.0                </td><td>612.0                  </td><td>0.0                     </td><td>0.0                         </td><td>0.0                      </td><td>0.0                       </td><td>0.488562092            </td><td>0.447610294       </td><td>false              </td><td>false                     </td><td>false                    </td><td>false                    </td><td>false                    </td></tr>\n",
       "<tr><td>1      </td><td>2.0               </td><td>M       </td><td>BLACK </td><td>33-37           </td><td>16.0              </td><td>false            </td><td>6.0                           </td><td>Specialized              </td><td>Less than HS diploma </td><td>1.0               </td><td>Violent/Non-Sex </td><td>More than 3 years</td><td>7.0                           </td><td>nan                         </td><td>nan                            </td><td>0.0                             </td><td>3.0                         </td><td>nan                                       </td><td>true                             </td><td>false                             </td><td>nan                               </td><td>nan                             </td><td>true                            </td><td>0.0                             </td><td>nan                             </td><td>true                                          </td><td>true                                               </td><td>true                                  </td><td>false                     </td><td>false                        </td><td>false            </td><td>false             </td><td>false            </td><td>false                            </td><td>true                    </td><td>false                    </td><td>false                             </td><td>nan                  </td><td>0.0                  </td><td>0.0                        </td><td>2.0                </td><td>35.66666667            </td><td>0.0                     </td><td>0.0                         </td><td>0.0                      </td><td>0.0                       </td><td>0.425233645            </td><td>2.0               </td><td>false              </td><td>true                      </td><td>false                    </td><td>false                    </td><td>true                     </td></tr>\n",
       "<tr><td>2      </td><td>3.0               </td><td>M       </td><td>BLACK </td><td>48 or older     </td><td>24.0              </td><td>false            </td><td>7.0                           </td><td>High                     </td><td>At least some college</td><td>nan               </td><td>Drug            </td><td>1-2 years        </td><td>6.0                           </td><td>nan                         </td><td>nan                            </td><td>2.0                             </td><td>2.0                         </td><td>nan                                       </td><td>true                             </td><td>false                             </td><td>nan                               </td><td>2.0                             </td><td>true                            </td><td>1.0                             </td><td>nan                             </td><td>false                                         </td><td>true                                               </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>true             </td><td>true              </td><td>false            </td><td>false                            </td><td>true                    </td><td>false                    </td><td>true                              </td><td>nan                  </td><td>6.0                  </td><td>0.0                        </td><td>0.0                </td><td>93.66666667            </td><td>0.333333343             </td><td>0.0                         </td><td>0.166666672              </td><td>0.0                       </td><td>0.0                    </td><td>0.0               </td><td>false              </td><td>true                      </td><td>false                    </td><td>true                     </td><td>false                    </td></tr>\n",
       "<tr><td>3      </td><td>4.0               </td><td>M       </td><td>WHITE </td><td>38-42           </td><td>16.0              </td><td>false            </td><td>7.0                           </td><td>High                     </td><td>Less than HS diploma </td><td>1.0               </td><td>Property        </td><td>1-2 years        </td><td>8.0                           </td><td>nan                         </td><td>0.0                            </td><td>3.0                             </td><td>3.0                         </td><td>3.0                                       </td><td>false                            </td><td>false                             </td><td>nan                               </td><td>nan                             </td><td>false                           </td><td>nan                             </td><td>nan                             </td><td>false                                         </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>true                         </td><td>true             </td><td>true              </td><td>false            </td><td>false                            </td><td>false                   </td><td>false                    </td><td>false                             </td><td>0.0                  </td><td>6.0                  </td><td>0.0                        </td><td>nan                </td><td>25.4                   </td><td>0.0                     </td><td>0.0                         </td><td>0.0                      </td><td>0.0                       </td><td>1.0                    </td><td>0.718996063       </td><td>false              </td><td>false                     </td><td>false                    </td><td>false                    </td><td>false                    </td></tr>\n",
       "<tr><td>4      </td><td>5.0               </td><td>M       </td><td>WHITE </td><td>33-37           </td><td>16.0              </td><td>false            </td><td>4.0                           </td><td>Specialized              </td><td>Less than HS diploma </td><td>nan               </td><td>Violent/Non-Sex </td><td>1-2 years        </td><td>4.0                           </td><td>4.0                         </td><td>nan                            </td><td>2.0                             </td><td>1.0                         </td><td>3.0                                       </td><td>true                             </td><td>false                             </td><td>1.0                               </td><td>0.0                             </td><td>true                            </td><td>0.0                             </td><td>1.0                             </td><td>false                                         </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>true             </td><td>true              </td><td>true             </td><td>false                            </td><td>false                   </td><td>false                    </td><td>false                             </td><td>0.0                  </td><td>7.0                  </td><td>0.0                        </td><td>0.0                </td><td>23.11764706            </td><td>0.0                     </td><td>0.0                         </td><td>0.05882353               </td><td>0.0                       </td><td>0.203562341            </td><td>0.929389313       </td><td>false              </td><td>true                      </td><td>true                     </td><td>false                    </td><td>false                    </td></tr>\n",
       "<tr><td>5      </td><td>7.0               </td><td>M       </td><td>BLACK </td><td>48 or older     </td><td>18.0              </td><td>false            </td><td>2.0                           </td><td>Standard                 </td><td>Less than HS diploma </td><td>2.0               </td><td>                </td><td>Less than 1 year </td><td>nan                           </td><td>nan                         </td><td>1.0                            </td><td>nan                             </td><td>1.0                         </td><td>nan                                       </td><td>false                            </td><td>true                              </td><td>nan                               </td><td>1.0                             </td><td>false                           </td><td>nan                             </td><td>0.0                             </td><td>true                                          </td><td>false                                              </td><td>true                                  </td><td>false                     </td><td>false                        </td><td>false            </td><td>false             </td><td>false            </td><td>false                            </td><td>false                   </td><td>false                    </td><td>false                             </td><td>0.0                  </td><td>0.0                  </td><td>0.0                        </td><td>1.0                </td><td>238.5                  </td><td>0.0                     </td><td>0.0                         </td><td>0.0                      </td><td>0.0                       </td><td>0.0                    </td><td>0.0               </td><td>false              </td><td>true                      </td><td>false                    </td><td>false                    </td><td>true                     </td></tr>\n",
       "<tr><td>6      </td><td>9.0               </td><td>F       </td><td>BLACK </td><td>43-47           </td><td>5.0               </td><td>                 </td><td>7.0                           </td><td>High                     </td><td>High School Diploma  </td><td>0.0               </td><td>Drug            </td><td>Less than 1 year </td><td>nan                           </td><td>4.0                         </td><td>2.0                            </td><td>nan                             </td><td>3.0                         </td><td>3.0                                       </td><td>false                            </td><td>false                             </td><td>2.0                               </td><td>nan                             </td><td>false                           </td><td>nan                             </td><td>nan                             </td><td>true                                          </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>true                         </td><td>true             </td><td>false             </td><td>false            </td><td>false                            </td><td>false                   </td><td>false                    </td><td>false                             </td><td>0.0                  </td><td>0.0                  </td><td>0.0                        </td><td>0.0                </td><td>nan                    </td><td>nan                     </td><td>nan                         </td><td>nan                      </td><td>nan                       </td><td>0.0                    </td><td>0.0               </td><td>true               </td><td>true                      </td><td>true                     </td><td>false                    </td><td>false                    </td></tr>\n",
       "<tr><td>7      </td><td>10.0              </td><td>M       </td><td>BLACK </td><td>43-47           </td><td>16.0              </td><td>false            </td><td>5.0                           </td><td>Standard                 </td><td>High School Diploma  </td><td>nan               </td><td>Property        </td><td>More than 3 years</td><td>nan                           </td><td>nan                         </td><td>nan                            </td><td>nan                             </td><td>2.0                         </td><td>nan                                       </td><td>true                             </td><td>true                              </td><td>nan                               </td><td>nan                             </td><td>true                            </td><td>nan                             </td><td>nan                             </td><td>true                                          </td><td>true                                               </td><td>true                                  </td><td>false                     </td><td>false                        </td><td>false            </td><td>true              </td><td>true             </td><td>false                            </td><td>false                   </td><td>false                    </td><td>false                             </td><td>0.0                  </td><td>0.0                  </td><td>0.0                        </td><td>0.0                </td><td>27.8                   </td><td>0.0                     </td><td>0.0                         </td><td>0.0                      </td><td>0.0                       </td><td>0.35971223             </td><td>1.0               </td><td>false              </td><td>true                      </td><td>true                     </td><td>false                    </td><td>false                    </td></tr>\n",
       "<tr><td>8      </td><td>11.0              </td><td>M       </td><td>WHITE </td><td>43-47           </td><td>5.0               </td><td>false            </td><td>3.0                           </td><td>Specialized              </td><td>Less than HS diploma </td><td>1.0               </td><td>Violent/Non-Sex </td><td>1-2 years        </td><td>3.0                           </td><td>nan                         </td><td>2.0                            </td><td>1.0                             </td><td>1.0                         </td><td>3.0                                       </td><td>true                             </td><td>false                             </td><td>0.0                               </td><td>3.0                             </td><td>false                           </td><td>0.0                             </td><td>0.0                             </td><td>true                                          </td><td>false                                              </td><td>false                                 </td><td>true                      </td><td>false                        </td><td>true             </td><td>true              </td><td>false            </td><td>true                             </td><td>true                    </td><td>false                    </td><td>false                             </td><td>0.0                  </td><td>9.0                  </td><td>2.0                        </td><td>2.0                </td><td>42.8                   </td><td>0.300000012             </td><td>0.0                         </td><td>0.300000012              </td><td>0.0                       </td><td>1.0                    </td><td>3.413551402       </td><td>true               </td><td>true                      </td><td>false                    </td><td>true                     </td><td>false                    </td></tr>\n",
       "<tr><td>9      </td><td>13.0              </td><td>M       </td><td>WHITE </td><td>48 or older     </td><td>18.0              </td><td>false            </td><td>3.0                           </td><td>Standard                 </td><td>Less than HS diploma </td><td>1.0               </td><td>Property        </td><td>More than 3 years</td><td>8.0                           </td><td>4.0                         </td><td>0.0                            </td><td>nan                             </td><td>2.0                         </td><td>1.0                                       </td><td>false                            </td><td>false                             </td><td>1.0                               </td><td>0.0                             </td><td>false                           </td><td>2.0                             </td><td>1.0                             </td><td>false                                         </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>false            </td><td>false             </td><td>false            </td><td>false                            </td><td>false                   </td><td>false                    </td><td>false                             </td><td>0.0                  </td><td>0.0                  </td><td>0.0                        </td><td>1.0                </td><td>nan                    </td><td>0.0                     </td><td>0.0                         </td><td>0.016055046              </td><td>0.002293578               </td><td>0.0                    </td><td>nan               </td><td>false              </td><td>false                     </td><td>false                    </td><td>false                    </td><td>false                    </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NIJ_Train_Mod.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender', 'Race', 'Age_at_Release', 'Residence_PUMA', 'Gang_Affiliated', 'Supervision_Risk_Score_First', 'Supervision_Level_First', 'Education_Level', 'Dependents', 'Prison_Offense', 'Prison_Years', 'Prior_Arrest_Episodes_Felony', 'Prior_Arrest_Episodes_Misd', 'Prior_Arrest_Episodes_Violent', 'Prior_Arrest_Episodes_Property', 'Prior_Arrest_Episodes_Drug', 'Prior_Arrest_Episodes_PPViolationCharges', 'Prior_Arrest_Episodes_DVCharges', 'Prior_Arrest_Episodes_GunCharges', 'Prior_Conviction_Episodes_Felony', 'Prior_Conviction_Episodes_Misd', 'Prior_Conviction_Episodes_Viol', 'Prior_Conviction_Episodes_Prop', 'Prior_Conviction_Episodes_Drug', 'Prior_Conviction_Episodes_PPViolationCharges', 'Prior_Conviction_Episodes_DomesticViolenceCharges', 'Prior_Conviction_Episodes_GunCharges', 'Prior_Revocations_Parole', 'Prior_Revocations_Probation', 'Condition_MH_SA', 'Condition_Cog_Ed', 'Condition_Other', 'Violations_ElectronicMonitoring', 'Violations_Instruction', 'Violations_FailToReport', 'Violations_MoveWithoutPermission', 'Delinquency_Reports', 'Program_Attendances', 'Program_UnexcusedAbsences', 'Residence_Changes', 'Avg_Days_per_DrugTest', 'DrugTests_THC_Positive', 'DrugTests_Cocaine_Positive', 'DrugTests_Meth_Positive', 'DrugTests_Other_Positive', 'Percent_Days_Employed', 'Jobs_Per_Year', 'Employment_Exempt', 'Recidivism_Arrest_Year1']\n"
     ]
    }
   ],
   "source": [
    "y= \"Recidivism_Arrest_Year1\"\n",
    "NIJ_Train_Mod=NIJ_Train_Mod.drop([\"ID\",\"Recidivism_Within_3years\",\"Recidivism_Arrest_Year2\",\"Recidivism_Arrest_Year3\"],axis=1)\n",
    "x= NIJ_Train_Mod.columns\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "06:17:10.678: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml = H2OAutoML(max_models = 10, seed = 1)\n",
    "aml.train(x = x, y = y, training_frame = NIJ_Train_Mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = aml.leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20210528_061710   </td><td style=\"text-align: right;\">0.867471</td><td style=\"text-align: right;\"> 0.40513 </td><td style=\"text-align: right;\">0.721791</td><td style=\"text-align: right;\">              0.219541</td><td style=\"text-align: right;\">0.365792</td><td style=\"text-align: right;\">0.133804</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20210528_061710                       </td><td style=\"text-align: right;\">0.864168</td><td style=\"text-align: right;\"> 0.410363</td><td style=\"text-align: right;\">0.713609</td><td style=\"text-align: right;\">              0.21977 </td><td style=\"text-align: right;\">0.368063</td><td style=\"text-align: right;\">0.13547 </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20210528_061710</td><td style=\"text-align: right;\">0.864058</td><td style=\"text-align: right;\"> 0.409899</td><td style=\"text-align: right;\">0.713256</td><td style=\"text-align: right;\">              0.219616</td><td style=\"text-align: right;\">0.368111</td><td style=\"text-align: right;\">0.135506</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20210528_061710                       </td><td style=\"text-align: right;\">0.863699</td><td style=\"text-align: right;\"> 0.410663</td><td style=\"text-align: right;\">0.712505</td><td style=\"text-align: right;\">              0.219131</td><td style=\"text-align: right;\">0.368405</td><td style=\"text-align: right;\">0.135722</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210528_061710_model_1         </td><td style=\"text-align: right;\">0.862715</td><td style=\"text-align: right;\"> 0.413537</td><td style=\"text-align: right;\">0.712251</td><td style=\"text-align: right;\">              0.221504</td><td style=\"text-align: right;\">0.369357</td><td style=\"text-align: right;\">0.136425</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20210528_061710                       </td><td style=\"text-align: right;\">0.862392</td><td style=\"text-align: right;\"> 0.411906</td><td style=\"text-align: right;\">0.711023</td><td style=\"text-align: right;\">              0.221938</td><td style=\"text-align: right;\">0.369111</td><td style=\"text-align: right;\">0.136243</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20210528_061710                       </td><td style=\"text-align: right;\">0.859444</td><td style=\"text-align: right;\"> 0.41611 </td><td style=\"text-align: right;\">0.702074</td><td style=\"text-align: right;\">              0.224182</td><td style=\"text-align: right;\">0.371412</td><td style=\"text-align: right;\">0.137947</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20210528_061710                       </td><td style=\"text-align: right;\">0.858616</td><td style=\"text-align: right;\"> 0.418236</td><td style=\"text-align: right;\">0.704776</td><td style=\"text-align: right;\">              0.228805</td><td style=\"text-align: right;\">0.372262</td><td style=\"text-align: right;\">0.138579</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20210528_061710                       </td><td style=\"text-align: right;\">0.818852</td><td style=\"text-align: right;\"> 0.473279</td><td style=\"text-align: right;\">0.635521</td><td style=\"text-align: right;\">              0.257104</td><td style=\"text-align: right;\">0.39568 </td><td style=\"text-align: right;\">0.156562</td></tr>\n",
       "<tr><td>DRF_1_AutoML_20210528_061710                       </td><td style=\"text-align: right;\">0.818494</td><td style=\"text-align: right;\"> 0.473402</td><td style=\"text-align: right;\">0.63413 </td><td style=\"text-align: right;\">              0.255788</td><td style=\"text-align: right;\">0.395534</td><td style=\"text-align: right;\">0.156447</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20210528_061710   </td><td style=\"text-align: right;\">0.867471</td><td style=\"text-align: right;\"> 0.40513 </td><td style=\"text-align: right;\">0.721791</td><td style=\"text-align: right;\">              0.219541</td><td style=\"text-align: right;\">0.365792</td><td style=\"text-align: right;\">0.133804</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20210528_061710                       </td><td style=\"text-align: right;\">0.864168</td><td style=\"text-align: right;\"> 0.410363</td><td style=\"text-align: right;\">0.713609</td><td style=\"text-align: right;\">              0.21977 </td><td style=\"text-align: right;\">0.368063</td><td style=\"text-align: right;\">0.13547 </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20210528_061710</td><td style=\"text-align: right;\">0.864058</td><td style=\"text-align: right;\"> 0.409899</td><td style=\"text-align: right;\">0.713256</td><td style=\"text-align: right;\">              0.219616</td><td style=\"text-align: right;\">0.368111</td><td style=\"text-align: right;\">0.135506</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20210528_061710                       </td><td style=\"text-align: right;\">0.863699</td><td style=\"text-align: right;\"> 0.410663</td><td style=\"text-align: right;\">0.712505</td><td style=\"text-align: right;\">              0.219131</td><td style=\"text-align: right;\">0.368405</td><td style=\"text-align: right;\">0.135722</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210528_061710_model_1         </td><td style=\"text-align: right;\">0.862715</td><td style=\"text-align: right;\"> 0.413537</td><td style=\"text-align: right;\">0.712251</td><td style=\"text-align: right;\">              0.221504</td><td style=\"text-align: right;\">0.369357</td><td style=\"text-align: right;\">0.136425</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20210528_061710                       </td><td style=\"text-align: right;\">0.862392</td><td style=\"text-align: right;\"> 0.411906</td><td style=\"text-align: right;\">0.711023</td><td style=\"text-align: right;\">              0.221938</td><td style=\"text-align: right;\">0.369111</td><td style=\"text-align: right;\">0.136243</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20210528_061710                       </td><td style=\"text-align: right;\">0.859444</td><td style=\"text-align: right;\"> 0.41611 </td><td style=\"text-align: right;\">0.702074</td><td style=\"text-align: right;\">              0.224182</td><td style=\"text-align: right;\">0.371412</td><td style=\"text-align: right;\">0.137947</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20210528_061710                       </td><td style=\"text-align: right;\">0.858616</td><td style=\"text-align: right;\"> 0.418236</td><td style=\"text-align: right;\">0.704776</td><td style=\"text-align: right;\">              0.228805</td><td style=\"text-align: right;\">0.372262</td><td style=\"text-align: right;\">0.138579</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20210528_061710                       </td><td style=\"text-align: right;\">0.818852</td><td style=\"text-align: right;\"> 0.473279</td><td style=\"text-align: right;\">0.635521</td><td style=\"text-align: right;\">              0.257104</td><td style=\"text-align: right;\">0.39568 </td><td style=\"text-align: right;\">0.156562</td></tr>\n",
       "<tr><td>DRF_1_AutoML_20210528_061710                       </td><td style=\"text-align: right;\">0.818494</td><td style=\"text-align: right;\"> 0.473402</td><td style=\"text-align: right;\">0.63413 </td><td style=\"text-align: right;\">              0.255788</td><td style=\"text-align: right;\">0.395534</td><td style=\"text-align: right;\">0.156447</td></tr>\n",
       "<tr><td>GLM_1_AutoML_20210528_061710                       </td><td style=\"text-align: right;\">0.769877</td><td style=\"text-align: right;\"> 0.509474</td><td style=\"text-align: right;\">0.56241 </td><td style=\"text-align: right;\">              0.295848</td><td style=\"text-align: right;\">0.412596</td><td style=\"text-align: right;\">0.170236</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20210528_061710              </td><td style=\"text-align: right;\">0.764187</td><td style=\"text-align: right;\"> 0.514955</td><td style=\"text-align: right;\">0.559117</td><td style=\"text-align: right;\">              0.303828</td><td style=\"text-align: right;\">0.415162</td><td style=\"text-align: right;\">0.172359</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model ids for all models in the AutoML Leaderboard\n",
    "model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n",
    "# Get the \"All Models\" Stacked Ensemble model\n",
    "se = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_AllModels\" in mid][0])\n",
    "# Get the Stacked Ensemble metalearner model\n",
    "metalearner = se.metalearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intercept': -1.5513084495297385,\n",
       " 'GBM_1_AutoML_20210528_061710': 0.5105255495423108,\n",
       " 'GBM_2_AutoML_20210528_061710': 0.46958082297640646,\n",
       " 'GBM_grid__1_AutoML_20210528_061710_model_1': 0.3403355892744305,\n",
       " 'GBM_5_AutoML_20210528_061710': 0.3784814600766142,\n",
       " 'GBM_3_AutoML_20210528_061710': 0.09444636609576594,\n",
       " 'GBM_4_AutoML_20210528_061710': 0.29942092112786983,\n",
       " 'XRT_1_AutoML_20210528_061710': 0.0,\n",
       " 'DRF_1_AutoML_20210528_061710': 0.0,\n",
       " 'GLM_1_AutoML_20210528_061710': 0.0,\n",
       " 'DeepLearning_1_AutoML_20210528_061710': 0.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metalearner.coef_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_AllModels_AutoML_20210528_061710\n",
      "\n",
      "No model summary for this model\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.08650724292190123\n",
      "RMSE: 0.2941211364759446\n",
      "LogLoss: 0.2874831484579681\n",
      "Null degrees of freedom: 10050\n",
      "Residual degrees of freedom: 10044\n",
      "Null deviance: 12311.739370630861\n",
      "Residual deviance: 5778.986250302074\n",
      "AIC: 5792.986250302074\n",
      "AUC: 0.9538420395181154\n",
      "AUCPR: 0.9041127762990673\n",
      "Gini: 0.9076840790362308\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4189203634519596: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>false</th>\n",
       "      <th>true</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>6310.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>(707.0/7017.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true</td>\n",
       "      <td>430.0</td>\n",
       "      <td>2604.0</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>(430.0/3034.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>6740.0</td>\n",
       "      <td>3311.0</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>(1137.0/10051.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           false    true   Error               Rate\n",
       "0  false  6310.0   707.0  0.1008     (707.0/7017.0)\n",
       "1   true   430.0  2604.0  0.1417     (430.0/3034.0)\n",
       "2  Total  6740.0  3311.0  0.1131   (1137.0/10051.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.418920</td>\n",
       "      <td>0.820804</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.302755</td>\n",
       "      <td>0.869886</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.575095</td>\n",
       "      <td>0.845452</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.497913</td>\n",
       "      <td>0.890260</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.974528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.039182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.974528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.449960</td>\n",
       "      <td>0.740427</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.390189</td>\n",
       "      <td>0.880433</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>0.882769</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.974528</td>\n",
       "      <td>7017.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.974528</td>\n",
       "      <td>3031.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>7017.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.039182</td>\n",
       "      <td>3034.000000</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.974528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.974528</td>\n",
       "      <td>0.999011</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.039182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.418920     0.820804  198.0\n",
       "1                        max f2   0.302755     0.869886  243.0\n",
       "2                  max f0point5   0.575095     0.845452  142.0\n",
       "3                  max accuracy   0.497913     0.890260  170.0\n",
       "4                 max precision   0.974528     1.000000    0.0\n",
       "5                    max recall   0.039182     1.000000  367.0\n",
       "6               max specificity   0.974528     1.000000    0.0\n",
       "7              max absolute_mcc   0.449960     0.740427  186.0\n",
       "8    max min_per_class_accuracy   0.390189     0.880433  209.0\n",
       "9   max mean_per_class_accuracy   0.379330     0.882769  213.0\n",
       "10                      max tns   0.974528  7017.000000    0.0\n",
       "11                      max fns   0.974528  3031.000000    0.0\n",
       "12                      max fps   0.003134  7017.000000  399.0\n",
       "13                      max tps   0.039182  3034.000000  367.0\n",
       "14                      max tnr   0.974528     1.000000    0.0\n",
       "15                      max fnr   0.974528     0.999011    0.0\n",
       "16                      max fpr   0.003134     1.000000  399.0\n",
       "17                      max tpr   0.039182     1.000000  367.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 30.19 %, avg score: 30.54 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>0.927209</td>\n",
       "      <td>3.312788</td>\n",
       "      <td>3.312788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945343</td>\n",
       "      <td>0.033289</td>\n",
       "      <td>0.033289</td>\n",
       "      <td>231.278840</td>\n",
       "      <td>231.278840</td>\n",
       "      <td>0.033289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020098</td>\n",
       "      <td>0.904970</td>\n",
       "      <td>3.312788</td>\n",
       "      <td>3.312788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930108</td>\n",
       "      <td>0.033289</td>\n",
       "      <td>0.066579</td>\n",
       "      <td>231.278840</td>\n",
       "      <td>231.278840</td>\n",
       "      <td>0.066579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030047</td>\n",
       "      <td>0.886254</td>\n",
       "      <td>3.312788</td>\n",
       "      <td>3.312788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.918306</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.099539</td>\n",
       "      <td>231.278840</td>\n",
       "      <td>231.278840</td>\n",
       "      <td>0.099539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040096</td>\n",
       "      <td>0.867489</td>\n",
       "      <td>3.181589</td>\n",
       "      <td>3.279907</td>\n",
       "      <td>0.960396</td>\n",
       "      <td>0.876064</td>\n",
       "      <td>0.990074</td>\n",
       "      <td>0.907719</td>\n",
       "      <td>0.031971</td>\n",
       "      <td>0.131510</td>\n",
       "      <td>218.158886</td>\n",
       "      <td>227.990712</td>\n",
       "      <td>0.130940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050045</td>\n",
       "      <td>0.851382</td>\n",
       "      <td>3.279661</td>\n",
       "      <td>3.279858</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.858894</td>\n",
       "      <td>0.990060</td>\n",
       "      <td>0.898012</td>\n",
       "      <td>0.032630</td>\n",
       "      <td>0.164140</td>\n",
       "      <td>227.966051</td>\n",
       "      <td>227.985810</td>\n",
       "      <td>0.163427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100090</td>\n",
       "      <td>0.772752</td>\n",
       "      <td>3.207411</td>\n",
       "      <td>3.243635</td>\n",
       "      <td>0.968191</td>\n",
       "      <td>0.809886</td>\n",
       "      <td>0.979125</td>\n",
       "      <td>0.853949</td>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.324654</td>\n",
       "      <td>220.741143</td>\n",
       "      <td>224.363476</td>\n",
       "      <td>0.321661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150035</td>\n",
       "      <td>0.700132</td>\n",
       "      <td>3.009226</td>\n",
       "      <td>3.165602</td>\n",
       "      <td>0.908367</td>\n",
       "      <td>0.738196</td>\n",
       "      <td>0.955570</td>\n",
       "      <td>0.815416</td>\n",
       "      <td>0.150297</td>\n",
       "      <td>0.474951</td>\n",
       "      <td>200.922611</td>\n",
       "      <td>216.560218</td>\n",
       "      <td>0.465402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200080</td>\n",
       "      <td>0.620309</td>\n",
       "      <td>2.693699</td>\n",
       "      <td>3.047568</td>\n",
       "      <td>0.813121</td>\n",
       "      <td>0.661551</td>\n",
       "      <td>0.919940</td>\n",
       "      <td>0.776931</td>\n",
       "      <td>0.134806</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>169.369872</td>\n",
       "      <td>204.756765</td>\n",
       "      <td>0.586812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300070</td>\n",
       "      <td>0.464755</td>\n",
       "      <td>2.040414</td>\n",
       "      <td>2.711961</td>\n",
       "      <td>0.615920</td>\n",
       "      <td>0.543442</td>\n",
       "      <td>0.818634</td>\n",
       "      <td>0.699127</td>\n",
       "      <td>0.204021</td>\n",
       "      <td>0.813777</td>\n",
       "      <td>104.041395</td>\n",
       "      <td>171.196106</td>\n",
       "      <td>0.735824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400060</td>\n",
       "      <td>0.316539</td>\n",
       "      <td>1.114152</td>\n",
       "      <td>2.312608</td>\n",
       "      <td>0.336318</td>\n",
       "      <td>0.388493</td>\n",
       "      <td>0.698085</td>\n",
       "      <td>0.621488</td>\n",
       "      <td>0.111404</td>\n",
       "      <td>0.925181</td>\n",
       "      <td>11.415172</td>\n",
       "      <td>131.260807</td>\n",
       "      <td>0.752173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500050</td>\n",
       "      <td>0.207099</td>\n",
       "      <td>0.481261</td>\n",
       "      <td>1.946411</td>\n",
       "      <td>0.145274</td>\n",
       "      <td>0.258995</td>\n",
       "      <td>0.587545</td>\n",
       "      <td>0.549004</td>\n",
       "      <td>0.048121</td>\n",
       "      <td>0.973303</td>\n",
       "      <td>-51.873920</td>\n",
       "      <td>94.641149</td>\n",
       "      <td>0.677877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600040</td>\n",
       "      <td>0.121346</td>\n",
       "      <td>0.210964</td>\n",
       "      <td>1.657218</td>\n",
       "      <td>0.063682</td>\n",
       "      <td>0.161457</td>\n",
       "      <td>0.500249</td>\n",
       "      <td>0.484423</td>\n",
       "      <td>0.021094</td>\n",
       "      <td>0.994397</td>\n",
       "      <td>-78.903636</td>\n",
       "      <td>65.721814</td>\n",
       "      <td>0.564869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.700030</td>\n",
       "      <td>0.058792</td>\n",
       "      <td>0.052741</td>\n",
       "      <td>1.428040</td>\n",
       "      <td>0.015920</td>\n",
       "      <td>0.088064</td>\n",
       "      <td>0.431069</td>\n",
       "      <td>0.427809</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>-94.725909</td>\n",
       "      <td>42.803968</td>\n",
       "      <td>0.429199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.800020</td>\n",
       "      <td>0.021974</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>1.249969</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.038180</td>\n",
       "      <td>0.377316</td>\n",
       "      <td>0.379111</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-99.670369</td>\n",
       "      <td>24.996891</td>\n",
       "      <td>0.286447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.900010</td>\n",
       "      <td>0.009440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014584</td>\n",
       "      <td>0.335397</td>\n",
       "      <td>0.338612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.109883</td>\n",
       "      <td>0.143224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006254</td>\n",
       "      <td>0.301861</td>\n",
       "      <td>0.305380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010049         0.927209  3.312788   \n",
       "1       2                  0.020098         0.904970  3.312788   \n",
       "2       3                  0.030047         0.886254  3.312788   \n",
       "3       4                  0.040096         0.867489  3.181589   \n",
       "4       5                  0.050045         0.851382  3.279661   \n",
       "5       6                  0.100090         0.772752  3.207411   \n",
       "6       7                  0.150035         0.700132  3.009226   \n",
       "7       8                  0.200080         0.620309  2.693699   \n",
       "8       9                  0.300070         0.464755  2.040414   \n",
       "9      10                  0.400060         0.316539  1.114152   \n",
       "10     11                  0.500050         0.207099  0.481261   \n",
       "11     12                  0.600040         0.121346  0.210964   \n",
       "12     13                  0.700030         0.058792  0.052741   \n",
       "13     14                  0.800020         0.021974  0.003296   \n",
       "14     15                  0.900010         0.009440  0.000000   \n",
       "15     16                  1.000000         0.002554  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          3.312788       1.000000  0.945343                  1.000000   \n",
       "1          3.312788       1.000000  0.914873                  1.000000   \n",
       "2          3.312788       1.000000  0.894465                  1.000000   \n",
       "3          3.279907       0.960396  0.876064                  0.990074   \n",
       "4          3.279858       0.990000  0.858894                  0.990060   \n",
       "5          3.243635       0.968191  0.809886                  0.979125   \n",
       "6          3.165602       0.908367  0.738196                  0.955570   \n",
       "7          3.047568       0.813121  0.661551                  0.919940   \n",
       "8          2.711961       0.615920  0.543442                  0.818634   \n",
       "9          2.312608       0.336318  0.388493                  0.698085   \n",
       "10         1.946411       0.145274  0.258995                  0.587545   \n",
       "11         1.657218       0.063682  0.161457                  0.500249   \n",
       "12         1.428040       0.015920  0.088064                  0.431069   \n",
       "13         1.249969       0.000995  0.038180                  0.377316   \n",
       "14         1.111099       0.000000  0.014584                  0.335397   \n",
       "15         1.000000       0.000000  0.006254                  0.301861   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.945343      0.033289                 0.033289  231.278840   \n",
       "1           0.930108      0.033289                 0.066579  231.278840   \n",
       "2           0.918306      0.032960                 0.099539  231.278840   \n",
       "3           0.907719      0.031971                 0.131510  218.158886   \n",
       "4           0.898012      0.032630                 0.164140  227.966051   \n",
       "5           0.853949      0.160514                 0.324654  220.741143   \n",
       "6           0.815416      0.150297                 0.474951  200.922611   \n",
       "7           0.776931      0.134806                 0.609756  169.369872   \n",
       "8           0.699127      0.204021                 0.813777  104.041395   \n",
       "9           0.621488      0.111404                 0.925181   11.415172   \n",
       "10          0.549004      0.048121                 0.973303  -51.873920   \n",
       "11          0.484423      0.021094                 0.994397  -78.903636   \n",
       "12          0.427809      0.005274                 0.999670  -94.725909   \n",
       "13          0.379111      0.000330                 1.000000  -99.670369   \n",
       "14          0.338612      0.000000                 1.000000 -100.000000   \n",
       "15          0.305380      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        231.278840            0.033289  \n",
       "1        231.278840            0.066579  \n",
       "2        231.278840            0.099539  \n",
       "3        227.990712            0.130940  \n",
       "4        227.985810            0.163427  \n",
       "5        224.363476            0.321661  \n",
       "6        216.560218            0.465402  \n",
       "7        204.756765            0.586812  \n",
       "8        171.196106            0.735824  \n",
       "9        131.260807            0.752173  \n",
       "10        94.641149            0.677877  \n",
       "11        65.721814            0.564869  \n",
       "12        42.803968            0.429199  \n",
       "13        24.996891            0.286447  \n",
       "14        11.109883            0.143224  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.13380359504990866\n",
      "RMSE: 0.3657917372630342\n",
      "LogLoss: 0.40513002313124813\n",
      "Null degrees of freedom: 18027\n",
      "Residual degrees of freedom: 18021\n",
      "Null deviance: 21973.615935551534\n",
      "Residual deviance: 14607.368114020283\n",
      "AIC: 14621.368114020283\n",
      "AUC: 0.86747107770566\n",
      "AUCPR: 0.7217905216811624\n",
      "Gini: 0.73494215541132\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35604976499101815: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>false</th>\n",
       "      <th>true</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>10016.0</td>\n",
       "      <td>2635.0</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>(2635.0/12651.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>4136.0</td>\n",
       "      <td>0.2308</td>\n",
       "      <td>(1241.0/5377.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>11257.0</td>\n",
       "      <td>6771.0</td>\n",
       "      <td>0.215</td>\n",
       "      <td>(3876.0/18028.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            false    true   Error               Rate\n",
       "0  false  10016.0  2635.0  0.2083   (2635.0/12651.0)\n",
       "1   true   1241.0  4136.0  0.2308    (1241.0/5377.0)\n",
       "2  Total  11257.0  6771.0   0.215   (3876.0/18028.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.356050</td>\n",
       "      <td>0.680935</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.120672</td>\n",
       "      <td>0.791223</td>\n",
       "      <td>324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.524412</td>\n",
       "      <td>0.672153</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.524412</td>\n",
       "      <td>0.800588</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.981574</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.011920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.981574</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.367843</td>\n",
       "      <td>0.530751</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.342223</td>\n",
       "      <td>0.780808</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.275598</td>\n",
       "      <td>0.781794</td>\n",
       "      <td>257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.981574</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.981574</td>\n",
       "      <td>5376.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.011920</td>\n",
       "      <td>5377.000000</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.981574</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.981574</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.011920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.356050      0.680935  224.0\n",
       "1                        max f2   0.120672      0.791223  324.0\n",
       "2                  max f0point5   0.524412      0.672153  157.0\n",
       "3                  max accuracy   0.524412      0.800588  157.0\n",
       "4                 max precision   0.981574      1.000000    0.0\n",
       "5                    max recall   0.011920      1.000000  389.0\n",
       "6               max specificity   0.981574      1.000000    0.0\n",
       "7              max absolute_mcc   0.367843      0.530751  219.0\n",
       "8    max min_per_class_accuracy   0.342223      0.780808  230.0\n",
       "9   max mean_per_class_accuracy   0.275598      0.781794  257.0\n",
       "10                      max tns   0.981574  12651.000000    0.0\n",
       "11                      max fns   0.981574   5376.000000    0.0\n",
       "12                      max fps   0.003425  12651.000000  399.0\n",
       "13                      max tps   0.011920   5377.000000  389.0\n",
       "14                      max tnr   0.981574      1.000000    0.0\n",
       "15                      max fnr   0.981574      0.999814    0.0\n",
       "16                      max fpr   0.003425      1.000000  399.0\n",
       "17                      max tpr   0.011920      1.000000  389.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 29.83 %, avg score: 29.83 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.909022</td>\n",
       "      <td>3.130514</td>\n",
       "      <td>3.130514</td>\n",
       "      <td>0.933702</td>\n",
       "      <td>0.933374</td>\n",
       "      <td>0.933702</td>\n",
       "      <td>0.933374</td>\n",
       "      <td>0.031430</td>\n",
       "      <td>0.031430</td>\n",
       "      <td>213.051394</td>\n",
       "      <td>213.051394</td>\n",
       "      <td>0.030482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020024</td>\n",
       "      <td>0.885657</td>\n",
       "      <td>3.054772</td>\n",
       "      <td>3.092748</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.896438</td>\n",
       "      <td>0.922438</td>\n",
       "      <td>0.914957</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.061930</td>\n",
       "      <td>205.477238</td>\n",
       "      <td>209.274807</td>\n",
       "      <td>0.059717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030009</td>\n",
       "      <td>0.859976</td>\n",
       "      <td>2.943012</td>\n",
       "      <td>3.042928</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.872478</td>\n",
       "      <td>0.907579</td>\n",
       "      <td>0.900824</td>\n",
       "      <td>0.029384</td>\n",
       "      <td>0.091315</td>\n",
       "      <td>194.301242</td>\n",
       "      <td>204.292844</td>\n",
       "      <td>0.087363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040049</td>\n",
       "      <td>0.841492</td>\n",
       "      <td>3.019371</td>\n",
       "      <td>3.037023</td>\n",
       "      <td>0.900552</td>\n",
       "      <td>0.850637</td>\n",
       "      <td>0.905817</td>\n",
       "      <td>0.888242</td>\n",
       "      <td>0.030314</td>\n",
       "      <td>0.121629</td>\n",
       "      <td>201.937144</td>\n",
       "      <td>203.702288</td>\n",
       "      <td>0.116254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050033</td>\n",
       "      <td>0.821851</td>\n",
       "      <td>2.663613</td>\n",
       "      <td>2.962506</td>\n",
       "      <td>0.794444</td>\n",
       "      <td>0.831180</td>\n",
       "      <td>0.883592</td>\n",
       "      <td>0.876855</td>\n",
       "      <td>0.026595</td>\n",
       "      <td>0.148224</td>\n",
       "      <td>166.361251</td>\n",
       "      <td>196.250640</td>\n",
       "      <td>0.139924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>0.736056</td>\n",
       "      <td>2.563905</td>\n",
       "      <td>2.763316</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.777556</td>\n",
       "      <td>0.824182</td>\n",
       "      <td>0.827233</td>\n",
       "      <td>0.128138</td>\n",
       "      <td>0.276362</td>\n",
       "      <td>156.390509</td>\n",
       "      <td>176.331628</td>\n",
       "      <td>0.251305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150044</td>\n",
       "      <td>0.660804</td>\n",
       "      <td>2.338038</td>\n",
       "      <td>2.621505</td>\n",
       "      <td>0.697339</td>\n",
       "      <td>0.697129</td>\n",
       "      <td>0.781885</td>\n",
       "      <td>0.783849</td>\n",
       "      <td>0.116980</td>\n",
       "      <td>0.393342</td>\n",
       "      <td>133.803830</td>\n",
       "      <td>162.150455</td>\n",
       "      <td>0.346705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.586668</td>\n",
       "      <td>1.975956</td>\n",
       "      <td>2.460207</td>\n",
       "      <td>0.589345</td>\n",
       "      <td>0.623198</td>\n",
       "      <td>0.733777</td>\n",
       "      <td>0.743709</td>\n",
       "      <td>0.098754</td>\n",
       "      <td>0.492096</td>\n",
       "      <td>97.595588</td>\n",
       "      <td>146.020689</td>\n",
       "      <td>0.416213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300033</td>\n",
       "      <td>0.449115</td>\n",
       "      <td>1.729397</td>\n",
       "      <td>2.216604</td>\n",
       "      <td>0.515807</td>\n",
       "      <td>0.517508</td>\n",
       "      <td>0.661120</td>\n",
       "      <td>0.668308</td>\n",
       "      <td>0.172959</td>\n",
       "      <td>0.665055</td>\n",
       "      <td>72.939713</td>\n",
       "      <td>121.660364</td>\n",
       "      <td>0.520165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399989</td>\n",
       "      <td>0.326906</td>\n",
       "      <td>1.294977</td>\n",
       "      <td>1.986293</td>\n",
       "      <td>0.386238</td>\n",
       "      <td>0.386662</td>\n",
       "      <td>0.592428</td>\n",
       "      <td>0.597926</td>\n",
       "      <td>0.129440</td>\n",
       "      <td>0.794495</td>\n",
       "      <td>29.497673</td>\n",
       "      <td>98.629277</td>\n",
       "      <td>0.562181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.215317</td>\n",
       "      <td>0.942800</td>\n",
       "      <td>1.777571</td>\n",
       "      <td>0.281198</td>\n",
       "      <td>0.270164</td>\n",
       "      <td>0.530175</td>\n",
       "      <td>0.532366</td>\n",
       "      <td>0.094290</td>\n",
       "      <td>0.888786</td>\n",
       "      <td>-5.719963</td>\n",
       "      <td>77.757114</td>\n",
       "      <td>0.554029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600011</td>\n",
       "      <td>0.127478</td>\n",
       "      <td>0.615517</td>\n",
       "      <td>1.583877</td>\n",
       "      <td>0.183583</td>\n",
       "      <td>0.168450</td>\n",
       "      <td>0.472405</td>\n",
       "      <td>0.471708</td>\n",
       "      <td>0.061558</td>\n",
       "      <td>0.950344</td>\n",
       "      <td>-38.448339</td>\n",
       "      <td>58.387748</td>\n",
       "      <td>0.499233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699967</td>\n",
       "      <td>0.060519</td>\n",
       "      <td>0.353514</td>\n",
       "      <td>1.408181</td>\n",
       "      <td>0.105438</td>\n",
       "      <td>0.091542</td>\n",
       "      <td>0.420002</td>\n",
       "      <td>0.417420</td>\n",
       "      <td>0.035336</td>\n",
       "      <td>0.985680</td>\n",
       "      <td>-64.648624</td>\n",
       "      <td>40.818088</td>\n",
       "      <td>0.407148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799978</td>\n",
       "      <td>0.023126</td>\n",
       "      <td>0.132029</td>\n",
       "      <td>1.248640</td>\n",
       "      <td>0.039379</td>\n",
       "      <td>0.039266</td>\n",
       "      <td>0.372417</td>\n",
       "      <td>0.370144</td>\n",
       "      <td>0.013204</td>\n",
       "      <td>0.998884</td>\n",
       "      <td>-86.797076</td>\n",
       "      <td>24.863980</td>\n",
       "      <td>0.283447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899989</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>0.011157</td>\n",
       "      <td>1.111125</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.015264</td>\n",
       "      <td>0.331402</td>\n",
       "      <td>0.330708</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-98.884260</td>\n",
       "      <td>11.112481</td>\n",
       "      <td>0.142518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.298258</td>\n",
       "      <td>0.298293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010040         0.909022  3.130514   \n",
       "1       2                  0.020024         0.885657  3.054772   \n",
       "2       3                  0.030009         0.859976  2.943012   \n",
       "3       4                  0.040049         0.841492  3.019371   \n",
       "4       5                  0.050033         0.821851  2.663613   \n",
       "5       6                  0.100011         0.736056  2.563905   \n",
       "6       7                  0.150044         0.660804  2.338038   \n",
       "7       8                  0.200022         0.586668  1.975956   \n",
       "8       9                  0.300033         0.449115  1.729397   \n",
       "9      10                  0.399989         0.326906  1.294977   \n",
       "10     11                  0.500000         0.215317  0.942800   \n",
       "11     12                  0.600011         0.127478  0.615517   \n",
       "12     13                  0.699967         0.060519  0.353514   \n",
       "13     14                  0.799978         0.023126  0.132029   \n",
       "14     15                  0.899989         0.009908  0.011157   \n",
       "15     16                  1.000000         0.002580  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          3.130514       0.933702  0.933374                  0.933702   \n",
       "1          3.092748       0.911111  0.896438                  0.922438   \n",
       "2          3.042928       0.877778  0.872478                  0.907579   \n",
       "3          3.037023       0.900552  0.850637                  0.905817   \n",
       "4          2.962506       0.794444  0.831180                  0.883592   \n",
       "5          2.763316       0.764706  0.777556                  0.824182   \n",
       "6          2.621505       0.697339  0.697129                  0.781885   \n",
       "7          2.460207       0.589345  0.623198                  0.733777   \n",
       "8          2.216604       0.515807  0.517508                  0.661120   \n",
       "9          1.986293       0.386238  0.386662                  0.592428   \n",
       "10         1.777571       0.281198  0.270164                  0.530175   \n",
       "11         1.583877       0.183583  0.168450                  0.472405   \n",
       "12         1.408181       0.105438  0.091542                  0.420002   \n",
       "13         1.248640       0.039379  0.039266                  0.372417   \n",
       "14         1.111125       0.003328  0.015264                  0.331402   \n",
       "15         1.000000       0.000000  0.006593                  0.298258   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.933374      0.031430                 0.031430  213.051394   \n",
       "1           0.914957      0.030500                 0.061930  205.477238   \n",
       "2           0.900824      0.029384                 0.091315  194.301242   \n",
       "3           0.888242      0.030314                 0.121629  201.937144   \n",
       "4           0.876855      0.026595                 0.148224  166.361251   \n",
       "5           0.827233      0.128138                 0.276362  156.390509   \n",
       "6           0.783849      0.116980                 0.393342  133.803830   \n",
       "7           0.743709      0.098754                 0.492096   97.595588   \n",
       "8           0.668308      0.172959                 0.665055   72.939713   \n",
       "9           0.597926      0.129440                 0.794495   29.497673   \n",
       "10          0.532366      0.094290                 0.888786   -5.719963   \n",
       "11          0.471708      0.061558                 0.950344  -38.448339   \n",
       "12          0.417420      0.035336                 0.985680  -64.648624   \n",
       "13          0.370144      0.013204                 0.998884  -86.797076   \n",
       "14          0.330708      0.001116                 1.000000  -98.884260   \n",
       "15          0.298293      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        213.051394            0.030482  \n",
       "1        209.274807            0.059717  \n",
       "2        204.292844            0.087363  \n",
       "3        203.702288            0.116254  \n",
       "4        196.250640            0.139924  \n",
       "5        176.331628            0.251305  \n",
       "6        162.150455            0.346705  \n",
       "7        146.020689            0.416213  \n",
       "8        121.660364            0.520165  \n",
       "9         98.629277            0.562181  \n",
       "10        77.757114            0.554029  \n",
       "11        58.387748            0.499233  \n",
       "12        40.818088            0.407148  \n",
       "13        24.863980            0.283447  \n",
       "14        11.112481            0.142518  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OBinomialModel.confusion_matrix of >"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "metalearner.std_coef_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_1_AutoML_20210528_061710\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>57885.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>53.45679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0               81.0                      81.0              57885.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0        6.0        6.0         6.0        18.0        64.0     53.45679  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.10043555525361032\n",
      "RMSE: 0.31691569108141415\n",
      "LogLoss: 0.3235122611131131\n",
      "Mean Per-Class Error: 0.144020838279167\n",
      "AUC: 0.9339457207041229\n",
      "AUCPR: 0.860621216295739\n",
      "Gini: 0.8678914414082457\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3957987447464135: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>false</th>\n",
       "      <th>true</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>11012.0</td>\n",
       "      <td>1639.0</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>(1639.0/12651.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true</td>\n",
       "      <td>889.0</td>\n",
       "      <td>4488.0</td>\n",
       "      <td>0.1653</td>\n",
       "      <td>(889.0/5377.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>11901.0</td>\n",
       "      <td>6127.0</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>(2528.0/18028.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            false    true   Error               Rate\n",
       "0  false  11012.0  1639.0  0.1296   (1639.0/12651.0)\n",
       "1   true    889.0  4488.0  0.1653     (889.0/5377.0)\n",
       "2  Total  11901.0  6127.0  0.1402   (2528.0/18028.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.395799</td>\n",
       "      <td>0.780250</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.263771</td>\n",
       "      <td>0.845464</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.553802</td>\n",
       "      <td>0.798050</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.452559</td>\n",
       "      <td>0.865099</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.969915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.030815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.969915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.415246</td>\n",
       "      <td>0.681859</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.374371</td>\n",
       "      <td>0.854083</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.363427</td>\n",
       "      <td>0.855979</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.969915</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.969915</td>\n",
       "      <td>5373.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.030815</td>\n",
       "      <td>5377.000000</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.969915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.969915</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.030815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.395799      0.780250  201.0\n",
       "1                        max f2   0.263771      0.845464  256.0\n",
       "2                  max f0point5   0.553802      0.798050  134.0\n",
       "3                  max accuracy   0.452559      0.865099  177.0\n",
       "4                 max precision   0.969915      1.000000    0.0\n",
       "5                    max recall   0.030815      1.000000  374.0\n",
       "6               max specificity   0.969915      1.000000    0.0\n",
       "7              max absolute_mcc   0.415246      0.681859  193.0\n",
       "8    max min_per_class_accuracy   0.374371      0.854083  210.0\n",
       "9   max mean_per_class_accuracy   0.363427      0.855979  214.0\n",
       "10                      max tns   0.969915  12651.000000    0.0\n",
       "11                      max fns   0.969915   5373.000000    0.0\n",
       "12                      max fps   0.004492  12651.000000  399.0\n",
       "13                      max tps   0.030815   5377.000000  374.0\n",
       "14                      max tnr   0.969915      1.000000    0.0\n",
       "15                      max fnr   0.969915      0.999256    0.0\n",
       "16                      max fpr   0.004492      1.000000  399.0\n",
       "17                      max tpr   0.030815      1.000000  374.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 29.83 %, avg score: 29.82 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.901151</td>\n",
       "      <td>3.352799</td>\n",
       "      <td>3.352799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925328</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925328</td>\n",
       "      <td>0.033662</td>\n",
       "      <td>0.033662</td>\n",
       "      <td>235.279896</td>\n",
       "      <td>235.279896</td>\n",
       "      <td>0.033662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020024</td>\n",
       "      <td>0.871201</td>\n",
       "      <td>3.315546</td>\n",
       "      <td>3.334224</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.885018</td>\n",
       "      <td>0.994460</td>\n",
       "      <td>0.905229</td>\n",
       "      <td>0.033104</td>\n",
       "      <td>0.066766</td>\n",
       "      <td>231.554564</td>\n",
       "      <td>233.422390</td>\n",
       "      <td>0.066608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030009</td>\n",
       "      <td>0.848312</td>\n",
       "      <td>3.241039</td>\n",
       "      <td>3.303220</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.859313</td>\n",
       "      <td>0.985213</td>\n",
       "      <td>0.889952</td>\n",
       "      <td>0.032360</td>\n",
       "      <td>0.099126</td>\n",
       "      <td>224.103899</td>\n",
       "      <td>230.321968</td>\n",
       "      <td>0.098494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040049</td>\n",
       "      <td>0.825817</td>\n",
       "      <td>3.204609</td>\n",
       "      <td>3.278499</td>\n",
       "      <td>0.955801</td>\n",
       "      <td>0.836330</td>\n",
       "      <td>0.977839</td>\n",
       "      <td>0.876509</td>\n",
       "      <td>0.032174</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>220.460895</td>\n",
       "      <td>227.849870</td>\n",
       "      <td>0.130035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050033</td>\n",
       "      <td>0.806206</td>\n",
       "      <td>3.296919</td>\n",
       "      <td>3.282175</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.815322</td>\n",
       "      <td>0.978936</td>\n",
       "      <td>0.864299</td>\n",
       "      <td>0.032918</td>\n",
       "      <td>0.164218</td>\n",
       "      <td>229.691898</td>\n",
       "      <td>228.217459</td>\n",
       "      <td>0.162716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>0.725528</td>\n",
       "      <td>3.077430</td>\n",
       "      <td>3.179859</td>\n",
       "      <td>0.917869</td>\n",
       "      <td>0.765024</td>\n",
       "      <td>0.948419</td>\n",
       "      <td>0.814689</td>\n",
       "      <td>0.153803</td>\n",
       "      <td>0.318021</td>\n",
       "      <td>207.743034</td>\n",
       "      <td>217.985925</td>\n",
       "      <td>0.310670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150044</td>\n",
       "      <td>0.654739</td>\n",
       "      <td>2.877014</td>\n",
       "      <td>3.078873</td>\n",
       "      <td>0.858093</td>\n",
       "      <td>0.690183</td>\n",
       "      <td>0.918299</td>\n",
       "      <td>0.773171</td>\n",
       "      <td>0.143946</td>\n",
       "      <td>0.461968</td>\n",
       "      <td>187.701374</td>\n",
       "      <td>207.887342</td>\n",
       "      <td>0.444499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.581294</td>\n",
       "      <td>2.482039</td>\n",
       "      <td>2.929748</td>\n",
       "      <td>0.740289</td>\n",
       "      <td>0.618011</td>\n",
       "      <td>0.873821</td>\n",
       "      <td>0.734403</td>\n",
       "      <td>0.124047</td>\n",
       "      <td>0.586015</td>\n",
       "      <td>148.203874</td>\n",
       "      <td>192.974751</td>\n",
       "      <td>0.550049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300033</td>\n",
       "      <td>0.449254</td>\n",
       "      <td>1.906056</td>\n",
       "      <td>2.588517</td>\n",
       "      <td>0.568497</td>\n",
       "      <td>0.514883</td>\n",
       "      <td>0.772047</td>\n",
       "      <td>0.661230</td>\n",
       "      <td>0.190627</td>\n",
       "      <td>0.776641</td>\n",
       "      <td>90.605598</td>\n",
       "      <td>158.851700</td>\n",
       "      <td>0.679179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399989</td>\n",
       "      <td>0.322884</td>\n",
       "      <td>1.175898</td>\n",
       "      <td>2.235509</td>\n",
       "      <td>0.350721</td>\n",
       "      <td>0.383975</td>\n",
       "      <td>0.666759</td>\n",
       "      <td>0.591945</td>\n",
       "      <td>0.117538</td>\n",
       "      <td>0.894179</td>\n",
       "      <td>17.589841</td>\n",
       "      <td>123.550928</td>\n",
       "      <td>0.704233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.216594</td>\n",
       "      <td>0.619236</td>\n",
       "      <td>1.912219</td>\n",
       "      <td>0.184692</td>\n",
       "      <td>0.268179</td>\n",
       "      <td>0.570335</td>\n",
       "      <td>0.527184</td>\n",
       "      <td>0.061930</td>\n",
       "      <td>0.956109</td>\n",
       "      <td>-38.076425</td>\n",
       "      <td>91.221871</td>\n",
       "      <td>0.649968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600011</td>\n",
       "      <td>0.133813</td>\n",
       "      <td>0.316126</td>\n",
       "      <td>1.646179</td>\n",
       "      <td>0.094287</td>\n",
       "      <td>0.172895</td>\n",
       "      <td>0.490986</td>\n",
       "      <td>0.468131</td>\n",
       "      <td>0.031616</td>\n",
       "      <td>0.987725</td>\n",
       "      <td>-68.387364</td>\n",
       "      <td>64.617873</td>\n",
       "      <td>0.552503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699967</td>\n",
       "      <td>0.067562</td>\n",
       "      <td>0.104194</td>\n",
       "      <td>1.425982</td>\n",
       "      <td>0.031077</td>\n",
       "      <td>0.098390</td>\n",
       "      <td>0.425311</td>\n",
       "      <td>0.415332</td>\n",
       "      <td>0.010415</td>\n",
       "      <td>0.998140</td>\n",
       "      <td>-89.580647</td>\n",
       "      <td>42.598241</td>\n",
       "      <td>0.424905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799978</td>\n",
       "      <td>0.029232</td>\n",
       "      <td>0.018596</td>\n",
       "      <td>1.250035</td>\n",
       "      <td>0.005546</td>\n",
       "      <td>0.045841</td>\n",
       "      <td>0.372833</td>\n",
       "      <td>0.369139</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-98.140433</td>\n",
       "      <td>25.003467</td>\n",
       "      <td>0.285037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899989</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020177</td>\n",
       "      <td>0.331402</td>\n",
       "      <td>0.330360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.112481</td>\n",
       "      <td>0.142518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009175</td>\n",
       "      <td>0.298258</td>\n",
       "      <td>0.298238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010040         0.901151  3.352799   \n",
       "1       2                  0.020024         0.871201  3.315546   \n",
       "2       3                  0.030009         0.848312  3.241039   \n",
       "3       4                  0.040049         0.825817  3.204609   \n",
       "4       5                  0.050033         0.806206  3.296919   \n",
       "5       6                  0.100011         0.725528  3.077430   \n",
       "6       7                  0.150044         0.654739  2.877014   \n",
       "7       8                  0.200022         0.581294  2.482039   \n",
       "8       9                  0.300033         0.449254  1.906056   \n",
       "9      10                  0.399989         0.322884  1.175898   \n",
       "10     11                  0.500000         0.216594  0.619236   \n",
       "11     12                  0.600011         0.133813  0.316126   \n",
       "12     13                  0.699967         0.067562  0.104194   \n",
       "13     14                  0.799978         0.029232  0.018596   \n",
       "14     15                  0.899989         0.013605  0.000000   \n",
       "15     16                  1.000000         0.003708  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          3.352799       1.000000  0.925328                  1.000000   \n",
       "1          3.334224       0.988889  0.885018                  0.994460   \n",
       "2          3.303220       0.966667  0.859313                  0.985213   \n",
       "3          3.278499       0.955801  0.836330                  0.977839   \n",
       "4          3.282175       0.983333  0.815322                  0.978936   \n",
       "5          3.179859       0.917869  0.765024                  0.948419   \n",
       "6          3.078873       0.858093  0.690183                  0.918299   \n",
       "7          2.929748       0.740289  0.618011                  0.873821   \n",
       "8          2.588517       0.568497  0.514883                  0.772047   \n",
       "9          2.235509       0.350721  0.383975                  0.666759   \n",
       "10         1.912219       0.184692  0.268179                  0.570335   \n",
       "11         1.646179       0.094287  0.172895                  0.490986   \n",
       "12         1.425982       0.031077  0.098390                  0.425311   \n",
       "13         1.250035       0.005546  0.045841                  0.372833   \n",
       "14         1.111125       0.000000  0.020177                  0.331402   \n",
       "15         1.000000       0.000000  0.009175                  0.298258   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.925328      0.033662                 0.033662  235.279896   \n",
       "1           0.905229      0.033104                 0.066766  231.554564   \n",
       "2           0.889952      0.032360                 0.099126  224.103899   \n",
       "3           0.876509      0.032174                 0.131300  220.460895   \n",
       "4           0.864299      0.032918                 0.164218  229.691898   \n",
       "5           0.814689      0.153803                 0.318021  207.743034   \n",
       "6           0.773171      0.143946                 0.461968  187.701374   \n",
       "7           0.734403      0.124047                 0.586015  148.203874   \n",
       "8           0.661230      0.190627                 0.776641   90.605598   \n",
       "9           0.591945      0.117538                 0.894179   17.589841   \n",
       "10          0.527184      0.061930                 0.956109  -38.076425   \n",
       "11          0.468131      0.031616                 0.987725  -68.387364   \n",
       "12          0.415332      0.010415                 0.998140  -89.580647   \n",
       "13          0.369139      0.001860                 1.000000  -98.140433   \n",
       "14          0.330360      0.000000                 1.000000 -100.000000   \n",
       "15          0.298238      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        235.279896            0.033662  \n",
       "1        233.422390            0.066608  \n",
       "2        230.321968            0.098494  \n",
       "3        227.849870            0.130035  \n",
       "4        228.217459            0.162716  \n",
       "5        217.985925            0.310670  \n",
       "6        207.887342            0.444499  \n",
       "7        192.974751            0.550049  \n",
       "8        158.851700            0.679179  \n",
       "9        123.550928            0.704233  \n",
       "10        91.221871            0.649968  \n",
       "11        64.617873            0.552503  \n",
       "12        42.598241            0.424905  \n",
       "13        25.003467            0.285037  \n",
       "14        11.112481            0.142518  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.13547005586359534\n",
      "RMSE: 0.36806257058222497\n",
      "LogLoss: 0.41036321129186654\n",
      "Mean Per-Class Error: 0.21941240313571475\n",
      "AUC: 0.8641679774825592\n",
      "AUCPR: 0.7136088615519571\n",
      "Gini: 0.7283359549651185\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3238127858709052: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>false</th>\n",
       "      <th>true</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>9662.0</td>\n",
       "      <td>2989.0</td>\n",
       "      <td>0.2363</td>\n",
       "      <td>(2989.0/12651.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>4284.0</td>\n",
       "      <td>0.2033</td>\n",
       "      <td>(1093.0/5377.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>10755.0</td>\n",
       "      <td>7273.0</td>\n",
       "      <td>0.2264</td>\n",
       "      <td>(4082.0/18028.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            false    true   Error               Rate\n",
       "0  false   9662.0  2989.0  0.2363   (2989.0/12651.0)\n",
       "1   true   1093.0  4284.0  0.2033    (1093.0/5377.0)\n",
       "2  Total  10755.0  7273.0  0.2264   (4082.0/18028.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.323813</td>\n",
       "      <td>0.677312</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.156366</td>\n",
       "      <td>0.789721</td>\n",
       "      <td>307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.485704</td>\n",
       "      <td>0.669430</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.485704</td>\n",
       "      <td>0.800089</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.978521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.978521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.354775</td>\n",
       "      <td>0.524296</td>\n",
       "      <td>218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.338593</td>\n",
       "      <td>0.776539</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.293433</td>\n",
       "      <td>0.780588</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.978521</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.978521</td>\n",
       "      <td>5376.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.004891</td>\n",
       "      <td>12651.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>5377.000000</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.978521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.978521</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.004891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.323813      0.677312  231.0\n",
       "1                        max f2   0.156366      0.789721  307.0\n",
       "2                  max f0point5   0.485704      0.669430  163.0\n",
       "3                  max accuracy   0.485704      0.800089  163.0\n",
       "4                 max precision   0.978521      1.000000    0.0\n",
       "5                    max recall   0.015320      1.000000  388.0\n",
       "6               max specificity   0.978521      1.000000    0.0\n",
       "7              max absolute_mcc   0.354775      0.524296  218.0\n",
       "8    max min_per_class_accuracy   0.338593      0.776539  225.0\n",
       "9   max mean_per_class_accuracy   0.293433      0.780588  245.0\n",
       "10                      max tns   0.978521  12651.000000    0.0\n",
       "11                      max fns   0.978521   5376.000000    0.0\n",
       "12                      max fps   0.004891  12651.000000  399.0\n",
       "13                      max tps   0.015320   5377.000000  388.0\n",
       "14                      max tnr   0.978521      1.000000    0.0\n",
       "15                      max fnr   0.978521      0.999814    0.0\n",
       "16                      max fpr   0.004891      1.000000  399.0\n",
       "17                      max tpr   0.015320      1.000000  388.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 29.83 %, avg score: 29.53 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.897360</td>\n",
       "      <td>3.204609</td>\n",
       "      <td>3.204609</td>\n",
       "      <td>0.955801</td>\n",
       "      <td>0.922177</td>\n",
       "      <td>0.955801</td>\n",
       "      <td>0.922177</td>\n",
       "      <td>0.032174</td>\n",
       "      <td>0.032174</td>\n",
       "      <td>220.460895</td>\n",
       "      <td>220.460895</td>\n",
       "      <td>0.031542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020024</td>\n",
       "      <td>0.862566</td>\n",
       "      <td>2.905759</td>\n",
       "      <td>3.055598</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.877426</td>\n",
       "      <td>0.911357</td>\n",
       "      <td>0.899863</td>\n",
       "      <td>0.029012</td>\n",
       "      <td>0.061187</td>\n",
       "      <td>190.575910</td>\n",
       "      <td>205.559794</td>\n",
       "      <td>0.058657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030009</td>\n",
       "      <td>0.835535</td>\n",
       "      <td>2.943012</td>\n",
       "      <td>3.018139</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.848007</td>\n",
       "      <td>0.900185</td>\n",
       "      <td>0.882610</td>\n",
       "      <td>0.029384</td>\n",
       "      <td>0.090571</td>\n",
       "      <td>194.301242</td>\n",
       "      <td>201.813880</td>\n",
       "      <td>0.086303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040049</td>\n",
       "      <td>0.812713</td>\n",
       "      <td>2.815610</td>\n",
       "      <td>2.967366</td>\n",
       "      <td>0.839779</td>\n",
       "      <td>0.824251</td>\n",
       "      <td>0.885042</td>\n",
       "      <td>0.867980</td>\n",
       "      <td>0.028269</td>\n",
       "      <td>0.118840</td>\n",
       "      <td>181.561018</td>\n",
       "      <td>196.736639</td>\n",
       "      <td>0.112279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050033</td>\n",
       "      <td>0.794527</td>\n",
       "      <td>2.887132</td>\n",
       "      <td>2.951355</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.803615</td>\n",
       "      <td>0.880266</td>\n",
       "      <td>0.855135</td>\n",
       "      <td>0.028826</td>\n",
       "      <td>0.147666</td>\n",
       "      <td>188.713244</td>\n",
       "      <td>195.135518</td>\n",
       "      <td>0.139129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>0.702162</td>\n",
       "      <td>2.467154</td>\n",
       "      <td>2.709389</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.745913</td>\n",
       "      <td>0.808098</td>\n",
       "      <td>0.800555</td>\n",
       "      <td>0.123303</td>\n",
       "      <td>0.270969</td>\n",
       "      <td>146.715395</td>\n",
       "      <td>170.938884</td>\n",
       "      <td>0.243619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150044</td>\n",
       "      <td>0.631082</td>\n",
       "      <td>2.271131</td>\n",
       "      <td>2.563249</td>\n",
       "      <td>0.677384</td>\n",
       "      <td>0.665807</td>\n",
       "      <td>0.764510</td>\n",
       "      <td>0.755622</td>\n",
       "      <td>0.113632</td>\n",
       "      <td>0.384601</td>\n",
       "      <td>127.113100</td>\n",
       "      <td>156.324889</td>\n",
       "      <td>0.334249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.563882</td>\n",
       "      <td>2.072707</td>\n",
       "      <td>2.440681</td>\n",
       "      <td>0.618202</td>\n",
       "      <td>0.598294</td>\n",
       "      <td>0.727953</td>\n",
       "      <td>0.716312</td>\n",
       "      <td>0.103589</td>\n",
       "      <td>0.488190</td>\n",
       "      <td>107.270701</td>\n",
       "      <td>144.068144</td>\n",
       "      <td>0.410647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300033</td>\n",
       "      <td>0.437947</td>\n",
       "      <td>1.742414</td>\n",
       "      <td>2.207926</td>\n",
       "      <td>0.519689</td>\n",
       "      <td>0.499244</td>\n",
       "      <td>0.658532</td>\n",
       "      <td>0.643956</td>\n",
       "      <td>0.174261</td>\n",
       "      <td>0.662451</td>\n",
       "      <td>74.241410</td>\n",
       "      <td>120.792566</td>\n",
       "      <td>0.516455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399989</td>\n",
       "      <td>0.326062</td>\n",
       "      <td>1.302419</td>\n",
       "      <td>1.981643</td>\n",
       "      <td>0.388457</td>\n",
       "      <td>0.380038</td>\n",
       "      <td>0.591041</td>\n",
       "      <td>0.578004</td>\n",
       "      <td>0.130184</td>\n",
       "      <td>0.792635</td>\n",
       "      <td>30.241913</td>\n",
       "      <td>98.164321</td>\n",
       "      <td>0.559531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.224432</td>\n",
       "      <td>0.881435</td>\n",
       "      <td>1.761577</td>\n",
       "      <td>0.262895</td>\n",
       "      <td>0.273726</td>\n",
       "      <td>0.525405</td>\n",
       "      <td>0.517142</td>\n",
       "      <td>0.088153</td>\n",
       "      <td>0.880789</td>\n",
       "      <td>-11.856533</td>\n",
       "      <td>76.157709</td>\n",
       "      <td>0.542633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600011</td>\n",
       "      <td>0.139814</td>\n",
       "      <td>0.669444</td>\n",
       "      <td>1.579538</td>\n",
       "      <td>0.199667</td>\n",
       "      <td>0.180544</td>\n",
       "      <td>0.471110</td>\n",
       "      <td>0.461037</td>\n",
       "      <td>0.066952</td>\n",
       "      <td>0.947740</td>\n",
       "      <td>-33.055595</td>\n",
       "      <td>57.953809</td>\n",
       "      <td>0.495523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699967</td>\n",
       "      <td>0.072736</td>\n",
       "      <td>0.377702</td>\n",
       "      <td>1.407915</td>\n",
       "      <td>0.112653</td>\n",
       "      <td>0.104769</td>\n",
       "      <td>0.419922</td>\n",
       "      <td>0.410162</td>\n",
       "      <td>0.037753</td>\n",
       "      <td>0.985494</td>\n",
       "      <td>-62.229845</td>\n",
       "      <td>40.791518</td>\n",
       "      <td>0.406883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799978</td>\n",
       "      <td>0.031845</td>\n",
       "      <td>0.133889</td>\n",
       "      <td>1.248640</td>\n",
       "      <td>0.039933</td>\n",
       "      <td>0.049954</td>\n",
       "      <td>0.372417</td>\n",
       "      <td>0.365129</td>\n",
       "      <td>0.013390</td>\n",
       "      <td>0.998884</td>\n",
       "      <td>-86.611119</td>\n",
       "      <td>24.863980</td>\n",
       "      <td>0.283447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899989</td>\n",
       "      <td>0.015102</td>\n",
       "      <td>0.011157</td>\n",
       "      <td>1.111125</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.022306</td>\n",
       "      <td>0.331402</td>\n",
       "      <td>0.327033</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-98.884260</td>\n",
       "      <td>11.112481</td>\n",
       "      <td>0.142518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010081</td>\n",
       "      <td>0.298258</td>\n",
       "      <td>0.295334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010040         0.897360  3.204609   \n",
       "1       2                  0.020024         0.862566  2.905759   \n",
       "2       3                  0.030009         0.835535  2.943012   \n",
       "3       4                  0.040049         0.812713  2.815610   \n",
       "4       5                  0.050033         0.794527  2.887132   \n",
       "5       6                  0.100011         0.702162  2.467154   \n",
       "6       7                  0.150044         0.631082  2.271131   \n",
       "7       8                  0.200022         0.563882  2.072707   \n",
       "8       9                  0.300033         0.437947  1.742414   \n",
       "9      10                  0.399989         0.326062  1.302419   \n",
       "10     11                  0.500000         0.224432  0.881435   \n",
       "11     12                  0.600011         0.139814  0.669444   \n",
       "12     13                  0.699967         0.072736  0.377702   \n",
       "13     14                  0.799978         0.031845  0.133889   \n",
       "14     15                  0.899989         0.015102  0.011157   \n",
       "15     16                  1.000000         0.003255  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          3.204609       0.955801  0.922177                  0.955801   \n",
       "1          3.055598       0.866667  0.877426                  0.911357   \n",
       "2          3.018139       0.877778  0.848007                  0.900185   \n",
       "3          2.967366       0.839779  0.824251                  0.885042   \n",
       "4          2.951355       0.861111  0.803615                  0.880266   \n",
       "5          2.709389       0.735849  0.745913                  0.808098   \n",
       "6          2.563249       0.677384  0.665807                  0.764510   \n",
       "7          2.440681       0.618202  0.598294                  0.727953   \n",
       "8          2.207926       0.519689  0.499244                  0.658532   \n",
       "9          1.981643       0.388457  0.380038                  0.591041   \n",
       "10         1.761577       0.262895  0.273726                  0.525405   \n",
       "11         1.579538       0.199667  0.180544                  0.471110   \n",
       "12         1.407915       0.112653  0.104769                  0.419922   \n",
       "13         1.248640       0.039933  0.049954                  0.372417   \n",
       "14         1.111125       0.003328  0.022306                  0.331402   \n",
       "15         1.000000       0.000000  0.010081                  0.298258   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.922177      0.032174                 0.032174  220.460895   \n",
       "1           0.899863      0.029012                 0.061187  190.575910   \n",
       "2           0.882610      0.029384                 0.090571  194.301242   \n",
       "3           0.867980      0.028269                 0.118840  181.561018   \n",
       "4           0.855135      0.028826                 0.147666  188.713244   \n",
       "5           0.800555      0.123303                 0.270969  146.715395   \n",
       "6           0.755622      0.113632                 0.384601  127.113100   \n",
       "7           0.716312      0.103589                 0.488190  107.270701   \n",
       "8           0.643956      0.174261                 0.662451   74.241410   \n",
       "9           0.578004      0.130184                 0.792635   30.241913   \n",
       "10          0.517142      0.088153                 0.880789  -11.856533   \n",
       "11          0.461037      0.066952                 0.947740  -33.055595   \n",
       "12          0.410162      0.037753                 0.985494  -62.229845   \n",
       "13          0.365129      0.013390                 0.998884  -86.611119   \n",
       "14          0.327033      0.001116                 1.000000  -98.884260   \n",
       "15          0.295334      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        220.460895            0.031542  \n",
       "1        205.559794            0.058657  \n",
       "2        201.813880            0.086303  \n",
       "3        196.736639            0.112279  \n",
       "4        195.135518            0.139129  \n",
       "5        170.938884            0.243619  \n",
       "6        156.324889            0.334249  \n",
       "7        144.068144            0.410647  \n",
       "8        120.792566            0.516455  \n",
       "9         98.164321            0.559531  \n",
       "10        76.157709            0.542633  \n",
       "11        57.953809            0.495523  \n",
       "12        40.791518            0.406883  \n",
       "13        24.863980            0.283447  \n",
       "14        11.112481            0.142518  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>cv_1_valid</th>\n",
       "      <th>cv_2_valid</th>\n",
       "      <th>cv_3_valid</th>\n",
       "      <th>cv_4_valid</th>\n",
       "      <th>cv_5_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.78067493</td>\n",
       "      <td>0.010983764</td>\n",
       "      <td>0.7698281</td>\n",
       "      <td>0.77066</td>\n",
       "      <td>0.7936772</td>\n",
       "      <td>0.79029125</td>\n",
       "      <td>0.77891815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.8642062</td>\n",
       "      <td>0.0054015317</td>\n",
       "      <td>0.86432254</td>\n",
       "      <td>0.8550114</td>\n",
       "      <td>0.867677</td>\n",
       "      <td>0.8684897</td>\n",
       "      <td>0.8655305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>err</td>\n",
       "      <td>0.21932505</td>\n",
       "      <td>0.010983764</td>\n",
       "      <td>0.23017193</td>\n",
       "      <td>0.22933999</td>\n",
       "      <td>0.20632279</td>\n",
       "      <td>0.20970874</td>\n",
       "      <td>0.22108184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>err_count</td>\n",
       "      <td>790.8</td>\n",
       "      <td>39.644672</td>\n",
       "      <td>830.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>797.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f0point5</td>\n",
       "      <td>0.6314402</td>\n",
       "      <td>0.016336285</td>\n",
       "      <td>0.61463416</td>\n",
       "      <td>0.6222425</td>\n",
       "      <td>0.65323085</td>\n",
       "      <td>0.6439571</td>\n",
       "      <td>0.6231366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.67986244</td>\n",
       "      <td>0.010331308</td>\n",
       "      <td>0.6800308</td>\n",
       "      <td>0.6642306</td>\n",
       "      <td>0.6912863</td>\n",
       "      <td>0.6865672</td>\n",
       "      <td>0.6771972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f2</td>\n",
       "      <td>0.73681825</td>\n",
       "      <td>0.017454185</td>\n",
       "      <td>0.7610009</td>\n",
       "      <td>0.71229535</td>\n",
       "      <td>0.73405004</td>\n",
       "      <td>0.7352158</td>\n",
       "      <td>0.74152917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lift_top_group</td>\n",
       "      <td>3.2269464</td>\n",
       "      <td>0.15848134</td>\n",
       "      <td>3.1055498</td>\n",
       "      <td>3.2100096</td>\n",
       "      <td>3.045608</td>\n",
       "      <td>3.359739</td>\n",
       "      <td>3.4138258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logloss</td>\n",
       "      <td>0.41036272</td>\n",
       "      <td>0.0072479476</td>\n",
       "      <td>0.40887854</td>\n",
       "      <td>0.42308584</td>\n",
       "      <td>0.40788755</td>\n",
       "      <td>0.40510845</td>\n",
       "      <td>0.40685323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_per_class_error</td>\n",
       "      <td>0.23894164</td>\n",
       "      <td>0.013036208</td>\n",
       "      <td>0.25403702</td>\n",
       "      <td>0.2516011</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.22833177</td>\n",
       "      <td>0.22636329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mcc</td>\n",
       "      <td>0.5280259</td>\n",
       "      <td>0.016884942</td>\n",
       "      <td>0.5289355</td>\n",
       "      <td>0.5006719</td>\n",
       "      <td>0.54429764</td>\n",
       "      <td>0.53922886</td>\n",
       "      <td>0.5269957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mean_per_class_accuracy</td>\n",
       "      <td>0.7807899</td>\n",
       "      <td>0.009282224</td>\n",
       "      <td>0.7862898</td>\n",
       "      <td>0.76437056</td>\n",
       "      <td>0.78571165</td>\n",
       "      <td>0.78492576</td>\n",
       "      <td>0.7826517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mean_per_class_error</td>\n",
       "      <td>0.2192101</td>\n",
       "      <td>0.009282224</td>\n",
       "      <td>0.21371017</td>\n",
       "      <td>0.23562944</td>\n",
       "      <td>0.21428837</td>\n",
       "      <td>0.21507426</td>\n",
       "      <td>0.2173483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.13546981</td>\n",
       "      <td>0.0029535464</td>\n",
       "      <td>0.13520809</td>\n",
       "      <td>0.14049165</td>\n",
       "      <td>0.13505216</td>\n",
       "      <td>0.13325684</td>\n",
       "      <td>0.13334033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pr_auc</td>\n",
       "      <td>0.71393496</td>\n",
       "      <td>0.005750112</td>\n",
       "      <td>0.7086458</td>\n",
       "      <td>0.707401</td>\n",
       "      <td>0.7154973</td>\n",
       "      <td>0.7208689</td>\n",
       "      <td>0.7172617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.602962</td>\n",
       "      <td>0.021094475</td>\n",
       "      <td>0.57760316</td>\n",
       "      <td>0.5970803</td>\n",
       "      <td>0.6301059</td>\n",
       "      <td>0.6183719</td>\n",
       "      <td>0.591649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.35273805</td>\n",
       "      <td>0.01082751</td>\n",
       "      <td>0.35102645</td>\n",
       "      <td>0.3348964</td>\n",
       "      <td>0.35898474</td>\n",
       "      <td>0.36256394</td>\n",
       "      <td>0.35621876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.7807951</td>\n",
       "      <td>0.0299197</td>\n",
       "      <td>0.8266167</td>\n",
       "      <td>0.7483989</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.7716682</td>\n",
       "      <td>0.7916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rmse</td>\n",
       "      <td>0.36804494</td>\n",
       "      <td>0.0039903303</td>\n",
       "      <td>0.36770654</td>\n",
       "      <td>0.37482217</td>\n",
       "      <td>0.36749443</td>\n",
       "      <td>0.3650436</td>\n",
       "      <td>0.36515796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>specificity</td>\n",
       "      <td>0.78078467</td>\n",
       "      <td>0.023410624</td>\n",
       "      <td>0.745963</td>\n",
       "      <td>0.7803422</td>\n",
       "      <td>0.80579823</td>\n",
       "      <td>0.79818326</td>\n",
       "      <td>0.7736367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean            sd  cv_1_valid  cv_2_valid  \\\n",
       "0                  accuracy  0.78067493   0.010983764   0.7698281     0.77066   \n",
       "1                       auc   0.8642062  0.0054015317  0.86432254   0.8550114   \n",
       "2                       err  0.21932505   0.010983764  0.23017193  0.22933999   \n",
       "3                 err_count       790.8     39.644672       830.0       827.0   \n",
       "4                  f0point5   0.6314402   0.016336285  0.61463416   0.6222425   \n",
       "5                        f1  0.67986244   0.010331308   0.6800308   0.6642306   \n",
       "6                        f2  0.73681825   0.017454185   0.7610009  0.71229535   \n",
       "7            lift_top_group   3.2269464    0.15848134   3.1055498   3.2100096   \n",
       "8                   logloss  0.41036272  0.0072479476  0.40887854  0.42308584   \n",
       "9       max_per_class_error  0.23894164   0.013036208  0.25403702   0.2516011   \n",
       "10                      mcc   0.5280259   0.016884942   0.5289355   0.5006719   \n",
       "11  mean_per_class_accuracy   0.7807899   0.009282224   0.7862898  0.76437056   \n",
       "12     mean_per_class_error   0.2192101   0.009282224  0.21371017  0.23562944   \n",
       "13                      mse  0.13546981  0.0029535464  0.13520809  0.14049165   \n",
       "14                   pr_auc  0.71393496   0.005750112   0.7086458    0.707401   \n",
       "15                precision    0.602962   0.021094475  0.57760316   0.5970803   \n",
       "16                       r2  0.35273805    0.01082751  0.35102645   0.3348964   \n",
       "17                   recall   0.7807951     0.0299197   0.8266167   0.7483989   \n",
       "18                     rmse  0.36804494  0.0039903303  0.36770654  0.37482217   \n",
       "19              specificity  0.78078467   0.023410624    0.745963   0.7803422   \n",
       "\n",
       "    cv_3_valid  cv_4_valid  cv_5_valid  \n",
       "0    0.7936772  0.79029125  0.77891815  \n",
       "1     0.867677   0.8684897   0.8655305  \n",
       "2   0.20632279  0.20970874  0.22108184  \n",
       "3        744.0       756.0       797.0  \n",
       "4   0.65323085   0.6439571   0.6231366  \n",
       "5    0.6912863   0.6865672   0.6771972  \n",
       "6   0.73405004   0.7352158  0.74152917  \n",
       "7     3.045608    3.359739   3.4138258  \n",
       "8   0.40788755  0.40510845  0.40685323  \n",
       "9     0.234375  0.22833177  0.22636329  \n",
       "10  0.54429764  0.53922886   0.5269957  \n",
       "11  0.78571165  0.78492576   0.7826517  \n",
       "12  0.21428837  0.21507426   0.2173483  \n",
       "13  0.13505216  0.13325684  0.13334033  \n",
       "14   0.7154973   0.7208689   0.7172617  \n",
       "15   0.6301059   0.6183719    0.591649  \n",
       "16  0.35898474  0.36256394  0.35621876  \n",
       "17    0.765625   0.7716682   0.7916667  \n",
       "18  0.36749443   0.3650436  0.36515796  \n",
       "19  0.80579823  0.79818326   0.7736367  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:05</td>\n",
       "      <td>11.065 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.457493</td>\n",
       "      <td>0.609381</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.298258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.701742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:05</td>\n",
       "      <td>11.270 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.416537</td>\n",
       "      <td>0.523970</td>\n",
       "      <td>0.856017</td>\n",
       "      <td>0.698773</td>\n",
       "      <td>3.204609</td>\n",
       "      <td>0.230419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:05</td>\n",
       "      <td>11.411 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.393472</td>\n",
       "      <td>0.477137</td>\n",
       "      <td>0.871462</td>\n",
       "      <td>0.724216</td>\n",
       "      <td>3.204609</td>\n",
       "      <td>0.229199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:05</td>\n",
       "      <td>11.625 sec</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.377093</td>\n",
       "      <td>0.442998</td>\n",
       "      <td>0.882104</td>\n",
       "      <td>0.749504</td>\n",
       "      <td>3.241656</td>\n",
       "      <td>0.203517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:05</td>\n",
       "      <td>11.753 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.367003</td>\n",
       "      <td>0.421426</td>\n",
       "      <td>0.888843</td>\n",
       "      <td>0.763042</td>\n",
       "      <td>3.315751</td>\n",
       "      <td>0.195418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:06</td>\n",
       "      <td>11.888 sec</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.359184</td>\n",
       "      <td>0.404474</td>\n",
       "      <td>0.894401</td>\n",
       "      <td>0.775427</td>\n",
       "      <td>3.297228</td>\n",
       "      <td>0.189594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:06</td>\n",
       "      <td>12.018 sec</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>0.391459</td>\n",
       "      <td>0.899891</td>\n",
       "      <td>0.787598</td>\n",
       "      <td>3.315751</td>\n",
       "      <td>0.181163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:06</td>\n",
       "      <td>12.147 sec</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.348575</td>\n",
       "      <td>0.382768</td>\n",
       "      <td>0.903974</td>\n",
       "      <td>0.796143</td>\n",
       "      <td>3.334275</td>\n",
       "      <td>0.170845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:06</td>\n",
       "      <td>12.273 sec</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.344660</td>\n",
       "      <td>0.374886</td>\n",
       "      <td>0.907749</td>\n",
       "      <td>0.804122</td>\n",
       "      <td>3.334275</td>\n",
       "      <td>0.174007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:06</td>\n",
       "      <td>12.434 sec</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.340521</td>\n",
       "      <td>0.366383</td>\n",
       "      <td>0.911266</td>\n",
       "      <td>0.812205</td>\n",
       "      <td>3.352799</td>\n",
       "      <td>0.170901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:06</td>\n",
       "      <td>12.568 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.336431</td>\n",
       "      <td>0.359107</td>\n",
       "      <td>0.915530</td>\n",
       "      <td>0.821728</td>\n",
       "      <td>3.334275</td>\n",
       "      <td>0.160029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:06</td>\n",
       "      <td>12.696 sec</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.333063</td>\n",
       "      <td>0.352487</td>\n",
       "      <td>0.918756</td>\n",
       "      <td>0.828210</td>\n",
       "      <td>3.334275</td>\n",
       "      <td>0.163523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:07</td>\n",
       "      <td>12.825 sec</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.329617</td>\n",
       "      <td>0.346242</td>\n",
       "      <td>0.922037</td>\n",
       "      <td>0.835166</td>\n",
       "      <td>3.334275</td>\n",
       "      <td>0.155369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:07</td>\n",
       "      <td>12.961 sec</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.326021</td>\n",
       "      <td>0.340007</td>\n",
       "      <td>0.925507</td>\n",
       "      <td>0.842732</td>\n",
       "      <td>3.334275</td>\n",
       "      <td>0.153040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:07</td>\n",
       "      <td>13.086 sec</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.323053</td>\n",
       "      <td>0.334475</td>\n",
       "      <td>0.928334</td>\n",
       "      <td>0.848745</td>\n",
       "      <td>3.352799</td>\n",
       "      <td>0.144608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:07</td>\n",
       "      <td>13.208 sec</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.320467</td>\n",
       "      <td>0.329565</td>\n",
       "      <td>0.930519</td>\n",
       "      <td>0.853458</td>\n",
       "      <td>3.352799</td>\n",
       "      <td>0.140448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:07</td>\n",
       "      <td>13.330 sec</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.317398</td>\n",
       "      <td>0.324319</td>\n",
       "      <td>0.933521</td>\n",
       "      <td>0.859733</td>\n",
       "      <td>3.352799</td>\n",
       "      <td>0.138618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>2021-05-28 06:18:07</td>\n",
       "      <td>13.381 sec</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.316916</td>\n",
       "      <td>0.323512</td>\n",
       "      <td>0.933946</td>\n",
       "      <td>0.860621</td>\n",
       "      <td>3.352799</td>\n",
       "      <td>0.140226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0     2021-05-28 06:18:05  11.065 sec              0.0       0.457493   \n",
       "1     2021-05-28 06:18:05  11.270 sec              5.0       0.416537   \n",
       "2     2021-05-28 06:18:05  11.411 sec             10.0       0.393472   \n",
       "3     2021-05-28 06:18:05  11.625 sec             15.0       0.377093   \n",
       "4     2021-05-28 06:18:05  11.753 sec             20.0       0.367003   \n",
       "5     2021-05-28 06:18:06  11.888 sec             25.0       0.359184   \n",
       "6     2021-05-28 06:18:06  12.018 sec             30.0       0.353004   \n",
       "7     2021-05-28 06:18:06  12.147 sec             35.0       0.348575   \n",
       "8     2021-05-28 06:18:06  12.273 sec             40.0       0.344660   \n",
       "9     2021-05-28 06:18:06  12.434 sec             45.0       0.340521   \n",
       "10    2021-05-28 06:18:06  12.568 sec             50.0       0.336431   \n",
       "11    2021-05-28 06:18:06  12.696 sec             55.0       0.333063   \n",
       "12    2021-05-28 06:18:07  12.825 sec             60.0       0.329617   \n",
       "13    2021-05-28 06:18:07  12.961 sec             65.0       0.326021   \n",
       "14    2021-05-28 06:18:07  13.086 sec             70.0       0.323053   \n",
       "15    2021-05-28 06:18:07  13.208 sec             75.0       0.320467   \n",
       "16    2021-05-28 06:18:07  13.330 sec             80.0       0.317398   \n",
       "17    2021-05-28 06:18:07  13.381 sec             81.0       0.316916   \n",
       "\n",
       "    training_logloss  training_auc  training_pr_auc  training_lift  \\\n",
       "0           0.609381      0.500000         0.298258       1.000000   \n",
       "1           0.523970      0.856017         0.698773       3.204609   \n",
       "2           0.477137      0.871462         0.724216       3.204609   \n",
       "3           0.442998      0.882104         0.749504       3.241656   \n",
       "4           0.421426      0.888843         0.763042       3.315751   \n",
       "5           0.404474      0.894401         0.775427       3.297228   \n",
       "6           0.391459      0.899891         0.787598       3.315751   \n",
       "7           0.382768      0.903974         0.796143       3.334275   \n",
       "8           0.374886      0.907749         0.804122       3.334275   \n",
       "9           0.366383      0.911266         0.812205       3.352799   \n",
       "10          0.359107      0.915530         0.821728       3.334275   \n",
       "11          0.352487      0.918756         0.828210       3.334275   \n",
       "12          0.346242      0.922037         0.835166       3.334275   \n",
       "13          0.340007      0.925507         0.842732       3.334275   \n",
       "14          0.334475      0.928334         0.848745       3.352799   \n",
       "15          0.329565      0.930519         0.853458       3.352799   \n",
       "16          0.324319      0.933521         0.859733       3.352799   \n",
       "17          0.323512      0.933946         0.860621       3.352799   \n",
       "\n",
       "    training_classification_error  \n",
       "0                        0.701742  \n",
       "1                        0.230419  \n",
       "2                        0.229199  \n",
       "3                        0.203517  \n",
       "4                        0.195418  \n",
       "5                        0.189594  \n",
       "6                        0.181163  \n",
       "7                        0.170845  \n",
       "8                        0.174007  \n",
       "9                        0.170901  \n",
       "10                       0.160029  \n",
       "11                       0.163523  \n",
       "12                       0.155369  \n",
       "13                       0.153040  \n",
       "14                       0.144608  \n",
       "15                       0.140448  \n",
       "16                       0.138618  \n",
       "17                       0.140226  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Percent_Days_Employed</td>\n",
       "      <td>2207.446533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.240241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jobs_Per_Year</td>\n",
       "      <td>1596.135376</td>\n",
       "      <td>0.723069</td>\n",
       "      <td>0.173710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delinquency_Reports</td>\n",
       "      <td>565.253235</td>\n",
       "      <td>0.256067</td>\n",
       "      <td>0.061518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avg_Days_per_DrugTest</td>\n",
       "      <td>447.108673</td>\n",
       "      <td>0.202546</td>\n",
       "      <td>0.048660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Age_at_Release</td>\n",
       "      <td>438.510162</td>\n",
       "      <td>0.198650</td>\n",
       "      <td>0.047724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DrugTests_THC_Positive</td>\n",
       "      <td>379.995056</td>\n",
       "      <td>0.172142</td>\n",
       "      <td>0.041356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Residence_Changes</td>\n",
       "      <td>345.457336</td>\n",
       "      <td>0.156496</td>\n",
       "      <td>0.037597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Program_Attendances</td>\n",
       "      <td>269.460999</td>\n",
       "      <td>0.122069</td>\n",
       "      <td>0.029326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Prior_Arrest_Episodes_Felony</td>\n",
       "      <td>259.170441</td>\n",
       "      <td>0.117407</td>\n",
       "      <td>0.028206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gang_Affiliated</td>\n",
       "      <td>241.904129</td>\n",
       "      <td>0.109585</td>\n",
       "      <td>0.026327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Supervision_Risk_Score_First</td>\n",
       "      <td>231.313385</td>\n",
       "      <td>0.104788</td>\n",
       "      <td>0.025174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Prior_Arrest_Episodes_PPViolationCharges</td>\n",
       "      <td>211.192078</td>\n",
       "      <td>0.095673</td>\n",
       "      <td>0.022984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DrugTests_Meth_Positive</td>\n",
       "      <td>201.253433</td>\n",
       "      <td>0.091170</td>\n",
       "      <td>0.021903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Prior_Arrest_Episodes_Property</td>\n",
       "      <td>195.097519</td>\n",
       "      <td>0.088382</td>\n",
       "      <td>0.021233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Residence_PUMA</td>\n",
       "      <td>136.996063</td>\n",
       "      <td>0.062061</td>\n",
       "      <td>0.014910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Prison_Offense</td>\n",
       "      <td>124.228493</td>\n",
       "      <td>0.056277</td>\n",
       "      <td>0.013520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Prior_Arrest_Episodes_Misd</td>\n",
       "      <td>120.916656</td>\n",
       "      <td>0.054777</td>\n",
       "      <td>0.013160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Supervision_Level_First</td>\n",
       "      <td>103.752914</td>\n",
       "      <td>0.047001</td>\n",
       "      <td>0.011292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Prior_Conviction_Episodes_Misd</td>\n",
       "      <td>97.146889</td>\n",
       "      <td>0.044009</td>\n",
       "      <td>0.010573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Prison_Years</td>\n",
       "      <td>80.273933</td>\n",
       "      <td>0.036365</td>\n",
       "      <td>0.008736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    variable  relative_importance  \\\n",
       "0                      Percent_Days_Employed          2207.446533   \n",
       "1                              Jobs_Per_Year          1596.135376   \n",
       "2                        Delinquency_Reports           565.253235   \n",
       "3                      Avg_Days_per_DrugTest           447.108673   \n",
       "4                             Age_at_Release           438.510162   \n",
       "5                     DrugTests_THC_Positive           379.995056   \n",
       "6                          Residence_Changes           345.457336   \n",
       "7                        Program_Attendances           269.460999   \n",
       "8               Prior_Arrest_Episodes_Felony           259.170441   \n",
       "9                            Gang_Affiliated           241.904129   \n",
       "10              Supervision_Risk_Score_First           231.313385   \n",
       "11  Prior_Arrest_Episodes_PPViolationCharges           211.192078   \n",
       "12                   DrugTests_Meth_Positive           201.253433   \n",
       "13            Prior_Arrest_Episodes_Property           195.097519   \n",
       "14                            Residence_PUMA           136.996063   \n",
       "15                            Prison_Offense           124.228493   \n",
       "16                Prior_Arrest_Episodes_Misd           120.916656   \n",
       "17                   Supervision_Level_First           103.752914   \n",
       "18            Prior_Conviction_Episodes_Misd            97.146889   \n",
       "19                              Prison_Years            80.273933   \n",
       "\n",
       "    scaled_importance  percentage  \n",
       "0            1.000000    0.240241  \n",
       "1            0.723069    0.173710  \n",
       "2            0.256067    0.061518  \n",
       "3            0.202546    0.048660  \n",
       "4            0.198650    0.047724  \n",
       "5            0.172142    0.041356  \n",
       "6            0.156496    0.037597  \n",
       "7            0.122069    0.029326  \n",
       "8            0.117407    0.028206  \n",
       "9            0.109585    0.026327  \n",
       "10           0.104788    0.025174  \n",
       "11           0.095673    0.022984  \n",
       "12           0.091170    0.021903  \n",
       "13           0.088382    0.021233  \n",
       "14           0.062061    0.014910  \n",
       "15           0.056277    0.013520  \n",
       "16           0.054777    0.013160  \n",
       "17           0.047001    0.011292  \n",
       "18           0.044009    0.010573  \n",
       "19           0.036365    0.008736  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbm = h2o.get_model([mid for mid in model_ids if \"GBM\" in mid][0])\n",
    "print(gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "NIJ_Test_Mod = h2o.import_file(\"NIJ_s_Recidivism_Challenge_Test_Dataset1-sara.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:7807\n",
      "Cols:33\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>ID                </th><th>Gender  </th><th>Race  </th><th>Age_at_Release  </th><th>Residence_PUMA   </th><th>Gang_Affiliated  </th><th>Supervision_Risk_Score_First  </th><th>Supervision_Level_First  </th><th>Education_Level      </th><th>Dependents        </th><th>Prison_Offense  </th><th>Prison_Years             </th><th>Prior_Arrest_Episodes_Felony  </th><th>Prior_Arrest_Episodes_Misd  </th><th>Prior_Arrest_Episodes_Violent  </th><th>Prior_Arrest_Episodes_Property  </th><th>Prior_Arrest_Episodes_Drug  </th><th>Prior_Arrest_Episodes_PPViolationCharges  </th><th>Prior_Arrest_Episodes_DVCharges  </th><th>Prior_Arrest_Episodes_GunCharges  </th><th>Prior_Conviction_Episodes_Felony  </th><th>Prior_Conviction_Episodes_Misd  </th><th>Prior_Conviction_Episodes_Viol  </th><th>Prior_Conviction_Episodes_Prop  </th><th>Prior_Conviction_Episodes_Drug  </th><th>Prior_Conviction_Episodes_PPViolationCharges  </th><th>Prior_Conviction_Episodes_DomesticViolenceCharges  </th><th>Prior_Conviction_Episodes_GunCharges  </th><th>Prior_Revocations_Parole  </th><th>Prior_Revocations_Probation  </th><th>Condition_MH_SA  </th><th>Condition_Cog_Ed  </th><th>Condition_Other  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int               </td><td>enum    </td><td>enum  </td><td>enum            </td><td>int              </td><td>enum             </td><td>int                           </td><td>enum                     </td><td>enum                 </td><td>int               </td><td>enum            </td><td>enum                     </td><td>int                           </td><td>int                         </td><td>int                            </td><td>int                             </td><td>int                         </td><td>int                                       </td><td>enum                             </td><td>enum                              </td><td>int                               </td><td>int                             </td><td>enum                            </td><td>int                             </td><td>int                             </td><td>enum                                          </td><td>enum                                               </td><td>enum                                  </td><td>enum                      </td><td>enum                         </td><td>enum             </td><td>enum              </td><td>enum             </td></tr>\n",
       "<tr><td>mins   </td><td>6.0               </td><td>        </td><td>      </td><td>                </td><td>1.0              </td><td>                 </td><td>1.0                           </td><td>                         </td><td>                     </td><td>0.0               </td><td>                </td><td>                         </td><td>0.0                           </td><td>0.0                         </td><td>0.0                            </td><td>0.0                             </td><td>0.0                         </td><td>0.0                                       </td><td>                                 </td><td>                                  </td><td>0.0                               </td><td>0.0                             </td><td>                                </td><td>0.0                             </td><td>0.0                             </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td></tr>\n",
       "<tr><td>mean   </td><td>13147.602023824773</td><td>        </td><td>      </td><td>                </td><td>12.48699884718842</td><td>                 </td><td>6.1225528582615505            </td><td>                         </td><td>                     </td><td>0.8110582204320762</td><td>                </td><td>                         </td><td>4.460160696350853             </td><td>2.083614548181478           </td><td>0.664463802943827              </td><td>1.4269331585845346              </td><td>1.3597837205903849          </td><td>1.487825356842989                         </td><td>                                 </td><td>                                  </td><td>0.8320836965998256                </td><td>1.1035737921906021              </td><td>                                </td><td>0.6062226543509966              </td><td>0.3482127288578902              </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td></tr>\n",
       "<tr><td>maxs   </td><td>26755.0           </td><td>        </td><td>      </td><td>                </td><td>25.0             </td><td>                 </td><td>10.0                          </td><td>                         </td><td>                     </td><td>2.0               </td><td>                </td><td>                         </td><td>9.0                           </td><td>5.0                         </td><td>2.0                            </td><td>4.0                             </td><td>4.0                         </td><td>4.0                                       </td><td>                                 </td><td>                                  </td><td>2.0                               </td><td>3.0                             </td><td>                                </td><td>2.0                             </td><td>1.0                             </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td></tr>\n",
       "<tr><td>sigma  </td><td>7721.873304986551 </td><td>        </td><td>      </td><td>                </td><td>7.110601208719824</td><td>                 </td><td>2.377941170789086             </td><td>                         </td><td>                     </td><td>0.817431863459127 </td><td>                </td><td>                         </td><td>2.413548531783437             </td><td>1.6658124644167591          </td><td>0.7459682969010476             </td><td>1.3176110953709808              </td><td>1.3216991712175232          </td><td>1.3757989915053217                        </td><td>                                 </td><td>                                  </td><td>0.7749226814076573                </td><td>1.0695770981890422              </td><td>                                </td><td>0.7468053029174522              </td><td>0.47644538603299535             </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td></tr>\n",
       "<tr><td>zeros  </td><td>0                 </td><td>        </td><td>      </td><td>                </td><td>0                </td><td>                 </td><td>0                             </td><td>                         </td><td>                     </td><td>2438              </td><td>                </td><td>                         </td><td>61                            </td><td>1246                        </td><td>3344                           </td><td>1956                            </td><td>2439                        </td><td>1981                                      </td><td>                                 </td><td>                                  </td><td>2284                              </td><td>2312                            </td><td>                                </td><td>3414                            </td><td>3738                            </td><td>                                              </td><td>                                                   </td><td>                                      </td><td>                          </td><td>                             </td><td>                 </td><td>                  </td><td>                 </td></tr>\n",
       "<tr><td>missing</td><td>0                 </td><td>0       </td><td>0     </td><td>0               </td><td>0                </td><td>950              </td><td>145                           </td><td>508                      </td><td>0                    </td><td>2345              </td><td>956             </td><td>0                        </td><td>1833                          </td><td>2473                        </td><td>1149                           </td><td>1703                            </td><td>964                         </td><td>1852                                      </td><td>0                                </td><td>0                                 </td><td>2072                              </td><td>1763                            </td><td>0                               </td><td>1636                            </td><td>2072                            </td><td>0                                             </td><td>0                                                  </td><td>0                                     </td><td>0                         </td><td>0                            </td><td>0                </td><td>0                 </td><td>0                </td></tr>\n",
       "<tr><td>0      </td><td>6.0               </td><td>M       </td><td>WHITE </td><td>38-42           </td><td>17.0             </td><td>false            </td><td>5.0                           </td><td>Standard                 </td><td>High School Diploma  </td><td>0.0               </td><td>Property        </td><td>More than 3 years        </td><td>4.0                           </td><td>0.0                         </td><td>1.0                            </td><td>3.0                             </td><td>0.0                         </td><td>0.0                                       </td><td>false                            </td><td>false                             </td><td>1.0                               </td><td>0.0                             </td><td>false                           </td><td>2.0                             </td><td>0.0                             </td><td>false                                         </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>false            </td><td>false             </td><td>true             </td></tr>\n",
       "<tr><td>1      </td><td>8.0               </td><td>M       </td><td>BLACK </td><td>38-42           </td><td>16.0             </td><td>false            </td><td>5.0                           </td><td>High                     </td><td>High School Diploma  </td><td>nan               </td><td>Drug            </td><td>Greater than 2 to 3 years</td><td>6.0                           </td><td>nan                         </td><td>nan                            </td><td>1.0                             </td><td>2.0                         </td><td>nan                                       </td><td>false                            </td><td>false                             </td><td>1.0                               </td><td>nan                             </td><td>true                            </td><td>0.0                             </td><td>nan                             </td><td>true                                          </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>false            </td><td>true              </td><td>false            </td></tr>\n",
       "<tr><td>2      </td><td>12.0              </td><td>M       </td><td>BLACK </td><td>33-37           </td><td>16.0             </td><td>false            </td><td>5.0                           </td><td>Specialized              </td><td>High School Diploma  </td><td>nan               </td><td>Other           </td><td>1-2 years                </td><td>nan                           </td><td>1.0                         </td><td>1.0                            </td><td>1.0                             </td><td>2.0                         </td><td>3.0                                       </td><td>false                            </td><td>false                             </td><td>nan                               </td><td>1.0                             </td><td>false                           </td><td>0.0                             </td><td>nan                             </td><td>false                                         </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>true                         </td><td>true             </td><td>true              </td><td>true             </td></tr>\n",
       "<tr><td>3      </td><td>15.0              </td><td>M       </td><td>WHITE </td><td>33-37           </td><td>5.0              </td><td>false            </td><td>7.0                           </td><td>Standard                 </td><td>Less than HS diploma </td><td>1.0               </td><td>Violent/Non-Sex </td><td>Greater than 2 to 3 years</td><td>9.0                           </td><td>3.0                         </td><td>2.0                            </td><td>2.0                             </td><td>4.0                         </td><td>4.0                                       </td><td>false                            </td><td>true                              </td><td>nan                               </td><td>2.0                             </td><td>true                            </td><td>1.0                             </td><td>1.0                             </td><td>true                                          </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>true             </td><td>true              </td><td>true             </td></tr>\n",
       "<tr><td>4      </td><td>16.0              </td><td>M       </td><td>BLACK </td><td>33-37           </td><td>3.0              </td><td>false            </td><td>4.0                           </td><td>Standard                 </td><td>Less than HS diploma </td><td>nan               </td><td>                </td><td>More than 3 years        </td><td>4.0                           </td><td>nan                         </td><td>0.0                            </td><td>0.0                             </td><td>3.0                         </td><td>4.0                                       </td><td>false                            </td><td>true                              </td><td>2.0                               </td><td>nan                             </td><td>false                           </td><td>0.0                             </td><td>nan                             </td><td>true                                          </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>true             </td><td>true              </td><td>false            </td></tr>\n",
       "<tr><td>5      </td><td>23.0              </td><td>F       </td><td>WHITE </td><td>48 or older     </td><td>5.0              </td><td>                 </td><td>4.0                           </td><td>                         </td><td>High School Diploma  </td><td>0.0               </td><td>Violent/Non-Sex </td><td>1-2 years                </td><td>2.0                           </td><td>nan                         </td><td>nan                            </td><td>nan                             </td><td>0.0                         </td><td>1.0                                       </td><td>true                             </td><td>false                             </td><td>2.0                               </td><td>2.0                             </td><td>true                            </td><td>1.0                             </td><td>0.0                             </td><td>false                                         </td><td>true                                               </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>true             </td><td>true              </td><td>false            </td></tr>\n",
       "<tr><td>6      </td><td>27.0              </td><td>M       </td><td>WHITE </td><td>48 or older     </td><td>14.0             </td><td>false            </td><td>2.0                           </td><td>Specialized              </td><td>Less than HS diploma </td><td>0.0               </td><td>Drug            </td><td>1-2 years                </td><td>9.0                           </td><td>nan                         </td><td>0.0                            </td><td>0.0                             </td><td>2.0                         </td><td>nan                                       </td><td>false                            </td><td>false                             </td><td>nan                               </td><td>nan                             </td><td>false                           </td><td>0.0                             </td><td>nan                             </td><td>true                                          </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>true             </td><td>false             </td><td>true             </td></tr>\n",
       "<tr><td>7      </td><td>28.0              </td><td>M       </td><td>WHITE </td><td>48 or older     </td><td>23.0             </td><td>false            </td><td>3.0                           </td><td>Standard                 </td><td>Less than HS diploma </td><td>0.0               </td><td>Other           </td><td>1-2 years                </td><td>nan                           </td><td>nan                         </td><td>nan                            </td><td>nan                             </td><td>1.0                         </td><td>nan                                       </td><td>false                            </td><td>false                             </td><td>nan                               </td><td>nan                             </td><td>true                            </td><td>nan                             </td><td>1.0                             </td><td>true                                          </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>true             </td><td>true              </td><td>false            </td></tr>\n",
       "<tr><td>8      </td><td>31.0              </td><td>M       </td><td>WHITE </td><td>43-47           </td><td>14.0             </td><td>false            </td><td>10.0                          </td><td>Specialized              </td><td>At least some college</td><td>0.0               </td><td>Property        </td><td>1-2 years                </td><td>nan                           </td><td>nan                         </td><td>nan                            </td><td>nan                             </td><td>0.0                         </td><td>nan                                       </td><td>true                             </td><td>true                              </td><td>nan                               </td><td>nan                             </td><td>false                           </td><td>nan                             </td><td>0.0                             </td><td>true                                          </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>true                         </td><td>true             </td><td>false             </td><td>true             </td></tr>\n",
       "<tr><td>9      </td><td>35.0              </td><td>M       </td><td>WHITE </td><td>33-37           </td><td>14.0             </td><td>false            </td><td>4.0                           </td><td>Standard                 </td><td>Less than HS diploma </td><td>0.0               </td><td>Drug            </td><td>Less than 1 year         </td><td>5.0                           </td><td>nan                         </td><td>1.0                            </td><td>0.0                             </td><td>4.0                         </td><td>nan                                       </td><td>false                            </td><td>true                              </td><td>nan                               </td><td>nan                             </td><td>false                           </td><td>0.0                             </td><td>nan                             </td><td>true                                          </td><td>false                                              </td><td>false                                 </td><td>false                     </td><td>false                        </td><td>false            </td><td>false             </td><td>false            </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NIJ_Test_Mod.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset is missing column 'Violations_ElectronicMonitoring': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset is missing column 'Violations_Instruction': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset is missing column 'Violations_FailToReport': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset is missing column 'Violations_MoveWithoutPermission': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset is missing column 'Delinquency_Reports': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset is missing column 'Program_Attendances': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset is missing column 'Program_UnexcusedAbsences': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset is missing column 'Residence_Changes': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset is missing column 'Avg_Days_per_DrugTest': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset is missing column 'DrugTests_THC_Positive': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset is missing column 'DrugTests_Cocaine_Positive': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset is missing column 'DrugTests_Meth_Positive': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset is missing column 'DrugTests_Other_Positive': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset is missing column 'Percent_Days_Employed': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset is missing column 'Jobs_Per_Year': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\Vimalathithan\\anaconda3\\lib\\site-packages\\h2o\\job.py:72: UserWarning: Test/Validation dataset is missing column 'Employment_Exempt': substituting in a column of NaN\n",
      "  warnings.warn(w)\n"
     ]
    }
   ],
   "source": [
    "preds = aml.predict(NIJ_Test_Mod)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
